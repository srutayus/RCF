{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from numpy.testing import rundocs\n",
    "import matplotlib.pyplot as plt\n",
    "#import talib\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import tensorflow\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import csv\n",
    "#from datetime import strptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Company (NOC, IOC, OC)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>Type Unit</th>\n",
       "      <th>Water_Depth\\n(meters)</th>\n",
       "      <th>Lessons Learned</th>\n",
       "      <th>Oil/Gas_Prod</th>\n",
       "      <th>FEED_Detail</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lingshui Semi</td>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>EPC</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SEMI</td>\n",
       "      <td>980</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bohai Ming Zhu</td>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>EPC</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petrojarl Varg</td>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>OC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>EPC</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865823</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stybarrow Venture MV16</td>\n",
       "      <td>AUST/NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>EPC</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>825</td>\n",
       "      <td>2</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.143875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alima FPU</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>EPC</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BARGE</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jangkrik</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4</td>\n",
       "      <td>OC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8824</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1052</td>\n",
       "      <td>2.676500</td>\n",
       "      <td>1</td>\n",
       "      <td>79400.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BARGE</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055416</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prelude</td>\n",
       "      <td>AUST/NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7814</td>\n",
       "      <td>EPC</td>\n",
       "      <td>2229</td>\n",
       "      <td>11.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>148333.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>FLNG</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>5</td>\n",
       "      <td>0.243158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CLOV FPSO</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7534</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1383</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>198333.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1290</td>\n",
       "      <td>4</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dalia</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>4</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4872</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1306</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>287000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1360</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836237</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Girassol</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>4</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3103</td>\n",
       "      <td>EPC</td>\n",
       "      <td>823</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>246666.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unit Name   Region  Local Content Requirment (H,M,A,L, N)  \\\n",
       "0           Lingshui Semi   SEA CH                                      5   \n",
       "1          Bohai Ming Zhu   SEA CH                                      5   \n",
       "2          Petrojarl Varg       NE                                      1   \n",
       "3  Stybarrow Venture MV16  AUST/NZ                                      3   \n",
       "4               Alima FPU   AFRICA                                      2   \n",
       "5                Jangkrik      SEA                                      4   \n",
       "6                 Prelude  AUST/NZ                                      3   \n",
       "7               CLOV FPSO   AFRICA                                      3   \n",
       "8                   Dalia   AFRICA                                      4   \n",
       "9                Girassol   AFRICA                                      4   \n",
       "\n",
       "  Company (NOC, IOC, OC)  Lease/ Own  Contract2  Contracting Date  \\\n",
       "0                    NOC           2          1             10439   \n",
       "1                    NOC           2          1              4350   \n",
       "2                     OC           1          1              2240   \n",
       "3                    IOC           1          3              5922   \n",
       "4                    IOC           2          1              5720   \n",
       "5                     OC           2          1              8824   \n",
       "6                    IOC           2          1              7814   \n",
       "7                    IOC           2          1              7534   \n",
       "8                    IOC           2          1              4872   \n",
       "9                    IOC           2          1              3103   \n",
       "\n",
       "  Contract (EPC, CL, PS, TK)  Planned_Duration  Planned_Cost  Hull Type  \\\n",
       "0                        EPC               700      3.100000          1   \n",
       "1                        EPC               259      0.400000          1   \n",
       "2                        EPC               816      0.460000          1   \n",
       "3                        EPC               702      0.598425          1   \n",
       "4                        EPC               994      1.133000          1   \n",
       "5                        EPC              1052      2.676500          1   \n",
       "6                        EPC              2229     11.160000          1   \n",
       "7                        EPC              1383      7.000000          1   \n",
       "8                        EPC              1306      3.400000          1   \n",
       "9                        EPC               823      2.500000          1   \n",
       "\n",
       "         BOE/day  Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  \\\n",
       "0   67166.666667                           2                              2   \n",
       "1   40000.000000                           1                              2   \n",
       "2   65833.333333                           2                              2   \n",
       "3   87500.000000                           2                              3   \n",
       "4  100000.000000                           3                              1   \n",
       "5   79400.000000                           2                              2   \n",
       "6  148333.333333                           6                              5   \n",
       "7  198333.333333                           4                              2   \n",
       "8  287000.000000                           6                              3   \n",
       "9  246666.666667                           5                              3   \n",
       "\n",
       "  Type Unit  Water_Depth\\n(meters)  Lessons Learned  Oil/Gas_Prod  \\\n",
       "0      SEMI                    980                2      0.148883   \n",
       "1      FPSO                     30                1      1.000000   \n",
       "2      FPSO                     84                1      0.865823   \n",
       "3      FPSO                    825                2      0.914286   \n",
       "4     BARGE                    600                3      0.900000   \n",
       "5     BARGE                    120                2      0.055416   \n",
       "6      FLNG                    250                1      0.235955   \n",
       "7      FPSO                   1290                4      0.806723   \n",
       "8      FPSO                   1360                5      0.836237   \n",
       "9      FPSO                   1350                1      0.810811   \n",
       "\n",
       "   FEED_Detail  Schedule_Overrun  \n",
       "0            4          0.760000  \n",
       "1            1          0.471042  \n",
       "2            2          0.286765  \n",
       "3            4         -0.143875  \n",
       "4            4         -0.022133  \n",
       "5            3          0.114068  \n",
       "6            5          0.243158  \n",
       "7            5          0.007954  \n",
       "8            2          0.010720  \n",
       "9            1          0.521264  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_excel(open('Cost.xls', 'rb'), sheet_name='Sheet1')\n",
    "#df.head(76)\n",
    "df = pd.read_excel(open('Cost_Sch-data-v2.xlsx', 'rb'), sheet_name='Sch_2')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.2511606227247125\n",
      "median 0.19644300727566694\n",
      "max 1.929054054054054\n",
      "min -0.14387464387464388\n",
      "std 0.30387827064383305\n",
      "2_std 0.6077565412876661\n",
      "3_std 0.9116348119314992\n",
      "3.9_std 1.1851252555109488\n",
      "(127, 20)\n",
      "describe:        Local Content Requirment (H,M,A,L, N)  Lease/ Own   Contract2  \\\n",
      "count                             127.000000  127.000000  127.000000   \n",
      "mean                                3.204724    1.787402    1.346457   \n",
      "std                                 1.471090    0.410766    0.770260   \n",
      "min                                 1.000000    1.000000    0.000000   \n",
      "25%                                 2.000000    2.000000    1.000000   \n",
      "50%                                 3.000000    2.000000    1.000000   \n",
      "75%                                 5.000000    2.000000    1.000000   \n",
      "max                                 5.000000    2.000000    3.000000   \n",
      "\n",
      "       Contracting Date  Planned_Duration  Planned_Cost   Hull Type  \\\n",
      "count        127.000000        127.000000    127.000000  127.000000   \n",
      "mean        5911.692913       1152.440945      2.155166    1.314961   \n",
      "std         2109.832091        434.454167      2.243545    0.466340   \n",
      "min          287.000000        259.000000      0.142500    1.000000   \n",
      "25%         4452.500000        848.500000      0.884818    1.000000   \n",
      "50%         5922.000000       1081.000000      1.400000    1.000000   \n",
      "75%         7813.500000       1364.000000      2.500000    2.000000   \n",
      "max        10439.000000       2557.000000     15.000000    2.000000   \n",
      "\n",
      "             BOE/day  Topsides (VL, L, M, S, VS)  \\\n",
      "count     127.000000                  127.000000   \n",
      "mean   155577.207165                    3.590551   \n",
      "std     77656.363731                    1.421794   \n",
      "min         0.000000                    1.000000   \n",
      "25%     93333.333333                    2.500000   \n",
      "50%    145833.333333                    3.000000   \n",
      "75%    198083.333333                    4.500000   \n",
      "max    361166.666667                    6.000000   \n",
      "\n",
      "       Technology Novelt (H,M,A,L,N)  Water_Depth\\n(meters)  Lessons Learned  \\\n",
      "count                     127.000000             127.000000       127.000000   \n",
      "mean                        2.417323            1066.913386         2.559055   \n",
      "std                         1.353660             733.831801         1.378137   \n",
      "min                         1.000000              27.000000         1.000000   \n",
      "25%                         1.000000             337.500000         1.000000   \n",
      "50%                         2.000000            1175.000000         2.000000   \n",
      "75%                         3.000000            1600.000000         4.000000   \n",
      "max                         5.000000            2900.000000         5.000000   \n",
      "\n",
      "       Oil/Gas_Prod  FEED_Detail  Schedule_Overrun  \n",
      "count    127.000000   127.000000        127.000000  \n",
      "mean       0.807506     2.645669          0.251161  \n",
      "std        0.171487     1.400270          0.303878  \n",
      "min        0.055416     1.000000         -0.143875  \n",
      "25%        0.780411     1.000000          0.030192  \n",
      "50%        0.835913     2.000000          0.196443  \n",
      "75%        0.900000     4.000000          0.389956  \n",
      "max        1.000000     5.000000          1.929054  \n"
     ]
    }
   ],
   "source": [
    "print('mean', df['Schedule_Overrun'].mean())\n",
    "print('median',df['Schedule_Overrun'].median())\n",
    "print('max',df['Schedule_Overrun'].max())\n",
    "print('min',df['Schedule_Overrun'].min())\n",
    "print('std',df['Schedule_Overrun'].std())\n",
    "Std3_9 =  3.9*df['Schedule_Overrun'].std()\n",
    "Std3 =  3*df['Schedule_Overrun'].std()\n",
    "Std2 =  2*df['Schedule_Overrun'].std()\n",
    "print('2_std',Std2)\n",
    "print('3_std',Std3)\n",
    "print('3.9_std',Std3_9)\n",
    "print(df.shape)\n",
    "print('describe:',df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Company (NOC, IOC, OC)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>Type Unit</th>\n",
       "      <th>Water_Depth\\n(meters)</th>\n",
       "      <th>Lessons Learned</th>\n",
       "      <th>Oil/Gas_Prod</th>\n",
       "      <th>FEED_Detail</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Balder</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1826</td>\n",
       "      <td>TK</td>\n",
       "      <td>592</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>90500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>1</td>\n",
       "      <td>1.929054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Thunder Horse</td>\n",
       "      <td>GOM</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4624</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1098</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>283333.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>SEMI</td>\n",
       "      <td>1830</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Gumusut Semi</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5</td>\n",
       "      <td>IOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6588</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1233</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SEMI</td>\n",
       "      <td>1220</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unit Name Region  Local Content Requirment (H,M,A,L, N)  \\\n",
       "60          Balder     NE                                      3   \n",
       "91   Thunder Horse    GOM                                      3   \n",
       "100   Gumusut Semi    SEA                                      5   \n",
       "\n",
       "    Company (NOC, IOC, OC)  Lease/ Own  Contract2  Contracting Date  \\\n",
       "60                     IOC           2          1              1826   \n",
       "91                     IOC           2          1              4624   \n",
       "100                    IOC           1          3              6588   \n",
       "\n",
       "    Contract (EPC, CL, PS, TK)  Planned_Duration  Planned_Cost  Hull Type  \\\n",
       "60                          TK               592          0.35          1   \n",
       "91                         EPC              1098          5.00          1   \n",
       "100                        EPC              1233          1.60          1   \n",
       "\n",
       "           BOE/day  Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  \\\n",
       "60    90500.000000                           2                              5   \n",
       "91   283333.333333                           6                              5   \n",
       "100  200000.000000                           5                              2   \n",
       "\n",
       "    Type Unit  Water_Depth\\n(meters)  Lessons Learned  Oil/Gas_Prod  \\\n",
       "60       FPSO                    125                1      0.917127   \n",
       "91       SEMI                   1830                1      0.882353   \n",
       "100      SEMI                   1220                2      0.750000   \n",
       "\n",
       "     FEED_Detail  Schedule_Overrun  \n",
       "60             1          1.929054  \n",
       "91             4          0.926230  \n",
       "100            3          0.999189  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[df[\"Cost_Overrun\"]==2.6800000000000006]\n",
    "df[df[\"Schedule_Overrun\"]>Std3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 20)\n",
      "(124, 20)\n"
     ]
    }
   ],
   "source": [
    "#df.drop([0,1])\n",
    "#df.head(10)\n",
    "print(df.shape)\n",
    "df = df[df.Schedule_Overrun < Std3]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.2261526334983535\n",
      "median 0.19186547976863388\n",
      "max 0.8792016806722689\n",
      "min -0.14387464387464388\n"
     ]
    }
   ],
   "source": [
    "#df.drop([df[\"Cost_Overrun\"]==2.6800000000000006], axis =0)\n",
    "#df.drop([67,67])\n",
    "print('mean', df['Schedule_Overrun'].mean())\n",
    "print('median',df['Schedule_Overrun'].median())\n",
    "print('max',df['Schedule_Overrun'].max())\n",
    "print('min',df['Schedule_Overrun'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Company (NOC, IOC, OC)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>Type Unit</th>\n",
       "      <th>Water_Depth\\n(meters)</th>\n",
       "      <th>Lessons Learned</th>\n",
       "      <th>Oil/Gas_Prod</th>\n",
       "      <th>FEED_Detail</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>EPC</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SEMI</td>\n",
       "      <td>980</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>EPC</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>OC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>EPC</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865823</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUST/NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>EPC</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>825</td>\n",
       "      <td>2</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.143875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>EPC</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BARGE</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SEA</td>\n",
       "      <td>4</td>\n",
       "      <td>OC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8824</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1052</td>\n",
       "      <td>2.676500</td>\n",
       "      <td>1</td>\n",
       "      <td>79400.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BARGE</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055416</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUST/NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7814</td>\n",
       "      <td>EPC</td>\n",
       "      <td>2229</td>\n",
       "      <td>11.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>148333.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>FLNG</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>5</td>\n",
       "      <td>0.243158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7534</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1383</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>198333.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1290</td>\n",
       "      <td>4</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>4</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4872</td>\n",
       "      <td>EPC</td>\n",
       "      <td>1306</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>287000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1360</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836237</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>4</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3103</td>\n",
       "      <td>EPC</td>\n",
       "      <td>823</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>246666.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>1350</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Region  Local Content Requirment (H,M,A,L, N) Company (NOC, IOC, OC)  \\\n",
       "0   SEA CH                                      5                    NOC   \n",
       "1   SEA CH                                      5                    NOC   \n",
       "2       NE                                      1                     OC   \n",
       "3  AUST/NZ                                      3                    IOC   \n",
       "4   AFRICA                                      2                    IOC   \n",
       "5      SEA                                      4                     OC   \n",
       "6  AUST/NZ                                      3                    IOC   \n",
       "7   AFRICA                                      3                    IOC   \n",
       "8   AFRICA                                      4                    IOC   \n",
       "9   AFRICA                                      4                    IOC   \n",
       "\n",
       "   Lease/ Own  Contract2  Contracting Date Contract (EPC, CL, PS, TK)  \\\n",
       "0           2          1             10439                        EPC   \n",
       "1           2          1              4350                        EPC   \n",
       "2           1          1              2240                        EPC   \n",
       "3           1          3              5922                        EPC   \n",
       "4           2          1              5720                        EPC   \n",
       "5           2          1              8824                        EPC   \n",
       "6           2          1              7814                        EPC   \n",
       "7           2          1              7534                        EPC   \n",
       "8           2          1              4872                        EPC   \n",
       "9           2          1              3103                        EPC   \n",
       "\n",
       "   Planned_Duration  Planned_Cost  Hull Type        BOE/day  \\\n",
       "0               700      3.100000          1   67166.666667   \n",
       "1               259      0.400000          1   40000.000000   \n",
       "2               816      0.460000          1   65833.333333   \n",
       "3               702      0.598425          1   87500.000000   \n",
       "4               994      1.133000          1  100000.000000   \n",
       "5              1052      2.676500          1   79400.000000   \n",
       "6              2229     11.160000          1  148333.333333   \n",
       "7              1383      7.000000          1  198333.333333   \n",
       "8              1306      3.400000          1  287000.000000   \n",
       "9               823      2.500000          1  246666.666667   \n",
       "\n",
       "   Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N) Type Unit  \\\n",
       "0                           2                              2      SEMI   \n",
       "1                           1                              2      FPSO   \n",
       "2                           2                              2      FPSO   \n",
       "3                           2                              3      FPSO   \n",
       "4                           3                              1     BARGE   \n",
       "5                           2                              2     BARGE   \n",
       "6                           6                              5      FLNG   \n",
       "7                           4                              2      FPSO   \n",
       "8                           6                              3      FPSO   \n",
       "9                           5                              3      FPSO   \n",
       "\n",
       "   Water_Depth\\n(meters)  Lessons Learned  Oil/Gas_Prod  FEED_Detail  \\\n",
       "0                    980                2      0.148883            4   \n",
       "1                     30                1      1.000000            1   \n",
       "2                     84                1      0.865823            2   \n",
       "3                    825                2      0.914286            4   \n",
       "4                    600                3      0.900000            4   \n",
       "5                    120                2      0.055416            3   \n",
       "6                    250                1      0.235955            5   \n",
       "7                   1290                4      0.806723            5   \n",
       "8                   1360                5      0.836237            2   \n",
       "9                   1350                1      0.810811            1   \n",
       "\n",
       "   Schedule_Overrun  \n",
       "0          0.760000  \n",
       "1          0.471042  \n",
       "2          0.286765  \n",
       "3         -0.143875  \n",
       "4         -0.022133  \n",
       "5          0.114068  \n",
       "6          0.243158  \n",
       "7          0.007954  \n",
       "8          0.010720  \n",
       "9          0.521264  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop('Unit Name', axis = 1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 19)\n",
      "[0.76 0.47104247104247104 0.2867647058823529 -0.14387464387464388\n",
      " -0.022132796780684104 0.11406844106463879 0.24315836698070883\n",
      " 0.007953723788864787 0.010719754977029096 0.5212636695018226\n",
      " 0.4477335800185014 0.546462063086104 -0.1400560224089636\n",
      " -0.10163111668757842 -0.08406524466750313 0.1903914590747331\n",
      " 0.29703763010408324 0.03654080389768575 0.06751054852320675\n",
      " 0.015567765567765568 0.11367673179396093 0.07214121258633922\n",
      " 0.707647628267183 0.2871473354231975 0.1933395004625347\n",
      " 0.005591798695246971 0.3763625932300631 0.0019723865877712033\n",
      " 0.14664804469273743 0.6635071090047393 0.43827859569648925\n",
      " 0.3674846625766871 0.5299244625217897 0.3649122807017544\n",
      " 0.3053691275167785 0.2551594746716698 0.20902090209020902\n",
      " 0.33906922174423154 0.4278451310129057 0.18138424821002386\n",
      " 0.059745347698334964 -0.04514889529298751 0.457280385078219\n",
      " -0.04279069767441861 -0.015084294587400177 0.18771998435666798\n",
      " 0.5043186180422264 0.233201581027668 0.3889602053915276\n",
      " 0.08676789587852494 0.39095205941931127 0.24777636594663277\n",
      " 0.24468085106382978 0.22646850672328378 0.05204778156996587\n",
      " 0.27897838899803534 0.3941227312013829 0.07241659886086249\n",
      " 0.1122715404699739 0.20804597701149424 0.7236070381231672\n",
      " 0.8565573770491803 -0.12518740629685157 0.7349397590361446\n",
      " 0.16285211267605634 0.1667521806054387 0.8792016806722689\n",
      " 0.058927000879507474 -0.01597444089456869 0.3501199040767386\n",
      " 0.03764320785597381 0.7279821627647715 0.31950207468879666\n",
      " 0.7009174311926606 0.2079207920792079 0.6636005256241787\n",
      " 0.09740259740259741 0.8095801301005322 0.0 0.4297297297297297\n",
      " 0.10747051114023591 0.356353591160221 0.24400564174894218\n",
      " 0.2737881508078995 0.19644300727566694 0.4914361001317523\n",
      " 0.603887399463807 -0.012808783165599268 0.2860520094562648\n",
      " 0.08768267223382047 -0.005422993492407809 0.0 0.08898015058179329\n",
      " 0.02384393063583815 -0.06468716861081654 0.18635809987819732\n",
      " 0.35233570863024544 0.3396004700352526 0.4055441478439425\n",
      " 0.36675824175824173 0.26747195858498707 0.6135040745052387\n",
      " 0.02290622763063708 -0.09581564584596726 0.1400198609731877\n",
      " 0.7426597582037997 0.12190812720848057 0.41948579161028415\n",
      " -0.01597444089456869 0.005591798695246971 -0.1400560224089636 0.04 0.04\n",
      " 0.3505084745762712 0.04460665044606651 0.038461538461538464\n",
      " 0.03857566765578635 -0.12209889001009082 0.23449830890642615\n",
      " -0.08847184986595175 -0.09016393442622951 -0.12562396006655574\n",
      " -0.08173076923076923 0.015300546448087432]\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.shape)\n",
    "Y = dataset[:,18]\n",
    "df= df.drop('Schedule_Overrun', axis = 1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_EPC</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_PS</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_TK</th>\n",
       "      <th>Type Unit_BARGE</th>\n",
       "      <th>Type Unit_FLNG</th>\n",
       "      <th>Type Unit_FPSO</th>\n",
       "      <th>Type Unit_FSO</th>\n",
       "      <th>Type Unit_SEMI</th>\n",
       "      <th>Type Unit_SPAR</th>\n",
       "      <th>Type Unit_TLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8824</td>\n",
       "      <td>1052</td>\n",
       "      <td>2.676500</td>\n",
       "      <td>1</td>\n",
       "      <td>79400.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7814</td>\n",
       "      <td>2229</td>\n",
       "      <td>11.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>148333.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7534</td>\n",
       "      <td>1383</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>198333.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4872</td>\n",
       "      <td>1306</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>287000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3103</td>\n",
       "      <td>823</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>246666.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Local Content Requirment (H,M,A,L, N)  Lease/ Own  Contract2  \\\n",
       "0                                      5           2          1   \n",
       "1                                      5           2          1   \n",
       "2                                      1           1          1   \n",
       "3                                      3           1          3   \n",
       "4                                      2           2          1   \n",
       "5                                      4           2          1   \n",
       "6                                      3           2          1   \n",
       "7                                      3           2          1   \n",
       "8                                      4           2          1   \n",
       "9                                      4           2          1   \n",
       "\n",
       "   Contracting Date  Planned_Duration  Planned_Cost  Hull Type        BOE/day  \\\n",
       "0             10439               700      3.100000          1   67166.666667   \n",
       "1              4350               259      0.400000          1   40000.000000   \n",
       "2              2240               816      0.460000          1   65833.333333   \n",
       "3              5922               702      0.598425          1   87500.000000   \n",
       "4              5720               994      1.133000          1  100000.000000   \n",
       "5              8824              1052      2.676500          1   79400.000000   \n",
       "6              7814              2229     11.160000          1  148333.333333   \n",
       "7              7534              1383      7.000000          1  198333.333333   \n",
       "8              4872              1306      3.400000          1  287000.000000   \n",
       "9              3103               823      2.500000          1  246666.666667   \n",
       "\n",
       "   Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  ...  \\\n",
       "0                           2                              2  ...   \n",
       "1                           1                              2  ...   \n",
       "2                           2                              2  ...   \n",
       "3                           2                              3  ...   \n",
       "4                           3                              1  ...   \n",
       "5                           2                              2  ...   \n",
       "6                           6                              5  ...   \n",
       "7                           4                              2  ...   \n",
       "8                           6                              3  ...   \n",
       "9                           5                              3  ...   \n",
       "\n",
       "   Contract (EPC, CL, PS, TK)_EPC  Contract (EPC, CL, PS, TK)_PS  \\\n",
       "0                               1                              0   \n",
       "1                               1                              0   \n",
       "2                               1                              0   \n",
       "3                               1                              0   \n",
       "4                               1                              0   \n",
       "5                               1                              0   \n",
       "6                               1                              0   \n",
       "7                               1                              0   \n",
       "8                               1                              0   \n",
       "9                               1                              0   \n",
       "\n",
       "   Contract (EPC, CL, PS, TK)_TK  Type Unit_BARGE  Type Unit_FLNG  \\\n",
       "0                              0                0               0   \n",
       "1                              0                0               0   \n",
       "2                              0                0               0   \n",
       "3                              0                0               0   \n",
       "4                              0                1               0   \n",
       "5                              0                1               0   \n",
       "6                              0                0               1   \n",
       "7                              0                0               0   \n",
       "8                              0                0               0   \n",
       "9                              0                0               0   \n",
       "\n",
       "   Type Unit_FPSO  Type Unit_FSO  Type Unit_SEMI  Type Unit_SPAR  \\\n",
       "0               0              0               1               0   \n",
       "1               1              0               0               0   \n",
       "2               1              0               0               0   \n",
       "3               1              0               0               0   \n",
       "4               0              0               0               0   \n",
       "5               0              0               0               0   \n",
       "6               0              0               0               0   \n",
       "7               1              0               0               0   \n",
       "8               1              0               0               0   \n",
       "9               1              0               0               0   \n",
       "\n",
       "   Type Unit_TLP  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "df = pd.get_dummies(df)\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "#df.iloc[:,5:].head(5)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 36)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 37)\n"
     ]
    }
   ],
   "source": [
    "df['Schedule_Overrun'] = Y\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76 0.47104247104247104 0.2867647058823529 -0.14387464387464388\n",
      " -0.022132796780684104 0.11406844106463879 0.24315836698070883\n",
      " 0.007953723788864787 0.010719754977029096 0.5212636695018226\n",
      " 0.4477335800185014 0.546462063086104 -0.1400560224089636\n",
      " -0.10163111668757842 -0.08406524466750313 0.1903914590747331\n",
      " 0.29703763010408324 0.03654080389768575 0.06751054852320675\n",
      " 0.015567765567765568 0.11367673179396093 0.07214121258633922\n",
      " 0.707647628267183 0.2871473354231975 0.1933395004625347\n",
      " 0.005591798695246971 0.3763625932300631 0.0019723865877712033\n",
      " 0.14664804469273743 0.6635071090047393 0.43827859569648925\n",
      " 0.3674846625766871 0.5299244625217897 0.3649122807017544\n",
      " 0.3053691275167785 0.2551594746716698 0.20902090209020902\n",
      " 0.33906922174423154 0.4278451310129057 0.18138424821002386\n",
      " 0.059745347698334964 -0.04514889529298751 0.457280385078219\n",
      " -0.04279069767441861 -0.015084294587400177 0.18771998435666798\n",
      " 0.5043186180422264 0.233201581027668 0.3889602053915276\n",
      " 0.08676789587852494 0.39095205941931127 0.24777636594663277\n",
      " 0.24468085106382978 0.22646850672328378 0.05204778156996587\n",
      " 0.27897838899803534 0.3941227312013829 0.07241659886086249\n",
      " 0.1122715404699739 0.20804597701149424 0.7236070381231672\n",
      " 0.8565573770491803 -0.12518740629685157 0.7349397590361446\n",
      " 0.16285211267605634 0.1667521806054387 0.8792016806722689\n",
      " 0.058927000879507474 -0.01597444089456869 0.3501199040767386\n",
      " 0.03764320785597381 0.7279821627647715 0.31950207468879666\n",
      " 0.7009174311926606 0.2079207920792079 0.6636005256241787\n",
      " 0.09740259740259741 0.8095801301005322 0.0 0.4297297297297297\n",
      " 0.10747051114023591 0.356353591160221 0.24400564174894218\n",
      " 0.2737881508078995 0.19644300727566694 0.4914361001317523\n",
      " 0.603887399463807 -0.012808783165599268 0.2860520094562648\n",
      " 0.08768267223382047 -0.005422993492407809 0.0 0.08898015058179329\n",
      " 0.02384393063583815 -0.06468716861081654 0.18635809987819732\n",
      " 0.35233570863024544 0.3396004700352526 0.4055441478439425\n",
      " 0.36675824175824173 0.26747195858498707 0.6135040745052387\n",
      " 0.02290622763063708 -0.09581564584596726 0.1400198609731877\n",
      " 0.7426597582037997 0.12190812720848057 0.41948579161028415\n",
      " -0.01597444089456869 0.005591798695246971 -0.1400560224089636 0.04 0.04\n",
      " 0.3505084745762712 0.04460665044606651 0.038461538461538464\n",
      " 0.03857566765578635 -0.12209889001009082 0.23449830890642615\n",
      " -0.08847184986595175 -0.09016393442622951 -0.12562396006655574\n",
      " -0.08173076923076923 0.015300546448087432]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_PS</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_TK</th>\n",
       "      <th>Type Unit_BARGE</th>\n",
       "      <th>Type Unit_FLNG</th>\n",
       "      <th>Type Unit_FPSO</th>\n",
       "      <th>Type Unit_FSO</th>\n",
       "      <th>Type Unit_SEMI</th>\n",
       "      <th>Type Unit_SPAR</th>\n",
       "      <th>Type Unit_TLP</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.143875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0221328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6001</td>\n",
       "      <td>1119</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>1</td>\n",
       "      <td>116666.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0884718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1381</td>\n",
       "      <td>1098</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>230833.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7729</td>\n",
       "      <td>1202</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>116666.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>1040</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1</td>\n",
       "      <td>216666.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0817308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "      <td>915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>93333.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0153005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Local Content Requirment (H,M,A,L, N)  Lease/ Own  Contract2  \\\n",
       "0                                        5           2          1   \n",
       "1                                        5           2          1   \n",
       "2                                        1           1          1   \n",
       "3                                        3           1          3   \n",
       "4                                        2           2          1   \n",
       "..                                     ...         ...        ...   \n",
       "122                                      2           2          1   \n",
       "123                                      1           2          1   \n",
       "124                                      1           2          1   \n",
       "125                                      1           2          1   \n",
       "126                                      1           2          1   \n",
       "\n",
       "     Contracting Date  Planned_Duration  Planned_Cost  Hull Type  \\\n",
       "0               10439               700      3.100000          1   \n",
       "1                4350               259      0.400000          1   \n",
       "2                2240               816      0.460000          1   \n",
       "3                5922               702      0.598425          1   \n",
       "4                5720               994      1.133000          1   \n",
       "..                ...               ...           ...        ...   \n",
       "122              6001              1119      4.410000          1   \n",
       "123              1381              1098      1.200000          1   \n",
       "124              7729              1202      3.000000          1   \n",
       "125              2398              1040      1.450000          1   \n",
       "126              1885               915      1.000000          1   \n",
       "\n",
       "           BOE/day  Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  \\\n",
       "0     67166.666667                           2                              2   \n",
       "1     40000.000000                           1                              2   \n",
       "2     65833.333333                           2                              2   \n",
       "3     87500.000000                           2                              3   \n",
       "4    100000.000000                           3                              1   \n",
       "..             ...                         ...                            ...   \n",
       "122  116666.666667                           3                              2   \n",
       "123  230833.333333                           5                              2   \n",
       "124  116666.666667                           3                              2   \n",
       "125  216666.666667                           5                              3   \n",
       "126   93333.333333                           2                              3   \n",
       "\n",
       "     ...  Contract (EPC, CL, PS, TK)_PS  Contract (EPC, CL, PS, TK)_TK  \\\n",
       "0    ...                              0                              0   \n",
       "1    ...                              0                              0   \n",
       "2    ...                              0                              0   \n",
       "3    ...                              0                              0   \n",
       "4    ...                              0                              0   \n",
       "..   ...                            ...                            ...   \n",
       "122  ...                              0                              0   \n",
       "123  ...                              0                              0   \n",
       "124  ...                              0                              0   \n",
       "125  ...                              0                              0   \n",
       "126  ...                              0                              0   \n",
       "\n",
       "     Type Unit_BARGE  Type Unit_FLNG  Type Unit_FPSO  Type Unit_FSO  \\\n",
       "0                  0               0               0              0   \n",
       "1                  0               0               1              0   \n",
       "2                  0               0               1              0   \n",
       "3                  0               0               1              0   \n",
       "4                  1               0               0              0   \n",
       "..               ...             ...             ...            ...   \n",
       "122                0               0               0              0   \n",
       "123                0               0               0              0   \n",
       "124                0               0               0              0   \n",
       "125                0               0               0              0   \n",
       "126                0               0               0              0   \n",
       "\n",
       "     Type Unit_SEMI  Type Unit_SPAR  Type Unit_TLP  Schedule_Overrun  \n",
       "0                 1               0              0              0.76  \n",
       "1                 0               0              0          0.471042  \n",
       "2                 0               0              0          0.286765  \n",
       "3                 0               0              0         -0.143875  \n",
       "4                 0               0              0        -0.0221328  \n",
       "..              ...             ...            ...               ...  \n",
       "122               0               0              1        -0.0884718  \n",
       "123               0               0              1        -0.0901639  \n",
       "124               0               0              1         -0.125624  \n",
       "125               0               0              1        -0.0817308  \n",
       "126               0               0              1         0.0153005  \n",
       "\n",
       "[124 rows x 37 columns]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['Schedule_Overrun'])\n",
    "df['Schedule_Overrun'].astype(str).astype(float)\n",
    "#df['Schedule_Overrun']\n",
    "df['Schedule_Overrun'] = pd.to_numeric(df['Schedule_Overrun'],errors='coerce')\n",
    "df.dtypes['Schedule_Overrun']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_PS</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_TK</th>\n",
       "      <th>Type Unit_BARGE</th>\n",
       "      <th>Type Unit_FLNG</th>\n",
       "      <th>Type Unit_FPSO</th>\n",
       "      <th>Type Unit_FSO</th>\n",
       "      <th>Type Unit_SEMI</th>\n",
       "      <th>Type Unit_SPAR</th>\n",
       "      <th>Type Unit_TLP</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.143875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6001</td>\n",
       "      <td>1119</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>1</td>\n",
       "      <td>116666.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.088472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1381</td>\n",
       "      <td>1098</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>230833.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.090164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7729</td>\n",
       "      <td>1202</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>116666.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>1040</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1</td>\n",
       "      <td>216666.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.081731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "      <td>915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>93333.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Local Content Requirment (H,M,A,L, N)  Lease/ Own  Contract2  \\\n",
       "0                                        5           2          1   \n",
       "1                                        5           2          1   \n",
       "2                                        1           1          1   \n",
       "3                                        3           1          3   \n",
       "4                                        2           2          1   \n",
       "..                                     ...         ...        ...   \n",
       "122                                      2           2          1   \n",
       "123                                      1           2          1   \n",
       "124                                      1           2          1   \n",
       "125                                      1           2          1   \n",
       "126                                      1           2          1   \n",
       "\n",
       "     Contracting Date  Planned_Duration  Planned_Cost  Hull Type  \\\n",
       "0               10439               700      3.100000          1   \n",
       "1                4350               259      0.400000          1   \n",
       "2                2240               816      0.460000          1   \n",
       "3                5922               702      0.598425          1   \n",
       "4                5720               994      1.133000          1   \n",
       "..                ...               ...           ...        ...   \n",
       "122              6001              1119      4.410000          1   \n",
       "123              1381              1098      1.200000          1   \n",
       "124              7729              1202      3.000000          1   \n",
       "125              2398              1040      1.450000          1   \n",
       "126              1885               915      1.000000          1   \n",
       "\n",
       "           BOE/day  Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  \\\n",
       "0     67166.666667                           2                              2   \n",
       "1     40000.000000                           1                              2   \n",
       "2     65833.333333                           2                              2   \n",
       "3     87500.000000                           2                              3   \n",
       "4    100000.000000                           3                              1   \n",
       "..             ...                         ...                            ...   \n",
       "122  116666.666667                           3                              2   \n",
       "123  230833.333333                           5                              2   \n",
       "124  116666.666667                           3                              2   \n",
       "125  216666.666667                           5                              3   \n",
       "126   93333.333333                           2                              3   \n",
       "\n",
       "     ...  Contract (EPC, CL, PS, TK)_PS  Contract (EPC, CL, PS, TK)_TK  \\\n",
       "0    ...                              0                              0   \n",
       "1    ...                              0                              0   \n",
       "2    ...                              0                              0   \n",
       "3    ...                              0                              0   \n",
       "4    ...                              0                              0   \n",
       "..   ...                            ...                            ...   \n",
       "122  ...                              0                              0   \n",
       "123  ...                              0                              0   \n",
       "124  ...                              0                              0   \n",
       "125  ...                              0                              0   \n",
       "126  ...                              0                              0   \n",
       "\n",
       "     Type Unit_BARGE  Type Unit_FLNG  Type Unit_FPSO  Type Unit_FSO  \\\n",
       "0                  0               0               0              0   \n",
       "1                  0               0               1              0   \n",
       "2                  0               0               1              0   \n",
       "3                  0               0               1              0   \n",
       "4                  1               0               0              0   \n",
       "..               ...             ...             ...            ...   \n",
       "122                0               0               0              0   \n",
       "123                0               0               0              0   \n",
       "124                0               0               0              0   \n",
       "125                0               0               0              0   \n",
       "126                0               0               0              0   \n",
       "\n",
       "     Type Unit_SEMI  Type Unit_SPAR  Type Unit_TLP  Schedule_Overrun  \n",
       "0                 1               0              0          0.760000  \n",
       "1                 0               0              0          0.471042  \n",
       "2                 0               0              0          0.286765  \n",
       "3                 0               0              0         -0.143875  \n",
       "4                 0               0              0         -0.022133  \n",
       "..              ...             ...            ...               ...  \n",
       "122               0               0              1         -0.088472  \n",
       "123               0               0              1         -0.090164  \n",
       "124               0               0              1         -0.125624  \n",
       "125               0               0              1         -0.081731  \n",
       "126               0               0              1          0.015301  \n",
       "\n",
       "[124 rows x 37 columns]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a5ecfb0b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "corr = df2.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a5d5ecfd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20)) \n",
    "corr = df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_PS</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)_TK</th>\n",
       "      <th>Type Unit_BARGE</th>\n",
       "      <th>Type Unit_FLNG</th>\n",
       "      <th>Type Unit_FPSO</th>\n",
       "      <th>Type Unit_FSO</th>\n",
       "      <th>Type Unit_SEMI</th>\n",
       "      <th>Type Unit_SPAR</th>\n",
       "      <th>Type Unit_TLP</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027317</td>\n",
       "      <td>0.078185</td>\n",
       "      <td>0.195892</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>-0.086451</td>\n",
       "      <td>0.354177</td>\n",
       "      <td>0.398567</td>\n",
       "      <td>0.363514</td>\n",
       "      <td>-0.132704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110515</td>\n",
       "      <td>0.101773</td>\n",
       "      <td>-0.016814</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>0.359552</td>\n",
       "      <td>-0.079032</td>\n",
       "      <td>0.070150</td>\n",
       "      <td>-0.271910</td>\n",
       "      <td>-0.317194</td>\n",
       "      <td>0.204014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lease/ Own</th>\n",
       "      <td>0.027317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.786215</td>\n",
       "      <td>-0.236899</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.165378</td>\n",
       "      <td>-0.407387</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>0.266547</td>\n",
       "      <td>0.312178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175055</td>\n",
       "      <td>0.079797</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>-0.180730</td>\n",
       "      <td>-0.106652</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.191076</td>\n",
       "      <td>0.116818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract2</th>\n",
       "      <td>0.078185</td>\n",
       "      <td>-0.786215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202845</td>\n",
       "      <td>-0.205245</td>\n",
       "      <td>-0.151574</td>\n",
       "      <td>0.305022</td>\n",
       "      <td>-0.086489</td>\n",
       "      <td>-0.098530</td>\n",
       "      <td>-0.199589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196888</td>\n",
       "      <td>-0.053998</td>\n",
       "      <td>-0.057002</td>\n",
       "      <td>-0.040142</td>\n",
       "      <td>0.162776</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>-0.063094</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>-0.165153</td>\n",
       "      <td>-0.084245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contracting Date</th>\n",
       "      <td>0.195892</td>\n",
       "      <td>-0.236899</td>\n",
       "      <td>0.202845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351832</td>\n",
       "      <td>0.254975</td>\n",
       "      <td>0.354339</td>\n",
       "      <td>-0.205998</td>\n",
       "      <td>-0.212550</td>\n",
       "      <td>-0.309855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130882</td>\n",
       "      <td>-0.305369</td>\n",
       "      <td>0.080996</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.205602</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>-0.133828</td>\n",
       "      <td>-0.049012</td>\n",
       "      <td>-0.240837</td>\n",
       "      <td>0.128776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Planned_Duration</th>\n",
       "      <td>0.222175</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>-0.205245</td>\n",
       "      <td>0.351832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.349849</td>\n",
       "      <td>-0.095672</td>\n",
       "      <td>0.320179</td>\n",
       "      <td>0.327667</td>\n",
       "      <td>-0.026833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067532</td>\n",
       "      <td>-0.125400</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>0.222290</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>-0.085211</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>-0.101881</td>\n",
       "      <td>-0.082009</td>\n",
       "      <td>-0.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Planned_Cost</th>\n",
       "      <td>-0.086451</td>\n",
       "      <td>0.165378</td>\n",
       "      <td>-0.151574</td>\n",
       "      <td>0.254975</td>\n",
       "      <td>0.349849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165272</td>\n",
       "      <td>0.178628</td>\n",
       "      <td>0.251371</td>\n",
       "      <td>0.250071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046328</td>\n",
       "      <td>-0.093498</td>\n",
       "      <td>-0.014086</td>\n",
       "      <td>0.362520</td>\n",
       "      <td>-0.036295</td>\n",
       "      <td>-0.012382</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>0.044775</td>\n",
       "      <td>-0.102980</td>\n",
       "      <td>-0.055486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hull Type</th>\n",
       "      <td>0.354177</td>\n",
       "      <td>-0.407387</td>\n",
       "      <td>0.305022</td>\n",
       "      <td>0.354339</td>\n",
       "      <td>-0.095672</td>\n",
       "      <td>-0.165272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063625</td>\n",
       "      <td>-0.084838</td>\n",
       "      <td>-0.288882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130664</td>\n",
       "      <td>-0.077664</td>\n",
       "      <td>-0.088354</td>\n",
       "      <td>-0.062221</td>\n",
       "      <td>0.442468</td>\n",
       "      <td>0.169894</td>\n",
       "      <td>-0.284363</td>\n",
       "      <td>-0.215302</td>\n",
       "      <td>-0.255990</td>\n",
       "      <td>0.052130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOE/day</th>\n",
       "      <td>0.398567</td>\n",
       "      <td>0.251417</td>\n",
       "      <td>-0.086489</td>\n",
       "      <td>-0.205998</td>\n",
       "      <td>0.320179</td>\n",
       "      <td>0.178628</td>\n",
       "      <td>-0.063625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095165</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>-0.107957</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>0.210914</td>\n",
       "      <td>-0.201248</td>\n",
       "      <td>0.158794</td>\n",
       "      <td>-0.193804</td>\n",
       "      <td>-0.128521</td>\n",
       "      <td>-0.053470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <td>0.363514</td>\n",
       "      <td>0.266547</td>\n",
       "      <td>-0.098530</td>\n",
       "      <td>-0.212550</td>\n",
       "      <td>0.327667</td>\n",
       "      <td>0.251371</td>\n",
       "      <td>-0.084838</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>0.090180</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>0.155919</td>\n",
       "      <td>0.190710</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>0.125471</td>\n",
       "      <td>-0.208085</td>\n",
       "      <td>-0.116078</td>\n",
       "      <td>-0.056887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <td>-0.132704</td>\n",
       "      <td>0.312178</td>\n",
       "      <td>-0.199589</td>\n",
       "      <td>-0.309855</td>\n",
       "      <td>-0.026833</td>\n",
       "      <td>0.250071</td>\n",
       "      <td>-0.288882</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>0.100226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>0.138967</td>\n",
       "      <td>-0.085042</td>\n",
       "      <td>0.178568</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>-0.100016</td>\n",
       "      <td>0.124158</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>-0.068870</td>\n",
       "      <td>0.169619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water_Depth\\n(meters)</th>\n",
       "      <td>0.244207</td>\n",
       "      <td>-0.077203</td>\n",
       "      <td>0.222506</td>\n",
       "      <td>0.319658</td>\n",
       "      <td>0.344221</td>\n",
       "      <td>0.049218</td>\n",
       "      <td>0.172038</td>\n",
       "      <td>0.223035</td>\n",
       "      <td>0.187506</td>\n",
       "      <td>-0.176706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139634</td>\n",
       "      <td>-0.124342</td>\n",
       "      <td>-0.123762</td>\n",
       "      <td>-0.100715</td>\n",
       "      <td>0.126852</td>\n",
       "      <td>-0.356560</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.175317</td>\n",
       "      <td>-0.021157</td>\n",
       "      <td>-0.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lessons Learned</th>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.047681</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>0.275490</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>-0.032002</td>\n",
       "      <td>0.244526</td>\n",
       "      <td>0.197389</td>\n",
       "      <td>-0.419917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104273</td>\n",
       "      <td>-0.191597</td>\n",
       "      <td>-0.008268</td>\n",
       "      <td>-0.104273</td>\n",
       "      <td>-0.125499</td>\n",
       "      <td>-0.064748</td>\n",
       "      <td>0.140035</td>\n",
       "      <td>-0.133702</td>\n",
       "      <td>0.237075</td>\n",
       "      <td>-0.395750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil/Gas_Prod</th>\n",
       "      <td>-0.048191</td>\n",
       "      <td>-0.150637</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>-0.128031</td>\n",
       "      <td>-0.171474</td>\n",
       "      <td>-0.287018</td>\n",
       "      <td>0.205407</td>\n",
       "      <td>-0.174851</td>\n",
       "      <td>-0.172617</td>\n",
       "      <td>-0.186104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065211</td>\n",
       "      <td>-0.184371</td>\n",
       "      <td>-0.244210</td>\n",
       "      <td>-0.298438</td>\n",
       "      <td>0.196031</td>\n",
       "      <td>0.121130</td>\n",
       "      <td>-0.218331</td>\n",
       "      <td>-0.031591</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>0.005987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEED_Detail</th>\n",
       "      <td>-0.506756</td>\n",
       "      <td>0.110157</td>\n",
       "      <td>-0.106876</td>\n",
       "      <td>0.050715</td>\n",
       "      <td>-0.016790</td>\n",
       "      <td>0.288991</td>\n",
       "      <td>-0.281413</td>\n",
       "      <td>-0.239255</td>\n",
       "      <td>-0.216985</td>\n",
       "      <td>0.251383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106099</td>\n",
       "      <td>-0.136670</td>\n",
       "      <td>0.078284</td>\n",
       "      <td>0.151867</td>\n",
       "      <td>-0.273034</td>\n",
       "      <td>-0.074224</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>0.306415</td>\n",
       "      <td>-0.337098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_AFRICA</th>\n",
       "      <td>0.063297</td>\n",
       "      <td>0.079744</td>\n",
       "      <td>-0.055096</td>\n",
       "      <td>-0.090627</td>\n",
       "      <td>-0.204161</td>\n",
       "      <td>0.113743</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.202309</td>\n",
       "      <td>0.230242</td>\n",
       "      <td>-0.151101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047571</td>\n",
       "      <td>-0.084495</td>\n",
       "      <td>0.087566</td>\n",
       "      <td>-0.047571</td>\n",
       "      <td>0.156377</td>\n",
       "      <td>0.100065</td>\n",
       "      <td>-0.217410</td>\n",
       "      <td>-0.164609</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>-0.110787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_AUST/NZ</th>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.023825</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>0.117909</td>\n",
       "      <td>0.110042</td>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.247790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020332</td>\n",
       "      <td>-0.066786</td>\n",
       "      <td>-0.028872</td>\n",
       "      <td>0.399864</td>\n",
       "      <td>0.050025</td>\n",
       "      <td>-0.059218</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>-0.070354</td>\n",
       "      <td>-0.083650</td>\n",
       "      <td>-0.056653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_BRAZ</th>\n",
       "      <td>0.585309</td>\n",
       "      <td>-0.148968</td>\n",
       "      <td>0.221929</td>\n",
       "      <td>0.298094</td>\n",
       "      <td>0.324549</td>\n",
       "      <td>-0.238490</td>\n",
       "      <td>0.460394</td>\n",
       "      <td>0.214246</td>\n",
       "      <td>0.192703</td>\n",
       "      <td>-0.322095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152886</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.075512</td>\n",
       "      <td>-0.053178</td>\n",
       "      <td>0.341059</td>\n",
       "      <td>-0.154881</td>\n",
       "      <td>-0.033755</td>\n",
       "      <td>-0.184009</td>\n",
       "      <td>-0.162264</td>\n",
       "      <td>0.122347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_CAN</th>\n",
       "      <td>-0.060250</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>-0.057002</td>\n",
       "      <td>-0.141579</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>-0.071785</td>\n",
       "      <td>-0.088354</td>\n",
       "      <td>-0.007827</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>0.253567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.037921</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>0.114312</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.052762</td>\n",
       "      <td>-0.039948</td>\n",
       "      <td>-0.047497</td>\n",
       "      <td>0.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_GOM</th>\n",
       "      <td>-0.605302</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>-0.073078</td>\n",
       "      <td>-0.153104</td>\n",
       "      <td>-0.058325</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>-0.313059</td>\n",
       "      <td>-0.271586</td>\n",
       "      <td>-0.266547</td>\n",
       "      <td>0.151864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>0.065715</td>\n",
       "      <td>-0.065949</td>\n",
       "      <td>-0.046443</td>\n",
       "      <td>-0.537045</td>\n",
       "      <td>-0.135266</td>\n",
       "      <td>0.068937</td>\n",
       "      <td>0.536060</td>\n",
       "      <td>0.416448</td>\n",
       "      <td>-0.154001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_NE</th>\n",
       "      <td>-0.177388</td>\n",
       "      <td>-0.055886</td>\n",
       "      <td>-0.130526</td>\n",
       "      <td>-0.143854</td>\n",
       "      <td>0.059391</td>\n",
       "      <td>0.172412</td>\n",
       "      <td>-0.149862</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>0.233428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038356</td>\n",
       "      <td>0.120683</td>\n",
       "      <td>-0.054465</td>\n",
       "      <td>-0.038356</td>\n",
       "      <td>-0.070869</td>\n",
       "      <td>0.161688</td>\n",
       "      <td>0.269603</td>\n",
       "      <td>-0.132721</td>\n",
       "      <td>-0.157803</td>\n",
       "      <td>0.128258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_SEA</th>\n",
       "      <td>0.010059</td>\n",
       "      <td>-0.106652</td>\n",
       "      <td>0.055674</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>-0.172536</td>\n",
       "      <td>-0.131407</td>\n",
       "      <td>0.029448</td>\n",
       "      <td>-0.166309</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.050408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>0.042779</td>\n",
       "      <td>0.226963</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>-0.029841</td>\n",
       "      <td>0.198276</td>\n",
       "      <td>-0.108218</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>-0.097420</td>\n",
       "      <td>-0.097734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_SEA CH</th>\n",
       "      <td>0.161838</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>-0.081282</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>-0.214925</td>\n",
       "      <td>-0.042880</td>\n",
       "      <td>-0.125988</td>\n",
       "      <td>-0.127678</td>\n",
       "      <td>-0.139501</td>\n",
       "      <td>-0.086778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016462</td>\n",
       "      <td>-0.054074</td>\n",
       "      <td>-0.023376</td>\n",
       "      <td>-0.016462</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>-0.047946</td>\n",
       "      <td>0.054337</td>\n",
       "      <td>-0.056963</td>\n",
       "      <td>-0.067729</td>\n",
       "      <td>0.251215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company (NOC, IOC, OC)_IOC</th>\n",
       "      <td>-0.189223</td>\n",
       "      <td>0.156703</td>\n",
       "      <td>-0.077610</td>\n",
       "      <td>-0.135951</td>\n",
       "      <td>-0.066622</td>\n",
       "      <td>0.210885</td>\n",
       "      <td>-0.096989</td>\n",
       "      <td>0.091770</td>\n",
       "      <td>0.177264</td>\n",
       "      <td>0.176469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>-0.131658</td>\n",
       "      <td>0.020925</td>\n",
       "      <td>0.106099</td>\n",
       "      <td>-0.063670</td>\n",
       "      <td>0.175967</td>\n",
       "      <td>-0.211019</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>0.135804</td>\n",
       "      <td>-0.116559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company (NOC, IOC, OC)_NOC</th>\n",
       "      <td>0.524259</td>\n",
       "      <td>-0.140367</td>\n",
       "      <td>0.173004</td>\n",
       "      <td>0.293720</td>\n",
       "      <td>0.184356</td>\n",
       "      <td>-0.277639</td>\n",
       "      <td>0.341772</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>-0.426494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138263</td>\n",
       "      <td>-0.063686</td>\n",
       "      <td>-0.083498</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>0.333891</td>\n",
       "      <td>-0.099516</td>\n",
       "      <td>-0.018561</td>\n",
       "      <td>-0.203469</td>\n",
       "      <td>-0.187870</td>\n",
       "      <td>0.200758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company (NOC, IOC, OC)_OC</th>\n",
       "      <td>-0.325489</td>\n",
       "      <td>-0.029106</td>\n",
       "      <td>-0.090783</td>\n",
       "      <td>-0.149537</td>\n",
       "      <td>-0.114369</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>-0.241099</td>\n",
       "      <td>-0.207873</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>0.240088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056544</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>0.061940</td>\n",
       "      <td>-0.056544</td>\n",
       "      <td>-0.269615</td>\n",
       "      <td>-0.091753</td>\n",
       "      <td>0.250214</td>\n",
       "      <td>0.182444</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>-0.076295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract (EPC, CL, PS, TK)_CL</th>\n",
       "      <td>0.266944</td>\n",
       "      <td>0.160706</td>\n",
       "      <td>-0.138903</td>\n",
       "      <td>0.201578</td>\n",
       "      <td>0.498741</td>\n",
       "      <td>-0.091037</td>\n",
       "      <td>0.148754</td>\n",
       "      <td>0.126720</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>-0.153653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.092407</td>\n",
       "      <td>-0.039948</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>0.221464</td>\n",
       "      <td>-0.081936</td>\n",
       "      <td>-0.048052</td>\n",
       "      <td>-0.097345</td>\n",
       "      <td>-0.115742</td>\n",
       "      <td>0.150356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract (EPC, CL, PS, TK)_EPC</th>\n",
       "      <td>-0.297089</td>\n",
       "      <td>-0.135498</td>\n",
       "      <td>0.095772</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>-0.266003</td>\n",
       "      <td>0.145243</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>-0.148928</td>\n",
       "      <td>-0.126369</td>\n",
       "      <td>0.037304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194149</td>\n",
       "      <td>-0.637729</td>\n",
       "      <td>0.059463</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>-0.159687</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>-0.077839</td>\n",
       "      <td>0.172283</td>\n",
       "      <td>-0.185532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract (EPC, CL, PS, TK)_PS</th>\n",
       "      <td>0.110515</td>\n",
       "      <td>-0.175055</td>\n",
       "      <td>0.196888</td>\n",
       "      <td>0.130882</td>\n",
       "      <td>-0.067532</td>\n",
       "      <td>-0.046328</td>\n",
       "      <td>0.130664</td>\n",
       "      <td>-0.095165</td>\n",
       "      <td>-0.101011</td>\n",
       "      <td>-0.093954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026705</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.008130</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>-0.037156</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>0.083485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract (EPC, CL, PS, TK)_TK</th>\n",
       "      <td>0.101773</td>\n",
       "      <td>0.079797</td>\n",
       "      <td>-0.053998</td>\n",
       "      <td>-0.305369</td>\n",
       "      <td>-0.125400</td>\n",
       "      <td>-0.093498</td>\n",
       "      <td>-0.077664</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.090180</td>\n",
       "      <td>0.138967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037921</td>\n",
       "      <td>-0.026705</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.077779</td>\n",
       "      <td>0.046107</td>\n",
       "      <td>0.220097</td>\n",
       "      <td>-0.109870</td>\n",
       "      <td>0.075878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_BARGE</th>\n",
       "      <td>-0.016814</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>-0.057002</td>\n",
       "      <td>0.080996</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>-0.014086</td>\n",
       "      <td>-0.088354</td>\n",
       "      <td>-0.107957</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.085042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.037921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.143410</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.052762</td>\n",
       "      <td>-0.039948</td>\n",
       "      <td>-0.047497</td>\n",
       "      <td>-0.092419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_FLNG</th>\n",
       "      <td>-0.011841</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>-0.040142</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.222290</td>\n",
       "      <td>0.362520</td>\n",
       "      <td>-0.062221</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>0.155919</td>\n",
       "      <td>0.178568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008130</td>\n",
       "      <td>-0.026705</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100993</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>-0.037156</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_FPSO</th>\n",
       "      <td>0.359552</td>\n",
       "      <td>-0.180730</td>\n",
       "      <td>0.162776</td>\n",
       "      <td>0.205602</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>-0.036295</td>\n",
       "      <td>0.442468</td>\n",
       "      <td>0.210914</td>\n",
       "      <td>0.190710</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.143410</td>\n",
       "      <td>-0.100993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.294143</td>\n",
       "      <td>-0.461558</td>\n",
       "      <td>-0.349462</td>\n",
       "      <td>-0.415504</td>\n",
       "      <td>0.112561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_FSO</th>\n",
       "      <td>-0.079032</td>\n",
       "      <td>-0.106652</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>-0.085211</td>\n",
       "      <td>-0.012382</td>\n",
       "      <td>0.169894</td>\n",
       "      <td>-0.201248</td>\n",
       "      <td>-0.177272</td>\n",
       "      <td>-0.100016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>-0.077779</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.023679</td>\n",
       "      <td>-0.294143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.108218</td>\n",
       "      <td>-0.081936</td>\n",
       "      <td>-0.097420</td>\n",
       "      <td>0.158776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_SEMI</th>\n",
       "      <td>0.070150</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>-0.063094</td>\n",
       "      <td>-0.133828</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>-0.284363</td>\n",
       "      <td>0.158794</td>\n",
       "      <td>0.125471</td>\n",
       "      <td>0.124158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037156</td>\n",
       "      <td>0.046107</td>\n",
       "      <td>-0.052762</td>\n",
       "      <td>-0.037156</td>\n",
       "      <td>-0.461558</td>\n",
       "      <td>-0.108218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.128570</td>\n",
       "      <td>-0.152868</td>\n",
       "      <td>0.012574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_SPAR</th>\n",
       "      <td>-0.271910</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>-0.049012</td>\n",
       "      <td>-0.101881</td>\n",
       "      <td>0.044775</td>\n",
       "      <td>-0.215302</td>\n",
       "      <td>-0.193804</td>\n",
       "      <td>-0.208085</td>\n",
       "      <td>0.210689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>0.220097</td>\n",
       "      <td>-0.039948</td>\n",
       "      <td>-0.028132</td>\n",
       "      <td>-0.349462</td>\n",
       "      <td>-0.081936</td>\n",
       "      <td>-0.128570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.115742</td>\n",
       "      <td>0.056902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type Unit_TLP</th>\n",
       "      <td>-0.317194</td>\n",
       "      <td>0.191076</td>\n",
       "      <td>-0.165153</td>\n",
       "      <td>-0.240837</td>\n",
       "      <td>-0.082009</td>\n",
       "      <td>-0.102980</td>\n",
       "      <td>-0.255990</td>\n",
       "      <td>-0.128521</td>\n",
       "      <td>-0.116078</td>\n",
       "      <td>-0.068870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>-0.109870</td>\n",
       "      <td>-0.047497</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>-0.415504</td>\n",
       "      <td>-0.097420</td>\n",
       "      <td>-0.152868</td>\n",
       "      <td>-0.115742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.320287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schedule_Overrun</th>\n",
       "      <td>0.204014</td>\n",
       "      <td>0.116818</td>\n",
       "      <td>-0.084245</td>\n",
       "      <td>0.128776</td>\n",
       "      <td>-0.011339</td>\n",
       "      <td>-0.055486</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>-0.053470</td>\n",
       "      <td>-0.056887</td>\n",
       "      <td>0.169619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083485</td>\n",
       "      <td>0.075878</td>\n",
       "      <td>-0.092419</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.112561</td>\n",
       "      <td>0.158776</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>-0.320287</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Local Content Requirment (H,M,A,L, N)  \\\n",
       "Local Content Requirment (H,M,A,L, N)                               1.000000   \n",
       "Lease/ Own                                                          0.027317   \n",
       "Contract2                                                           0.078185   \n",
       "Contracting Date                                                    0.195892   \n",
       "Planned_Duration                                                    0.222175   \n",
       "Planned_Cost                                                       -0.086451   \n",
       "Hull Type                                                           0.354177   \n",
       "BOE/day                                                             0.398567   \n",
       "Topsides (VL, L, M, S, VS)                                          0.363514   \n",
       "Technology Novelt (H,M,A,L,N)                                      -0.132704   \n",
       "Water_Depth\\n(meters)                                               0.244207   \n",
       "Lessons Learned                                                     0.019401   \n",
       "Oil/Gas_Prod                                                       -0.048191   \n",
       "FEED_Detail                                                        -0.506756   \n",
       "Region_AFRICA                                                       0.063297   \n",
       "Region_AUST/NZ                                                      0.021387   \n",
       "Region_BRAZ                                                         0.585309   \n",
       "Region_CAN                                                         -0.060250   \n",
       "Region_GOM                                                         -0.605302   \n",
       "Region_NE                                                          -0.177388   \n",
       "Region_SEA                                                          0.010059   \n",
       "Region_SEA CH                                                       0.161838   \n",
       "Company (NOC, IOC, OC)_IOC                                         -0.189223   \n",
       "Company (NOC, IOC, OC)_NOC                                          0.524259   \n",
       "Company (NOC, IOC, OC)_OC                                          -0.325489   \n",
       "Contract (EPC, CL, PS, TK)_CL                                       0.266944   \n",
       "Contract (EPC, CL, PS, TK)_EPC                                     -0.297089   \n",
       "Contract (EPC, CL, PS, TK)_PS                                       0.110515   \n",
       "Contract (EPC, CL, PS, TK)_TK                                       0.101773   \n",
       "Type Unit_BARGE                                                    -0.016814   \n",
       "Type Unit_FLNG                                                     -0.011841   \n",
       "Type Unit_FPSO                                                      0.359552   \n",
       "Type Unit_FSO                                                      -0.079032   \n",
       "Type Unit_SEMI                                                      0.070150   \n",
       "Type Unit_SPAR                                                     -0.271910   \n",
       "Type Unit_TLP                                                      -0.317194   \n",
       "Schedule_Overrun                                                    0.204014   \n",
       "\n",
       "                                       Lease/ Own  Contract2  \\\n",
       "Local Content Requirment (H,M,A,L, N)    0.027317   0.078185   \n",
       "Lease/ Own                               1.000000  -0.786215   \n",
       "Contract2                               -0.786215   1.000000   \n",
       "Contracting Date                        -0.236899   0.202845   \n",
       "Planned_Duration                         0.233233  -0.205245   \n",
       "Planned_Cost                             0.165378  -0.151574   \n",
       "Hull Type                               -0.407387   0.305022   \n",
       "BOE/day                                  0.251417  -0.086489   \n",
       "Topsides (VL, L, M, S, VS)               0.266547  -0.098530   \n",
       "Technology Novelt (H,M,A,L,N)            0.312178  -0.199589   \n",
       "Water_Depth\\n(meters)                   -0.077203   0.222506   \n",
       "Lessons Learned                          0.047681   0.017547   \n",
       "Oil/Gas_Prod                            -0.150637   0.056682   \n",
       "FEED_Detail                              0.110157  -0.106876   \n",
       "Region_AFRICA                            0.079744  -0.055096   \n",
       "Region_AUST/NZ                           0.023825   0.047805   \n",
       "Region_BRAZ                             -0.148968   0.221929   \n",
       "Region_CAN                               0.065949  -0.057002   \n",
       "Region_GOM                               0.119309  -0.073078   \n",
       "Region_NE                               -0.055886  -0.130526   \n",
       "Region_SEA                              -0.106652   0.055674   \n",
       "Region_SEA CH                            0.094040  -0.081282   \n",
       "Company (NOC, IOC, OC)_IOC               0.156703  -0.077610   \n",
       "Company (NOC, IOC, OC)_NOC              -0.140367   0.173004   \n",
       "Company (NOC, IOC, OC)_OC               -0.029106  -0.090783   \n",
       "Contract (EPC, CL, PS, TK)_CL            0.160706  -0.138903   \n",
       "Contract (EPC, CL, PS, TK)_EPC          -0.135498   0.095772   \n",
       "Contract (EPC, CL, PS, TK)_PS           -0.175055   0.196888   \n",
       "Contract (EPC, CL, PS, TK)_TK            0.079797  -0.053998   \n",
       "Type Unit_BARGE                          0.065949  -0.057002   \n",
       "Type Unit_FLNG                           0.046443  -0.040142   \n",
       "Type Unit_FPSO                          -0.180730   0.162776   \n",
       "Type Unit_FSO                           -0.106652   0.012527   \n",
       "Type Unit_SEMI                           0.099778  -0.063094   \n",
       "Type Unit_SPAR                           0.021352   0.010222   \n",
       "Type Unit_TLP                            0.191076  -0.165153   \n",
       "Schedule_Overrun                         0.116818  -0.084245   \n",
       "\n",
       "                                       Contracting Date  Planned_Duration  \\\n",
       "Local Content Requirment (H,M,A,L, N)          0.195892          0.222175   \n",
       "Lease/ Own                                    -0.236899          0.233233   \n",
       "Contract2                                      0.202845         -0.205245   \n",
       "Contracting Date                               1.000000          0.351832   \n",
       "Planned_Duration                               0.351832          1.000000   \n",
       "Planned_Cost                                   0.254975          0.349849   \n",
       "Hull Type                                      0.354339         -0.095672   \n",
       "BOE/day                                       -0.205998          0.320179   \n",
       "Topsides (VL, L, M, S, VS)                    -0.212550          0.327667   \n",
       "Technology Novelt (H,M,A,L,N)                 -0.309855         -0.026833   \n",
       "Water_Depth\\n(meters)                          0.319658          0.344221   \n",
       "Lessons Learned                                0.126458          0.275490   \n",
       "Oil/Gas_Prod                                  -0.128031         -0.171474   \n",
       "FEED_Detail                                    0.050715         -0.016790   \n",
       "Region_AFRICA                                 -0.090627         -0.204161   \n",
       "Region_AUST/NZ                                 0.117909          0.110042   \n",
       "Region_BRAZ                                    0.298094          0.324549   \n",
       "Region_CAN                                    -0.141579          0.010671   \n",
       "Region_GOM                                    -0.153104         -0.058325   \n",
       "Region_NE                                     -0.143854          0.059391   \n",
       "Region_SEA                                     0.019117         -0.172536   \n",
       "Region_SEA CH                                  0.050627         -0.214925   \n",
       "Company (NOC, IOC, OC)_IOC                    -0.135951         -0.066622   \n",
       "Company (NOC, IOC, OC)_NOC                     0.293720          0.184356   \n",
       "Company (NOC, IOC, OC)_OC                     -0.149537         -0.114369   \n",
       "Contract (EPC, CL, PS, TK)_CL                  0.201578          0.498741   \n",
       "Contract (EPC, CL, PS, TK)_EPC                 0.036986         -0.266003   \n",
       "Contract (EPC, CL, PS, TK)_PS                  0.130882         -0.067532   \n",
       "Contract (EPC, CL, PS, TK)_TK                 -0.305369         -0.125400   \n",
       "Type Unit_BARGE                                0.080996         -0.039374   \n",
       "Type Unit_FLNG                                 0.080417          0.222290   \n",
       "Type Unit_FPSO                                 0.205602          0.068198   \n",
       "Type Unit_FSO                                  0.081709         -0.085211   \n",
       "Type Unit_SEMI                                -0.133828          0.079034   \n",
       "Type Unit_SPAR                                -0.049012         -0.101881   \n",
       "Type Unit_TLP                                 -0.240837         -0.082009   \n",
       "Schedule_Overrun                               0.128776         -0.011339   \n",
       "\n",
       "                                       Planned_Cost  Hull Type   BOE/day  \\\n",
       "Local Content Requirment (H,M,A,L, N)     -0.086451   0.354177  0.398567   \n",
       "Lease/ Own                                 0.165378  -0.407387  0.251417   \n",
       "Contract2                                 -0.151574   0.305022 -0.086489   \n",
       "Contracting Date                           0.254975   0.354339 -0.205998   \n",
       "Planned_Duration                           0.349849  -0.095672  0.320179   \n",
       "Planned_Cost                               1.000000  -0.165272  0.178628   \n",
       "Hull Type                                 -0.165272   1.000000 -0.063625   \n",
       "BOE/day                                    0.178628  -0.063625  1.000000   \n",
       "Topsides (VL, L, M, S, VS)                 0.251371  -0.084838  0.945819   \n",
       "Technology Novelt (H,M,A,L,N)              0.250071  -0.288882  0.056127   \n",
       "Water_Depth\\n(meters)                      0.049218   0.172038  0.223035   \n",
       "Lessons Learned                            0.016630  -0.032002  0.244526   \n",
       "Oil/Gas_Prod                              -0.287018   0.205407 -0.174851   \n",
       "FEED_Detail                                0.288991  -0.281413 -0.239255   \n",
       "Region_AFRICA                              0.113743   0.012136  0.202309   \n",
       "Region_AUST/NZ                             0.104509   0.005187 -0.001762   \n",
       "Region_BRAZ                               -0.238490   0.460394  0.214246   \n",
       "Region_CAN                                -0.071785  -0.088354 -0.007827   \n",
       "Region_GOM                                 0.053516  -0.313059 -0.271586   \n",
       "Region_NE                                  0.172412  -0.149862 -0.005291   \n",
       "Region_SEA                                -0.131407   0.029448 -0.166309   \n",
       "Region_SEA CH                             -0.042880  -0.125988 -0.127678   \n",
       "Company (NOC, IOC, OC)_IOC                 0.210885  -0.096989  0.091770   \n",
       "Company (NOC, IOC, OC)_NOC                -0.277639   0.341772  0.105516   \n",
       "Company (NOC, IOC, OC)_OC                  0.051038  -0.241099 -0.207873   \n",
       "Contract (EPC, CL, PS, TK)_CL             -0.091037   0.148754  0.126720   \n",
       "Contract (EPC, CL, PS, TK)_EPC             0.145243  -0.085947 -0.148928   \n",
       "Contract (EPC, CL, PS, TK)_PS             -0.046328   0.130664 -0.095165   \n",
       "Contract (EPC, CL, PS, TK)_TK             -0.093498  -0.077664  0.107884   \n",
       "Type Unit_BARGE                           -0.014086  -0.088354 -0.107957   \n",
       "Type Unit_FLNG                             0.362520  -0.062221 -0.007461   \n",
       "Type Unit_FPSO                            -0.036295   0.442468  0.210914   \n",
       "Type Unit_FSO                             -0.012382   0.169894 -0.201248   \n",
       "Type Unit_SEMI                             0.032005  -0.284363  0.158794   \n",
       "Type Unit_SPAR                             0.044775  -0.215302 -0.193804   \n",
       "Type Unit_TLP                             -0.102980  -0.255990 -0.128521   \n",
       "Schedule_Overrun                          -0.055486   0.052130 -0.053470   \n",
       "\n",
       "                                       Topsides (VL, L, M, S, VS)  \\\n",
       "Local Content Requirment (H,M,A,L, N)                    0.363514   \n",
       "Lease/ Own                                               0.266547   \n",
       "Contract2                                               -0.098530   \n",
       "Contracting Date                                        -0.212550   \n",
       "Planned_Duration                                         0.327667   \n",
       "Planned_Cost                                             0.251371   \n",
       "Hull Type                                               -0.084838   \n",
       "BOE/day                                                  0.945819   \n",
       "Topsides (VL, L, M, S, VS)                               1.000000   \n",
       "Technology Novelt (H,M,A,L,N)                            0.100226   \n",
       "Water_Depth\\n(meters)                                    0.187506   \n",
       "Lessons Learned                                          0.197389   \n",
       "Oil/Gas_Prod                                            -0.172617   \n",
       "FEED_Detail                                             -0.216985   \n",
       "Region_AFRICA                                            0.230242   \n",
       "Region_AUST/NZ                                           0.015114   \n",
       "Region_BRAZ                                              0.192703   \n",
       "Region_CAN                                              -0.006620   \n",
       "Region_GOM                                              -0.266547   \n",
       "Region_NE                                               -0.014020   \n",
       "Region_SEA                                              -0.177272   \n",
       "Region_SEA CH                                           -0.139501   \n",
       "Company (NOC, IOC, OC)_IOC                               0.177264   \n",
       "Company (NOC, IOC, OC)_NOC                               0.073006   \n",
       "Company (NOC, IOC, OC)_OC                               -0.268554   \n",
       "Contract (EPC, CL, PS, TK)_CL                            0.115205   \n",
       "Contract (EPC, CL, PS, TK)_EPC                          -0.126369   \n",
       "Contract (EPC, CL, PS, TK)_PS                           -0.101011   \n",
       "Contract (EPC, CL, PS, TK)_TK                            0.090180   \n",
       "Type Unit_BARGE                                         -0.097830   \n",
       "Type Unit_FLNG                                           0.155919   \n",
       "Type Unit_FPSO                                           0.190710   \n",
       "Type Unit_FSO                                           -0.177272   \n",
       "Type Unit_SEMI                                           0.125471   \n",
       "Type Unit_SPAR                                          -0.208085   \n",
       "Type Unit_TLP                                           -0.116078   \n",
       "Schedule_Overrun                                        -0.056887   \n",
       "\n",
       "                                       Technology Novelt (H,M,A,L,N)  ...  \\\n",
       "Local Content Requirment (H,M,A,L, N)                      -0.132704  ...   \n",
       "Lease/ Own                                                  0.312178  ...   \n",
       "Contract2                                                  -0.199589  ...   \n",
       "Contracting Date                                           -0.309855  ...   \n",
       "Planned_Duration                                           -0.026833  ...   \n",
       "Planned_Cost                                                0.250071  ...   \n",
       "Hull Type                                                  -0.288882  ...   \n",
       "BOE/day                                                     0.056127  ...   \n",
       "Topsides (VL, L, M, S, VS)                                  0.100226  ...   \n",
       "Technology Novelt (H,M,A,L,N)                               1.000000  ...   \n",
       "Water_Depth\\n(meters)                                      -0.176706  ...   \n",
       "Lessons Learned                                            -0.419917  ...   \n",
       "Oil/Gas_Prod                                               -0.186104  ...   \n",
       "FEED_Detail                                                 0.251383  ...   \n",
       "Region_AFRICA                                              -0.151101  ...   \n",
       "Region_AUST/NZ                                              0.247790  ...   \n",
       "Region_BRAZ                                                -0.322095  ...   \n",
       "Region_CAN                                                  0.253567  ...   \n",
       "Region_GOM                                                  0.151864  ...   \n",
       "Region_NE                                                   0.233428  ...   \n",
       "Region_SEA                                                 -0.050408  ...   \n",
       "Region_SEA CH                                              -0.086778  ...   \n",
       "Company (NOC, IOC, OC)_IOC                                  0.176469  ...   \n",
       "Company (NOC, IOC, OC)_NOC                                 -0.426494  ...   \n",
       "Company (NOC, IOC, OC)_OC                                   0.240088  ...   \n",
       "Contract (EPC, CL, PS, TK)_CL                              -0.153653  ...   \n",
       "Contract (EPC, CL, PS, TK)_EPC                              0.037304  ...   \n",
       "Contract (EPC, CL, PS, TK)_PS                              -0.093954  ...   \n",
       "Contract (EPC, CL, PS, TK)_TK                               0.138967  ...   \n",
       "Type Unit_BARGE                                            -0.085042  ...   \n",
       "Type Unit_FLNG                                              0.178568  ...   \n",
       "Type Unit_FPSO                                             -0.124536  ...   \n",
       "Type Unit_FSO                                              -0.100016  ...   \n",
       "Type Unit_SEMI                                              0.124158  ...   \n",
       "Type Unit_SPAR                                              0.210689  ...   \n",
       "Type Unit_TLP                                              -0.068870  ...   \n",
       "Schedule_Overrun                                            0.169619  ...   \n",
       "\n",
       "                                       Contract (EPC, CL, PS, TK)_PS  \\\n",
       "Local Content Requirment (H,M,A,L, N)                       0.110515   \n",
       "Lease/ Own                                                 -0.175055   \n",
       "Contract2                                                   0.196888   \n",
       "Contracting Date                                            0.130882   \n",
       "Planned_Duration                                           -0.067532   \n",
       "Planned_Cost                                               -0.046328   \n",
       "Hull Type                                                   0.130664   \n",
       "BOE/day                                                    -0.095165   \n",
       "Topsides (VL, L, M, S, VS)                                 -0.101011   \n",
       "Technology Novelt (H,M,A,L,N)                              -0.093954   \n",
       "Water_Depth\\n(meters)                                       0.139634   \n",
       "Lessons Learned                                            -0.104273   \n",
       "Oil/Gas_Prod                                               -0.065211   \n",
       "FEED_Detail                                                -0.106099   \n",
       "Region_AFRICA                                              -0.047571   \n",
       "Region_AUST/NZ                                             -0.020332   \n",
       "Region_BRAZ                                                 0.152886   \n",
       "Region_CAN                                                 -0.011545   \n",
       "Region_GOM                                                 -0.046443   \n",
       "Region_NE                                                  -0.038356   \n",
       "Region_SEA                                                 -0.023679   \n",
       "Region_SEA CH                                              -0.016462   \n",
       "Company (NOC, IOC, OC)_IOC                                 -0.076627   \n",
       "Company (NOC, IOC, OC)_NOC                                  0.138263   \n",
       "Company (NOC, IOC, OC)_OC                                  -0.056544   \n",
       "Contract (EPC, CL, PS, TK)_CL                              -0.028132   \n",
       "Contract (EPC, CL, PS, TK)_EPC                             -0.194149   \n",
       "Contract (EPC, CL, PS, TK)_PS                               1.000000   \n",
       "Contract (EPC, CL, PS, TK)_TK                              -0.026705   \n",
       "Type Unit_BARGE                                            -0.011545   \n",
       "Type Unit_FLNG                                             -0.008130   \n",
       "Type Unit_FPSO                                              0.080502   \n",
       "Type Unit_FSO                                              -0.023679   \n",
       "Type Unit_SEMI                                             -0.037156   \n",
       "Type Unit_SPAR                                             -0.028132   \n",
       "Type Unit_TLP                                              -0.033449   \n",
       "Schedule_Overrun                                            0.083485   \n",
       "\n",
       "                                       Contract (EPC, CL, PS, TK)_TK  \\\n",
       "Local Content Requirment (H,M,A,L, N)                       0.101773   \n",
       "Lease/ Own                                                  0.079797   \n",
       "Contract2                                                  -0.053998   \n",
       "Contracting Date                                           -0.305369   \n",
       "Planned_Duration                                           -0.125400   \n",
       "Planned_Cost                                               -0.093498   \n",
       "Hull Type                                                  -0.077664   \n",
       "BOE/day                                                     0.107884   \n",
       "Topsides (VL, L, M, S, VS)                                  0.090180   \n",
       "Technology Novelt (H,M,A,L,N)                               0.138967   \n",
       "Water_Depth\\n(meters)                                      -0.124342   \n",
       "Lessons Learned                                            -0.191597   \n",
       "Oil/Gas_Prod                                               -0.184371   \n",
       "FEED_Detail                                                -0.136670   \n",
       "Region_AFRICA                                              -0.084495   \n",
       "Region_AUST/NZ                                             -0.066786   \n",
       "Region_BRAZ                                                -0.039302   \n",
       "Region_CAN                                                 -0.037921   \n",
       "Region_GOM                                                  0.065715   \n",
       "Region_NE                                                   0.120683   \n",
       "Region_SEA                                                  0.042779   \n",
       "Region_SEA CH                                              -0.054074   \n",
       "Company (NOC, IOC, OC)_IOC                                 -0.131658   \n",
       "Company (NOC, IOC, OC)_NOC                                 -0.063686   \n",
       "Company (NOC, IOC, OC)_OC                                   0.209081   \n",
       "Contract (EPC, CL, PS, TK)_CL                              -0.092407   \n",
       "Contract (EPC, CL, PS, TK)_EPC                             -0.637729   \n",
       "Contract (EPC, CL, PS, TK)_PS                              -0.026705   \n",
       "Contract (EPC, CL, PS, TK)_TK                               1.000000   \n",
       "Type Unit_BARGE                                            -0.037921   \n",
       "Type Unit_FLNG                                             -0.026705   \n",
       "Type Unit_FPSO                                             -0.033654   \n",
       "Type Unit_FSO                                              -0.077779   \n",
       "Type Unit_SEMI                                              0.046107   \n",
       "Type Unit_SPAR                                              0.220097   \n",
       "Type Unit_TLP                                              -0.109870   \n",
       "Schedule_Overrun                                            0.075878   \n",
       "\n",
       "                                       Type Unit_BARGE  Type Unit_FLNG  \\\n",
       "Local Content Requirment (H,M,A,L, N)        -0.016814       -0.011841   \n",
       "Lease/ Own                                    0.065949        0.046443   \n",
       "Contract2                                    -0.057002       -0.040142   \n",
       "Contracting Date                              0.080996        0.080417   \n",
       "Planned_Duration                             -0.039374        0.222290   \n",
       "Planned_Cost                                 -0.014086        0.362520   \n",
       "Hull Type                                    -0.088354       -0.062221   \n",
       "BOE/day                                      -0.107957       -0.007461   \n",
       "Topsides (VL, L, M, S, VS)                   -0.097830        0.155919   \n",
       "Technology Novelt (H,M,A,L,N)                -0.085042        0.178568   \n",
       "Water_Depth\\n(meters)                        -0.123762       -0.100715   \n",
       "Lessons Learned                              -0.008268       -0.104273   \n",
       "Oil/Gas_Prod                                 -0.244210       -0.298438   \n",
       "FEED_Detail                                   0.078284        0.151867   \n",
       "Region_AFRICA                                 0.087566       -0.047571   \n",
       "Region_AUST/NZ                               -0.028872        0.399864   \n",
       "Region_BRAZ                                  -0.075512       -0.053178   \n",
       "Region_CAN                                   -0.016393       -0.011545   \n",
       "Region_GOM                                   -0.065949       -0.046443   \n",
       "Region_NE                                    -0.054465       -0.038356   \n",
       "Region_SEA                                    0.226963       -0.023679   \n",
       "Region_SEA CH                                -0.023376       -0.016462   \n",
       "Company (NOC, IOC, OC)_IOC                    0.020925        0.106099   \n",
       "Company (NOC, IOC, OC)_NOC                   -0.083498       -0.058802   \n",
       "Company (NOC, IOC, OC)_OC                     0.061940       -0.056544   \n",
       "Contract (EPC, CL, PS, TK)_CL                -0.039948       -0.028132   \n",
       "Contract (EPC, CL, PS, TK)_EPC                0.059463        0.041875   \n",
       "Contract (EPC, CL, PS, TK)_PS                -0.011545       -0.008130   \n",
       "Contract (EPC, CL, PS, TK)_TK                -0.037921       -0.026705   \n",
       "Type Unit_BARGE                               1.000000       -0.011545   \n",
       "Type Unit_FLNG                               -0.011545        1.000000   \n",
       "Type Unit_FPSO                               -0.143410       -0.100993   \n",
       "Type Unit_FSO                                -0.033624       -0.023679   \n",
       "Type Unit_SEMI                               -0.052762       -0.037156   \n",
       "Type Unit_SPAR                               -0.039948       -0.028132   \n",
       "Type Unit_TLP                                -0.047497       -0.033449   \n",
       "Schedule_Overrun                             -0.092419        0.006143   \n",
       "\n",
       "                                       Type Unit_FPSO  Type Unit_FSO  \\\n",
       "Local Content Requirment (H,M,A,L, N)        0.359552      -0.079032   \n",
       "Lease/ Own                                  -0.180730      -0.106652   \n",
       "Contract2                                    0.162776       0.012527   \n",
       "Contracting Date                             0.205602       0.081709   \n",
       "Planned_Duration                             0.068198      -0.085211   \n",
       "Planned_Cost                                -0.036295      -0.012382   \n",
       "Hull Type                                    0.442468       0.169894   \n",
       "BOE/day                                      0.210914      -0.201248   \n",
       "Topsides (VL, L, M, S, VS)                   0.190710      -0.177272   \n",
       "Technology Novelt (H,M,A,L,N)               -0.124536      -0.100016   \n",
       "Water_Depth\\n(meters)                        0.126852      -0.356560   \n",
       "Lessons Learned                             -0.125499      -0.064748   \n",
       "Oil/Gas_Prod                                 0.196031       0.121130   \n",
       "FEED_Detail                                 -0.273034      -0.074224   \n",
       "Region_AFRICA                                0.156377       0.100065   \n",
       "Region_AUST/NZ                               0.050025      -0.059218   \n",
       "Region_BRAZ                                  0.341059      -0.154881   \n",
       "Region_CAN                                   0.114312      -0.033624   \n",
       "Region_GOM                                  -0.537045      -0.135266   \n",
       "Region_NE                                   -0.070869       0.161688   \n",
       "Region_SEA                                  -0.029841       0.198276   \n",
       "Region_SEA CH                                0.071129      -0.047946   \n",
       "Company (NOC, IOC, OC)_IOC                  -0.063670       0.175967   \n",
       "Company (NOC, IOC, OC)_NOC                   0.333891      -0.099516   \n",
       "Company (NOC, IOC, OC)_OC                   -0.269615      -0.091753   \n",
       "Contract (EPC, CL, PS, TK)_CL                0.221464      -0.081936   \n",
       "Contract (EPC, CL, PS, TK)_EPC              -0.159687       0.121963   \n",
       "Contract (EPC, CL, PS, TK)_PS                0.080502      -0.023679   \n",
       "Contract (EPC, CL, PS, TK)_TK               -0.033654      -0.077779   \n",
       "Type Unit_BARGE                             -0.143410      -0.033624   \n",
       "Type Unit_FLNG                              -0.100993      -0.023679   \n",
       "Type Unit_FPSO                               1.000000      -0.294143   \n",
       "Type Unit_FSO                               -0.294143       1.000000   \n",
       "Type Unit_SEMI                              -0.461558      -0.108218   \n",
       "Type Unit_SPAR                              -0.349462      -0.081936   \n",
       "Type Unit_TLP                               -0.415504      -0.097420   \n",
       "Schedule_Overrun                             0.112561       0.158776   \n",
       "\n",
       "                                       Type Unit_SEMI  Type Unit_SPAR  \\\n",
       "Local Content Requirment (H,M,A,L, N)        0.070150       -0.271910   \n",
       "Lease/ Own                                   0.099778        0.021352   \n",
       "Contract2                                   -0.063094        0.010222   \n",
       "Contracting Date                            -0.133828       -0.049012   \n",
       "Planned_Duration                             0.079034       -0.101881   \n",
       "Planned_Cost                                 0.032005        0.044775   \n",
       "Hull Type                                   -0.284363       -0.215302   \n",
       "BOE/day                                      0.158794       -0.193804   \n",
       "Topsides (VL, L, M, S, VS)                   0.125471       -0.208085   \n",
       "Technology Novelt (H,M,A,L,N)                0.124158        0.210689   \n",
       "Water_Depth\\n(meters)                        0.017676        0.175317   \n",
       "Lessons Learned                              0.140035       -0.133702   \n",
       "Oil/Gas_Prod                                -0.218331       -0.031591   \n",
       "FEED_Detail                                  0.039087        0.058898   \n",
       "Region_AFRICA                               -0.217410       -0.164609   \n",
       "Region_AUST/NZ                               0.013766       -0.070354   \n",
       "Region_BRAZ                                 -0.033755       -0.184009   \n",
       "Region_CAN                                  -0.052762       -0.039948   \n",
       "Region_GOM                                   0.068937        0.536060   \n",
       "Region_NE                                    0.269603       -0.132721   \n",
       "Region_SEA                                  -0.108218        0.033519   \n",
       "Region_SEA CH                                0.054337       -0.056963   \n",
       "Company (NOC, IOC, OC)_IOC                  -0.211019        0.022250   \n",
       "Company (NOC, IOC, OC)_NOC                  -0.018561       -0.203469   \n",
       "Company (NOC, IOC, OC)_OC                    0.250214        0.182444   \n",
       "Contract (EPC, CL, PS, TK)_CL               -0.048052       -0.097345   \n",
       "Contract (EPC, CL, PS, TK)_EPC               0.011599       -0.077839   \n",
       "Contract (EPC, CL, PS, TK)_PS               -0.037156       -0.028132   \n",
       "Contract (EPC, CL, PS, TK)_TK                0.046107        0.220097   \n",
       "Type Unit_BARGE                             -0.052762       -0.039948   \n",
       "Type Unit_FLNG                              -0.037156       -0.028132   \n",
       "Type Unit_FPSO                              -0.461558       -0.349462   \n",
       "Type Unit_FSO                               -0.108218       -0.081936   \n",
       "Type Unit_SEMI                               1.000000       -0.128570   \n",
       "Type Unit_SPAR                              -0.128570        1.000000   \n",
       "Type Unit_TLP                               -0.152868       -0.115742   \n",
       "Schedule_Overrun                             0.012574        0.056902   \n",
       "\n",
       "                                       Type Unit_TLP  Schedule_Overrun  \n",
       "Local Content Requirment (H,M,A,L, N)      -0.317194          0.204014  \n",
       "Lease/ Own                                  0.191076          0.116818  \n",
       "Contract2                                  -0.165153         -0.084245  \n",
       "Contracting Date                           -0.240837          0.128776  \n",
       "Planned_Duration                           -0.082009         -0.011339  \n",
       "Planned_Cost                               -0.102980         -0.055486  \n",
       "Hull Type                                  -0.255990          0.052130  \n",
       "BOE/day                                    -0.128521         -0.053470  \n",
       "Topsides (VL, L, M, S, VS)                 -0.116078         -0.056887  \n",
       "Technology Novelt (H,M,A,L,N)              -0.068870          0.169619  \n",
       "Water_Depth\\n(meters)                      -0.021157         -0.062700  \n",
       "Lessons Learned                             0.237075         -0.395750  \n",
       "Oil/Gas_Prod                                0.049683          0.005987  \n",
       "FEED_Detail                                 0.306415         -0.337098  \n",
       "Region_AFRICA                               0.043976         -0.110787  \n",
       "Region_AUST/NZ                             -0.083650         -0.056653  \n",
       "Region_BRAZ                                -0.162264          0.122347  \n",
       "Region_CAN                                 -0.047497          0.003650  \n",
       "Region_GOM                                  0.416448         -0.154001  \n",
       "Region_NE                                  -0.157803          0.128258  \n",
       "Region_SEA                                 -0.097420         -0.097734  \n",
       "Region_SEA CH                              -0.067729          0.251215  \n",
       "Company (NOC, IOC, OC)_IOC                  0.135804         -0.116559  \n",
       "Company (NOC, IOC, OC)_NOC                 -0.187870          0.200758  \n",
       "Company (NOC, IOC, OC)_OC                   0.042096         -0.076295  \n",
       "Contract (EPC, CL, PS, TK)_CL              -0.115742          0.150356  \n",
       "Contract (EPC, CL, PS, TK)_EPC              0.172283         -0.185532  \n",
       "Contract (EPC, CL, PS, TK)_PS              -0.033449          0.083485  \n",
       "Contract (EPC, CL, PS, TK)_TK              -0.109870          0.075878  \n",
       "Type Unit_BARGE                            -0.047497         -0.092419  \n",
       "Type Unit_FLNG                             -0.033449          0.006143  \n",
       "Type Unit_FPSO                             -0.415504          0.112561  \n",
       "Type Unit_FSO                              -0.097420          0.158776  \n",
       "Type Unit_SEMI                             -0.152868          0.012574  \n",
       "Type Unit_SPAR                             -0.115742          0.056902  \n",
       "Type Unit_TLP                               1.000000         -0.320287  \n",
       "Schedule_Overrun                           -0.320287          1.000000  \n",
       "\n",
       "[37 rows x 37 columns]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  2.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.76      ],\n",
       "       [ 5.        ,  2.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.47104247],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.28676471],\n",
       "       ...,\n",
       "       [ 1.        ,  2.        ,  1.        , ...,  0.        ,\n",
       "         1.        , -0.12562396],\n",
       "       [ 1.        ,  2.        ,  1.        , ...,  0.        ,\n",
       "         1.        , -0.08173077],\n",
       "       [ 1.        ,  2.        ,  1.        , ...,  0.        ,\n",
       "         1.        ,  0.01530055]])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset[:,1:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0000e+00, 1.0000e+00, 1.0439e+04, ..., 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 4.3500e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [1.0000e+00, 1.0000e+00, 2.2400e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [2.0000e+00, 1.0000e+00, 7.7290e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 2.3980e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 1.8850e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = dataset[:,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76      ,  0.47104247,  0.28676471, -0.14387464, -0.0221328 ,\n",
       "        0.11406844,  0.24315837,  0.00795372,  0.01071975,  0.52126367,\n",
       "        0.44773358,  0.54646206, -0.14005602, -0.10163112, -0.08406524,\n",
       "        0.19039146,  0.29703763,  0.0365408 ,  0.06751055,  0.01556777,\n",
       "        0.11367673,  0.07214121,  0.70764763,  0.28714734,  0.1933395 ,\n",
       "        0.0055918 ,  0.37636259,  0.00197239,  0.14664804,  0.66350711,\n",
       "        0.4382786 ,  0.36748466,  0.52992446,  0.36491228,  0.30536913,\n",
       "        0.25515947,  0.2090209 ,  0.33906922,  0.42784513,  0.18138425,\n",
       "        0.05974535, -0.0451489 ,  0.45728039, -0.0427907 , -0.01508429,\n",
       "        0.18771998,  0.50431862,  0.23320158,  0.38896021,  0.0867679 ,\n",
       "        0.39095206,  0.24777637,  0.24468085,  0.22646851,  0.05204778,\n",
       "        0.27897839,  0.39412273,  0.0724166 ,  0.11227154,  0.20804598,\n",
       "        0.72360704,  0.85655738, -0.12518741,  0.73493976,  0.16285211,\n",
       "        0.16675218,  0.87920168,  0.058927  , -0.01597444,  0.3501199 ,\n",
       "        0.03764321,  0.72798216,  0.31950207,  0.70091743,  0.20792079,\n",
       "        0.66360053,  0.0974026 ,  0.80958013,  0.        ,  0.42972973,\n",
       "        0.10747051,  0.35635359,  0.24400564,  0.27378815,  0.19644301,\n",
       "        0.4914361 ,  0.6038874 , -0.01280878,  0.28605201,  0.08768267,\n",
       "       -0.00542299,  0.        ,  0.08898015,  0.02384393, -0.06468717,\n",
       "        0.1863581 ,  0.35233571,  0.33960047,  0.40554415,  0.36675824,\n",
       "        0.26747196,  0.61350407,  0.02290623, -0.09581565,  0.14001986,\n",
       "        0.74265976,  0.12190813,  0.41948579, -0.01597444,  0.0055918 ,\n",
       "       -0.14005602,  0.04      ,  0.04      ,  0.35050847,  0.04460665,\n",
       "        0.03846154,  0.03857567, -0.12209889,  0.23449831, -0.08847185,\n",
       "       -0.09016393, -0.12562396, -0.08173077,  0.01530055])"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333, 1.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.33333333, 0.40021671, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.33333333, 0.19237589, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.33333333, 0.73305753, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.33333333, 0.20793932, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.33333333, 0.15740741, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler2 = preprocessing.MinMaxScaler()\n",
    "#Y_scale = min_max_scaler2.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3)\n",
    "#X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "#X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y_scale, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 35)\n",
      "(124,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 35) (19, 35) (19, 35) (86,) (19,) (19,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.80%\n",
      "accuracy: 1.80%\n",
      "accuracy: 1.80%\n",
      "accuracy: 1.80%\n",
      "accuracy: 1.79%\n",
      "accuracy: 1.79%\n",
      "accuracy: 0.00%\n",
      "accuracy: 1.79%\n",
      "accuracy: 1.79%\n",
      "accuracy: 1.79%\n",
      "1.61% (+/- 0.54%)\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(X_scale, Y):\n",
    "# create model\n",
    "\tmodel2 = Sequential()\n",
    "\tmodel2.add(Dense(35, input_dim=35, activation='relu'))\n",
    "\tmodel2.add(Dense(70, activation='relu'))\n",
    "\tmodel2.add(Dense(35, activation='relu'))\n",
    "\tmodel2.add(Dense(7, activation='relu'))\n",
    "\tmodel2.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel2.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\t# Fit the model\n",
    "\tmodel2.fit(X_scale[train], Y[train], epochs=150, batch_size=9, verbose=0)\n",
    "\t# evaluate the model\n",
    "\tscores = model2.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "\tprint(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "\tcvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.0000e+00 - val_loss: 0.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.1355 - accuracy: 0.0000e+00 - val_loss: 0.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.1284 - accuracy: 0.0233 - val_loss: 0.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.1221 - accuracy: 0.0233 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.1162 - accuracy: 0.0233 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.1109 - accuracy: 0.0233 - val_loss: 0.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.1064 - accuracy: 0.0233 - val_loss: 0.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.1021 - accuracy: 0.0233 - val_loss: 0.1231 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0983 - accuracy: 0.0233 - val_loss: 0.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0949 - accuracy: 0.0233 - val_loss: 0.1151 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0920 - accuracy: 0.0233 - val_loss: 0.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0892 - accuracy: 0.0233 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0868 - accuracy: 0.0233 - val_loss: 0.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0845 - accuracy: 0.0233 - val_loss: 0.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0825 - accuracy: 0.0233 - val_loss: 0.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 494us/step - loss: 0.0807 - accuracy: 0.0233 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 410us/step - loss: 0.0791 - accuracy: 0.0233 - val_loss: 0.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 414us/step - loss: 0.0777 - accuracy: 0.0233 - val_loss: 0.0941 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 392us/step - loss: 0.0764 - accuracy: 0.0233 - val_loss: 0.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 435us/step - loss: 0.0751 - accuracy: 0.0233 - val_loss: 0.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.0740 - accuracy: 0.0233 - val_loss: 0.0895 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0730 - accuracy: 0.0233 - val_loss: 0.0881 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0721 - accuracy: 0.0233 - val_loss: 0.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0713 - accuracy: 0.0233 - val_loss: 0.0858 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0705 - accuracy: 0.0233 - val_loss: 0.0847 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0698 - accuracy: 0.0233 - val_loss: 0.0838 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0691 - accuracy: 0.0233 - val_loss: 0.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0685 - accuracy: 0.0233 - val_loss: 0.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0680 - accuracy: 0.0233 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0675 - accuracy: 0.0233 - val_loss: 0.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0670 - accuracy: 0.0233 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0666 - accuracy: 0.0233 - val_loss: 0.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0662 - accuracy: 0.0233 - val_loss: 0.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0658 - accuracy: 0.0233 - val_loss: 0.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0655 - accuracy: 0.0233 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0651 - accuracy: 0.0233 - val_loss: 0.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0649 - accuracy: 0.0233 - val_loss: 0.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0646 - accuracy: 0.0233 - val_loss: 0.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0644 - accuracy: 0.0233 - val_loss: 0.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0640 - accuracy: 0.0233 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0636 - accuracy: 0.0233 - val_loss: 0.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 395us/step - loss: 0.0633 - accuracy: 0.0233 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 315us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 257us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 256us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 259us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 256us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 422us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 430us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 442us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 571us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 500us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 398us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 405us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 602us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 365us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 398us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 372us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 382us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 637us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 517us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 462us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 459us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 447us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 382us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 423us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 371us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 505us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 476us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 456us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 500us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 432us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 438us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 440us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 409us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 443us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 739us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 428us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 369us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 370us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 381us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 389us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 362us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 393us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 398us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 351us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 385us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 579us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 559us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 418us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 393us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 362us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 630us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 465us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 412us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 476us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 365us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 387us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 439us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 444us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 470us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 476us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 477us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 402us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 415us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 420us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 451us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 402us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 386us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 365us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 401us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 426us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 384us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 375us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 380us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 425us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 402us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 328us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 564us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 496us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 442us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 411us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 581us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 717us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 685us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 773us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 783us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 792us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 703us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0782 - accuracy: 0.0233 - val_loss: 0.0949 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 392us/step - loss: 0.0770 - accuracy: 0.0233 - val_loss: 0.0932 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0757 - accuracy: 0.0233 - val_loss: 0.0916 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 490us/step - loss: 0.0746 - accuracy: 0.0233 - val_loss: 0.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 442us/step - loss: 0.0737 - accuracy: 0.0233 - val_loss: 0.0889 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 416us/step - loss: 0.0727 - accuracy: 0.0233 - val_loss: 0.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 462us/step - loss: 0.0718 - accuracy: 0.0233 - val_loss: 0.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 466us/step - loss: 0.0710 - accuracy: 0.0233 - val_loss: 0.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 440us/step - loss: 0.0703 - accuracy: 0.0233 - val_loss: 0.0845 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 497us/step - loss: 0.0697 - accuracy: 0.0233 - val_loss: 0.0835 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0690 - accuracy: 0.0233 - val_loss: 0.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0684 - accuracy: 0.0233 - val_loss: 0.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 384us/step - loss: 0.0679 - accuracy: 0.0233 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 392us/step - loss: 0.0674 - accuracy: 0.0233 - val_loss: 0.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0670 - accuracy: 0.0233 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 373us/step - loss: 0.0666 - accuracy: 0.0233 - val_loss: 0.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 410us/step - loss: 0.0662 - accuracy: 0.0233 - val_loss: 0.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 419us/step - loss: 0.0658 - accuracy: 0.0233 - val_loss: 0.0780 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 390us/step - loss: 0.0655 - accuracy: 0.0233 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 455us/step - loss: 0.0652 - accuracy: 0.0233 - val_loss: 0.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 544us/step - loss: 0.0650 - accuracy: 0.0233 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0640 - accuracy: 0.0233 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0746 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0636 - accuracy: 0.0233 - val_loss: 0.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0633 - accuracy: 0.0233 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 358us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 358us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 402us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 472us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 440us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 342us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 450us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 378us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 384us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 365us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 372us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 431us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 440us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 441us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 592us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 420us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 401us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 444us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 558us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 385us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 388us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 370us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 403us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 423us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 369us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 391us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 566us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 552us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 514us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 552us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 412us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 389us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 551us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 497us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 529us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 475us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 472us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 543us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 443us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 421us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 558us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 583us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 500us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 452us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 368us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 524us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 963us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 567us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 515us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 503us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 521us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 368us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 545us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 420us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 373us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 422us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 385us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 716us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 673us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 579us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 426us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 404us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 399us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 447us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 544us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 351us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 258us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 359us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 368us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 418us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 375us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 369us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 407us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 386us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 401us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.1317 - accuracy: 0.0233 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.1251 - accuracy: 0.0233 - val_loss: 0.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.1189 - accuracy: 0.0233 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.1134 - accuracy: 0.0233 - val_loss: 0.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.1083 - accuracy: 0.0233 - val_loss: 0.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.1037 - accuracy: 0.0233 - val_loss: 0.1249 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0997 - accuracy: 0.0233 - val_loss: 0.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0962 - accuracy: 0.0233 - val_loss: 0.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0931 - accuracy: 0.0233 - val_loss: 0.1128 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0902 - accuracy: 0.0233 - val_loss: 0.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0877 - accuracy: 0.0233 - val_loss: 0.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0852 - accuracy: 0.0233 - val_loss: 0.1034 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0831 - accuracy: 0.0233 - val_loss: 0.1008 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0811 - accuracy: 0.0233 - val_loss: 0.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0794 - accuracy: 0.0233 - val_loss: 0.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0778 - accuracy: 0.0233 - val_loss: 0.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0764 - accuracy: 0.0233 - val_loss: 0.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0751 - accuracy: 0.0233 - val_loss: 0.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0740 - accuracy: 0.0233 - val_loss: 0.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0729 - accuracy: 0.0233 - val_loss: 0.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0720 - accuracy: 0.0233 - val_loss: 0.0868 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0712 - accuracy: 0.0233 - val_loss: 0.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0704 - accuracy: 0.0233 - val_loss: 0.0845 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0696 - accuracy: 0.0233 - val_loss: 0.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0690 - accuracy: 0.0233 - val_loss: 0.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 318us/step - loss: 0.0684 - accuracy: 0.0233 - val_loss: 0.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0678 - accuracy: 0.0233 - val_loss: 0.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0672 - accuracy: 0.0233 - val_loss: 0.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0668 - accuracy: 0.0233 - val_loss: 0.0795 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0664 - accuracy: 0.0233 - val_loss: 0.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0659 - accuracy: 0.0233 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0656 - accuracy: 0.0233 - val_loss: 0.0777 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0653 - accuracy: 0.0233 - val_loss: 0.0771 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0650 - accuracy: 0.0233 - val_loss: 0.0767 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0644 - accuracy: 0.0233 - val_loss: 0.0757 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0639 - accuracy: 0.0233 - val_loss: 0.0749 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0637 - accuracy: 0.0233 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0633 - accuracy: 0.0233 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 358us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 357us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 366us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 885us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 588us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 459us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 392us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 374us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 362us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 366us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 432us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 374us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 423us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 256us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 507us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 448us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 490us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 605us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0716 - accuracy: 0.0233 - val_loss: 0.0863 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0709 - accuracy: 0.0233 - val_loss: 0.0854 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0703 - accuracy: 0.0233 - val_loss: 0.0845 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0697 - accuracy: 0.0233 - val_loss: 0.0838 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0692 - accuracy: 0.0233 - val_loss: 0.0830 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0687 - accuracy: 0.0233 - val_loss: 0.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0682 - accuracy: 0.0233 - val_loss: 0.0815 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0677 - accuracy: 0.0233 - val_loss: 0.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0673 - accuracy: 0.0233 - val_loss: 0.0803 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0670 - accuracy: 0.0233 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0666 - accuracy: 0.0233 - val_loss: 0.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0663 - accuracy: 0.0233 - val_loss: 0.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0660 - accuracy: 0.0233 - val_loss: 0.0783 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0657 - accuracy: 0.0233 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0654 - accuracy: 0.0233 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0652 - accuracy: 0.0233 - val_loss: 0.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0649 - accuracy: 0.0233 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0643 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0641 - accuracy: 0.0233 - val_loss: 0.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0639 - accuracy: 0.0233 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0637 - accuracy: 0.0233 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0725 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 316us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 351us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 383us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 362us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 253us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.0973 - accuracy: 0.0233 - val_loss: 0.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 386us/step - loss: 0.0942 - accuracy: 0.0233 - val_loss: 0.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 382us/step - loss: 0.0913 - accuracy: 0.0233 - val_loss: 0.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0887 - accuracy: 0.0233 - val_loss: 0.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 369us/step - loss: 0.0863 - accuracy: 0.0233 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0842 - accuracy: 0.0233 - val_loss: 0.1021 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0822 - accuracy: 0.0233 - val_loss: 0.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0805 - accuracy: 0.0233 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0790 - accuracy: 0.0233 - val_loss: 0.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0776 - accuracy: 0.0233 - val_loss: 0.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0763 - accuracy: 0.0233 - val_loss: 0.0924 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0751 - accuracy: 0.0233 - val_loss: 0.0907 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0739 - accuracy: 0.0233 - val_loss: 0.0892 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0729 - accuracy: 0.0233 - val_loss: 0.0878 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0719 - accuracy: 0.0233 - val_loss: 0.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0711 - accuracy: 0.0233 - val_loss: 0.0857 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0704 - accuracy: 0.0233 - val_loss: 0.0846 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0697 - accuracy: 0.0233 - val_loss: 0.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0691 - accuracy: 0.0233 - val_loss: 0.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0684 - accuracy: 0.0233 - val_loss: 0.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0678 - accuracy: 0.0233 - val_loss: 0.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0673 - accuracy: 0.0233 - val_loss: 0.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0669 - accuracy: 0.0233 - val_loss: 0.0796 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0665 - accuracy: 0.0233 - val_loss: 0.0790 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0661 - accuracy: 0.0233 - val_loss: 0.0784 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0657 - accuracy: 0.0233 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0654 - accuracy: 0.0233 - val_loss: 0.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0651 - accuracy: 0.0233 - val_loss: 0.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0648 - accuracy: 0.0233 - val_loss: 0.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0643 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0641 - accuracy: 0.0233 - val_loss: 0.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0746 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0636 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 282us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 366us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 384us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 481us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 438us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 422us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 465us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 370us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 373us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 399us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 464us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 418us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.3247 - accuracy: 0.0000e+00 - val_loss: 0.3672 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.3120 - accuracy: 0.0000e+00 - val_loss: 0.3534 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.2994 - accuracy: 0.0000e+00 - val_loss: 0.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.2870 - accuracy: 0.0000e+00 - val_loss: 0.3262 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.2746 - accuracy: 0.0000e+00 - val_loss: 0.3129 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.2626 - accuracy: 0.0000e+00 - val_loss: 0.2999 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.2508 - accuracy: 0.0000e+00 - val_loss: 0.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.2397 - accuracy: 0.0000e+00 - val_loss: 0.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.2289 - accuracy: 0.0000e+00 - val_loss: 0.2638 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.2187 - accuracy: 0.0000e+00 - val_loss: 0.2528 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.2089 - accuracy: 0.0000e+00 - val_loss: 0.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.1996 - accuracy: 0.0000e+00 - val_loss: 0.2320 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.1907 - accuracy: 0.0000e+00 - val_loss: 0.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.1825 - accuracy: 0.0000e+00 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.1746 - accuracy: 0.0000e+00 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.1672 - accuracy: 0.0000e+00 - val_loss: 0.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.1601 - accuracy: 0.0000e+00 - val_loss: 0.1891 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.1536 - accuracy: 0.0000e+00 - val_loss: 0.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.1474 - accuracy: 0.0000e+00 - val_loss: 0.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.1418 - accuracy: 0.0000e+00 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.1367 - accuracy: 0.0000e+00 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.1318 - accuracy: 0.0233 - val_loss: 0.1579 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.1273 - accuracy: 0.0233 - val_loss: 0.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.1232 - accuracy: 0.0233 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 361us/step - loss: 0.1193 - accuracy: 0.0233 - val_loss: 0.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.1155 - accuracy: 0.0233 - val_loss: 0.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.1121 - accuracy: 0.0233 - val_loss: 0.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.1089 - accuracy: 0.0233 - val_loss: 0.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.1060 - accuracy: 0.0233 - val_loss: 0.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.1033 - accuracy: 0.0233 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.1007 - accuracy: 0.0233 - val_loss: 0.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0983 - accuracy: 0.0233 - val_loss: 0.1197 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0961 - accuracy: 0.0233 - val_loss: 0.1171 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0941 - accuracy: 0.0233 - val_loss: 0.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 296us/step - loss: 0.0921 - accuracy: 0.0233 - val_loss: 0.1124 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0904 - accuracy: 0.0233 - val_loss: 0.1103 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0888 - accuracy: 0.0233 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0871 - accuracy: 0.0233 - val_loss: 0.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0857 - accuracy: 0.0233 - val_loss: 0.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0844 - accuracy: 0.0233 - val_loss: 0.1029 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0830 - accuracy: 0.0233 - val_loss: 0.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0818 - accuracy: 0.0233 - val_loss: 0.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0807 - accuracy: 0.0233 - val_loss: 0.0983 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0796 - accuracy: 0.0233 - val_loss: 0.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0786 - accuracy: 0.0233 - val_loss: 0.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0777 - accuracy: 0.0233 - val_loss: 0.0945 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0768 - accuracy: 0.0233 - val_loss: 0.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0760 - accuracy: 0.0233 - val_loss: 0.0923 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0752 - accuracy: 0.0233 - val_loss: 0.0913 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0745 - accuracy: 0.0233 - val_loss: 0.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0738 - accuracy: 0.0233 - val_loss: 0.0895 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0732 - accuracy: 0.0233 - val_loss: 0.0886 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0726 - accuracy: 0.0233 - val_loss: 0.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0721 - accuracy: 0.0233 - val_loss: 0.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0715 - accuracy: 0.0233 - val_loss: 0.0863 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0710 - accuracy: 0.0233 - val_loss: 0.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0705 - accuracy: 0.0233 - val_loss: 0.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0701 - accuracy: 0.0233 - val_loss: 0.0843 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0696 - accuracy: 0.0233 - val_loss: 0.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0692 - accuracy: 0.0233 - val_loss: 0.0832 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0689 - accuracy: 0.0233 - val_loss: 0.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0685 - accuracy: 0.0233 - val_loss: 0.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0681 - accuracy: 0.0233 - val_loss: 0.0815 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0678 - accuracy: 0.0233 - val_loss: 0.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0674 - accuracy: 0.0233 - val_loss: 0.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0671 - accuracy: 0.0233 - val_loss: 0.0801 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0669 - accuracy: 0.0233 - val_loss: 0.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0666 - accuracy: 0.0233 - val_loss: 0.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0664 - accuracy: 0.0233 - val_loss: 0.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0661 - accuracy: 0.0233 - val_loss: 0.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0659 - accuracy: 0.0233 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0657 - accuracy: 0.0233 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0655 - accuracy: 0.0233 - val_loss: 0.0775 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0653 - accuracy: 0.0233 - val_loss: 0.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0651 - accuracy: 0.0233 - val_loss: 0.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 408us/step - loss: 0.0649 - accuracy: 0.0233 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0644 - accuracy: 0.0233 - val_loss: 0.0757 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0641 - accuracy: 0.0233 - val_loss: 0.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0640 - accuracy: 0.0233 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0637 - accuracy: 0.0233 - val_loss: 0.0746 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0636 - accuracy: 0.0233 - val_loss: 0.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0633 - accuracy: 0.0233 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 307us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 281us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 351us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 379us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 359us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 434us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 387us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 359us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 456us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 378us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 387us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 400us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 330us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 332us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0842 - accuracy: 0.0233 - val_loss: 0.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0823 - accuracy: 0.0233 - val_loss: 0.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0806 - accuracy: 0.0233 - val_loss: 0.0978 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0791 - accuracy: 0.0233 - val_loss: 0.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0778 - accuracy: 0.0233 - val_loss: 0.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0765 - accuracy: 0.0233 - val_loss: 0.0927 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0754 - accuracy: 0.0233 - val_loss: 0.0913 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0744 - accuracy: 0.0233 - val_loss: 0.0899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0734 - accuracy: 0.0233 - val_loss: 0.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0724 - accuracy: 0.0233 - val_loss: 0.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0715 - accuracy: 0.0233 - val_loss: 0.0862 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0708 - accuracy: 0.0233 - val_loss: 0.0851 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0701 - accuracy: 0.0233 - val_loss: 0.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0695 - accuracy: 0.0233 - val_loss: 0.0833 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0689 - accuracy: 0.0233 - val_loss: 0.0825 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0683 - accuracy: 0.0233 - val_loss: 0.0817 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0679 - accuracy: 0.0233 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0675 - accuracy: 0.0233 - val_loss: 0.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0670 - accuracy: 0.0233 - val_loss: 0.0798 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0667 - accuracy: 0.0233 - val_loss: 0.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0663 - accuracy: 0.0233 - val_loss: 0.0786 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0659 - accuracy: 0.0233 - val_loss: 0.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0656 - accuracy: 0.0233 - val_loss: 0.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0653 - accuracy: 0.0233 - val_loss: 0.0771 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0650 - accuracy: 0.0233 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0643 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0641 - accuracy: 0.0233 - val_loss: 0.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0639 - accuracy: 0.0233 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0637 - accuracy: 0.0233 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 381us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0629 - accuracy: 0.0233 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 360us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 375us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 342us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 294us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 357us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 341us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 370us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 359us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 399us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 434us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 479us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 423us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 357us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 356us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 375us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 339us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 349us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 357us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 377us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 336us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 442us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 472us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 418us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 331us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 326us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 256us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 257us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.1390 - accuracy: 0.0000e+00 - val_loss: 0.1628 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.1296 - accuracy: 0.0233 - val_loss: 0.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.1210 - accuracy: 0.0233 - val_loss: 0.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.1136 - accuracy: 0.0233 - val_loss: 0.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.1074 - accuracy: 0.0233 - val_loss: 0.1284 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.1021 - accuracy: 0.0233 - val_loss: 0.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0975 - accuracy: 0.0233 - val_loss: 0.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0933 - accuracy: 0.0233 - val_loss: 0.1125 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0897 - accuracy: 0.0233 - val_loss: 0.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0867 - accuracy: 0.0233 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0839 - accuracy: 0.0233 - val_loss: 0.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0816 - accuracy: 0.0233 - val_loss: 0.0988 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0796 - accuracy: 0.0233 - val_loss: 0.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0777 - accuracy: 0.0233 - val_loss: 0.0939 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0760 - accuracy: 0.0233 - val_loss: 0.0918 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0745 - accuracy: 0.0233 - val_loss: 0.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0732 - accuracy: 0.0233 - val_loss: 0.0881 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0720 - accuracy: 0.0233 - val_loss: 0.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0710 - accuracy: 0.0233 - val_loss: 0.0854 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0701 - accuracy: 0.0233 - val_loss: 0.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0693 - accuracy: 0.0233 - val_loss: 0.0830 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0686 - accuracy: 0.0233 - val_loss: 0.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0679 - accuracy: 0.0233 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0674 - accuracy: 0.0233 - val_loss: 0.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0668 - accuracy: 0.0233 - val_loss: 0.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0662 - accuracy: 0.0233 - val_loss: 0.0786 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0659 - accuracy: 0.0233 - val_loss: 0.0780 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0655 - accuracy: 0.0233 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0651 - accuracy: 0.0233 - val_loss: 0.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0648 - accuracy: 0.0233 - val_loss: 0.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0645 - accuracy: 0.0233 - val_loss: 0.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0640 - accuracy: 0.0233 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0633 - accuracy: 0.0233 - val_loss: 0.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0625 - accuracy: 0.0233 - val_loss: 0.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 264us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 344us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 261us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 350us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 259us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 313us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 335us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 257us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 262us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 264us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 263us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Train on 86 samples, validate on 19 samples\n",
      "Epoch 1/400\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.0829 - accuracy: 0.0233 - val_loss: 0.1007 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "86/86 [==============================] - 0s 332us/step - loss: 0.0812 - accuracy: 0.0233 - val_loss: 0.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0799 - accuracy: 0.0233 - val_loss: 0.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0785 - accuracy: 0.0233 - val_loss: 0.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0772 - accuracy: 0.0233 - val_loss: 0.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0761 - accuracy: 0.0233 - val_loss: 0.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0750 - accuracy: 0.0233 - val_loss: 0.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0741 - accuracy: 0.0233 - val_loss: 0.0896 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0731 - accuracy: 0.0233 - val_loss: 0.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "86/86 [==============================] - 0s 327us/step - loss: 0.0724 - accuracy: 0.0233 - val_loss: 0.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0716 - accuracy: 0.0233 - val_loss: 0.0862 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0708 - accuracy: 0.0233 - val_loss: 0.0852 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0701 - accuracy: 0.0233 - val_loss: 0.0843 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0695 - accuracy: 0.0233 - val_loss: 0.0835 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0690 - accuracy: 0.0233 - val_loss: 0.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0685 - accuracy: 0.0233 - val_loss: 0.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0680 - accuracy: 0.0233 - val_loss: 0.0813 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0676 - accuracy: 0.0233 - val_loss: 0.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0671 - accuracy: 0.0233 - val_loss: 0.0800 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0667 - accuracy: 0.0233 - val_loss: 0.0795 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0664 - accuracy: 0.0233 - val_loss: 0.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0661 - accuracy: 0.0233 - val_loss: 0.0784 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0657 - accuracy: 0.0233 - val_loss: 0.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0654 - accuracy: 0.0233 - val_loss: 0.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0651 - accuracy: 0.0233 - val_loss: 0.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0649 - accuracy: 0.0233 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "86/86 [==============================] - 0s 329us/step - loss: 0.0647 - accuracy: 0.0233 - val_loss: 0.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0644 - accuracy: 0.0233 - val_loss: 0.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0642 - accuracy: 0.0233 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 309us/step - loss: 0.0640 - accuracy: 0.0233 - val_loss: 0.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0638 - accuracy: 0.0233 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0637 - accuracy: 0.0233 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0635 - accuracy: 0.0233 - val_loss: 0.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0634 - accuracy: 0.0233 - val_loss: 0.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0632 - accuracy: 0.0233 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0631 - accuracy: 0.0233 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0630 - accuracy: 0.0233 - val_loss: 0.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0628 - accuracy: 0.0233 - val_loss: 0.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0627 - accuracy: 0.0233 - val_loss: 0.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0626 - accuracy: 0.0233 - val_loss: 0.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0624 - accuracy: 0.0233 - val_loss: 0.0722 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0623 - accuracy: 0.0233 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "86/86 [==============================] - 0s 265us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0718 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0622 - accuracy: 0.0233 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0621 - accuracy: 0.0233 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0620 - accuracy: 0.0233 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0619 - accuracy: 0.0233 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0618 - accuracy: 0.0233 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0617 - accuracy: 0.0233 - val_loss: 0.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "86/86 [==============================] - 0s 318us/step - loss: 0.0616 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0615 - accuracy: 0.0233 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0699 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0614 - accuracy: 0.0233 - val_loss: 0.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0613 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0612 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0611 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 282us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0610 - accuracy: 0.0233 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "86/86 [==============================] - 0s 301us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "86/86 [==============================] - 0s 266us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "86/86 [==============================] - 0s 323us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "86/86 [==============================] - 0s 302us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "86/86 [==============================] - 0s 298us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "86/86 [==============================] - 0s 309us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "86/86 [==============================] - 0s 306us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0677 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "86/86 [==============================] - 0s 315us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "86/86 [==============================] - 0s 280us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "86/86 [==============================] - 0s 268us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "86/86 [==============================] - 0s 285us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "86/86 [==============================] - 0s 257us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "86/86 [==============================] - 0s 267us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "86/86 [==============================] - 0s 297us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "86/86 [==============================] - 0s 260us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "86/86 [==============================] - 0s 274us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "86/86 [==============================] - 0s 273us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "86/86 [==============================] - 0s 275us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "86/86 [==============================] - 0s 269us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "86/86 [==============================] - 0s 281us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "86/86 [==============================] - 0s 279us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "86/86 [==============================] - 0s 294us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "86/86 [==============================] - 0s 272us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "86/86 [==============================] - 0s 270us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "86/86 [==============================] - 0s 333us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "86/86 [==============================] - 0s 321us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "86/86 [==============================] - 0s 320us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "86/86 [==============================] - 0s 307us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "86/86 [==============================] - 0s 311us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "86/86 [==============================] - 0s 303us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "86/86 [==============================] - 0s 308us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "86/86 [==============================] - 0s 289us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "86/86 [==============================] - 0s 288us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "86/86 [==============================] - 0s 305us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "86/86 [==============================] - 0s 290us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "86/86 [==============================] - 0s 271us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "86/86 [==============================] - 0s 287us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "86/86 [==============================] - 0s 284us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "86/86 [==============================] - 0s 325us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "86/86 [==============================] - 0s 353us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "86/86 [==============================] - 0s 300us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "86/86 [==============================] - 0s 299us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "86/86 [==============================] - 0s 276us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "86/86 [==============================] - 0s 291us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "86/86 [==============================] - 0s 277us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "86/86 [==============================] - 0s 304us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "86/86 [==============================] - 0s 282us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "86/86 [==============================] - 0s 293us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "86/86 [==============================] - 0s 278us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "86/86 [==============================] - 0s 296us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "86/86 [==============================] - 0s 322us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "86/86 [==============================] - 0s 283us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "86/86 [==============================] - 0s 363us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "86/86 [==============================] - 0s 324us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "86/86 [==============================] - 0s 371us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "86/86 [==============================] - 0s 400us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "86/86 [==============================] - 0s 357us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "86/86 [==============================] - 0s 337us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "86/86 [==============================] - 0s 319us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "86/86 [==============================] - 0s 352us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "86/86 [==============================] - 0s 347us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "86/86 [==============================] - 0s 312us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "86/86 [==============================] - 0s 310us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "86/86 [==============================] - 0s 340us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "86/86 [==============================] - 0s 367us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "86/86 [==============================] - 0s 473us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "86/86 [==============================] - 0s 802us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "86/86 [==============================] - 0s 758us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "86/86 [==============================] - 0s 691us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "86/86 [==============================] - 0s 483us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "86/86 [==============================] - 0s 433us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "86/86 [==============================] - 0s 489us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "86/86 [==============================] - 0s 706us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "86/86 [==============================] - 0s 690us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "86/86 [==============================] - 0s 627us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "86/86 [==============================] - 0s 579us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "86/86 [==============================] - 0s 466us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "86/86 [==============================] - 0s 411us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "86/86 [==============================] - 0s 708us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "86/86 [==============================] - 0s 972us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "86/86 [==============================] - 0s 698us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "86/86 [==============================] - 0s 925us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "86/86 [==============================] - 0s 447us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "86/86 [==============================] - 0s 643us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "86/86 [==============================] - 0s 762us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "86/86 [==============================] - 0s 969us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "86/86 [==============================] - 0s 490us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "86/86 [==============================] - 0s 712us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "86/86 [==============================] - 0s 822us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "86/86 [==============================] - 0s 970us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "86/86 [==============================] - 0s 760us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "86/86 [==============================] - 0s 921us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "86/86 [==============================] - 0s 798us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "86/86 [==============================] - 0s 529us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "86/86 [==============================] - 0s 382us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "86/86 [==============================] - 0s 544us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "86/86 [==============================] - 0s 432us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 700us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "86/86 [==============================] - 0s 490us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "86/86 [==============================] - 0s 402us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "86/86 [==============================] - 0s 401us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "86/86 [==============================] - 0s 429us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "86/86 [==============================] - 0s 372us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "86/86 [==============================] - 0s 465us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "86/86 [==============================] - 0s 438us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "86/86 [==============================] - 0s 433us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "86/86 [==============================] - 0s 468us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "86/86 [==============================] - 0s 388us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "86/86 [==============================] - 0s 381us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "86/86 [==============================] - 0s 424us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "86/86 [==============================] - 0s 396us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "86/86 [==============================] - 0s 334us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "86/86 [==============================] - 0s 376us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "86/86 [==============================] - 0s 416us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "86/86 [==============================] - 0s 355us/step - loss: 0.0608 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "86/86 [==============================] - 0s 389us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "86/86 [==============================] - 0s 368us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "86/86 [==============================] - 0s 314us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "86/86 [==============================] - 0s 387us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "86/86 [==============================] - 0s 448us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "86/86 [==============================] - 0s 345us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "86/86 [==============================] - 0s 346us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "86/86 [==============================] - 0s 295us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "86/86 [==============================] - 0s 364us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "86/86 [==============================] - 0s 397us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "86/86 [==============================] - 0s 292us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "86/86 [==============================] - 0s 354us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "86/86 [==============================] - 0s 328us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "86/86 [==============================] - 0s 316us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "86/86 [==============================] - 0s 362us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "86/86 [==============================] - 0s 286us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "86/86 [==============================] - 0s 338us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "86/86 [==============================] - 0s 348us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "86/86 [==============================] - 0s 343us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "86/86 [==============================] - 0s 317us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "86/86 [==============================] - 0s 754us/step - loss: 0.0609 - accuracy: 0.0233 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "1.16% (+/- 0.54%)\n"
     ]
    }
   ],
   "source": [
    "cvscores2 = []\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "# create model\n",
    "    model3 = Sequential([\n",
    "        Dense(35, activation='sigmoid', input_shape=(35,)),\n",
    "        Dense(70, activation='sigmoid'),\n",
    "        Dense(35, activation='sigmoid'),\n",
    "        Dense(7, activation='sigmoid'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    epochs=400\n",
    "    learning_rate = 0.1\n",
    "    decay_rate = learning_rate / epochs\n",
    "    momentum = 0.8\n",
    "    sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model3.compile(optimizer='sgd',\n",
    "              loss='mse',              \n",
    "              metrics=['accuracy'])\n",
    "    hist3 = model3.fit(X_train, Y_train,\n",
    "          batch_size=9, epochs=epochs,\n",
    "          validation_data=(X_val, Y_val))\n",
    "    scores = model3.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "    cvscores2.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "19/19 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a60a472b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist3.history['loss'])\n",
    "plt.plot(hist3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(28, activation='sigmoid', input_shape=(18,)),\n",
    "    Dense(3, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=400\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "#model.compile(optimizer='sgd',\n",
    "#              loss='binary_crossentropy',\n",
    "#              metrics=['accuracy'])\n",
    "#opt = model.optimizers.Adam(learning_rate=0.1)\n",
    "#model.compile(optimizer='adam',\n",
    "#model.compile(optimizer=opt,\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',              \n",
    "              metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=9, epochs=epochs,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = [[2002, 1.9, 1], [2012, 2, 1], [2015, 2, 4]]\n",
    "Xnew = [2002, 1.9, 1]\n",
    "Xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Local Content Requirment (H,M,A,L, N)</th>\n",
       "      <th>Company (NOC, IOC, OC)</th>\n",
       "      <th>Lease/ Own</th>\n",
       "      <th>Contract2</th>\n",
       "      <th>Contracting Date</th>\n",
       "      <th>Contract (EPC, CL, PS, TK)</th>\n",
       "      <th>Planned_Duration</th>\n",
       "      <th>Planned_Cost</th>\n",
       "      <th>Hull Type</th>\n",
       "      <th>BOE/day</th>\n",
       "      <th>Topsides (VL, L, M, S, VS)</th>\n",
       "      <th>Technology Novelt (H,M,A,L,N)</th>\n",
       "      <th>Type Unit</th>\n",
       "      <th>Water_Depth\\n(meters)</th>\n",
       "      <th>Lessons Learned</th>\n",
       "      <th>Oil/Gas_Prod</th>\n",
       "      <th>FEED_Detail</th>\n",
       "      <th>Schedule_Overrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lingshui Semi</td>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10439</td>\n",
       "      <td>EPC</td>\n",
       "      <td>700</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>67166.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SEMI</td>\n",
       "      <td>980</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bohai Ming Zhu</td>\n",
       "      <td>SEA CH</td>\n",
       "      <td>5</td>\n",
       "      <td>NOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4350</td>\n",
       "      <td>EPC</td>\n",
       "      <td>259</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petrojarl Varg</td>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>OC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240</td>\n",
       "      <td>EPC</td>\n",
       "      <td>816</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1</td>\n",
       "      <td>65833.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865823</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stybarrow Venture MV16</td>\n",
       "      <td>AUST/NZ</td>\n",
       "      <td>3</td>\n",
       "      <td>IOC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922</td>\n",
       "      <td>EPC</td>\n",
       "      <td>702</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>1</td>\n",
       "      <td>87500.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>FPSO</td>\n",
       "      <td>825</td>\n",
       "      <td>2</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.143875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alima FPU</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>2</td>\n",
       "      <td>IOC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5720</td>\n",
       "      <td>EPC</td>\n",
       "      <td>994</td>\n",
       "      <td>1.133000</td>\n",
       "      <td>1</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BARGE</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.022133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unit Name   Region  Local Content Requirment (H,M,A,L, N)  \\\n",
       "0           Lingshui Semi   SEA CH                                      5   \n",
       "1          Bohai Ming Zhu   SEA CH                                      5   \n",
       "2          Petrojarl Varg       NE                                      1   \n",
       "3  Stybarrow Venture MV16  AUST/NZ                                      3   \n",
       "4               Alima FPU   AFRICA                                      2   \n",
       "\n",
       "  Company (NOC, IOC, OC)  Lease/ Own  Contract2  Contracting Date  \\\n",
       "0                    NOC           2          1             10439   \n",
       "1                    NOC           2          1              4350   \n",
       "2                     OC           1          1              2240   \n",
       "3                    IOC           1          3              5922   \n",
       "4                    IOC           2          1              5720   \n",
       "\n",
       "  Contract (EPC, CL, PS, TK)  Planned_Duration  Planned_Cost  Hull Type  \\\n",
       "0                        EPC               700      3.100000          1   \n",
       "1                        EPC               259      0.400000          1   \n",
       "2                        EPC               816      0.460000          1   \n",
       "3                        EPC               702      0.598425          1   \n",
       "4                        EPC               994      1.133000          1   \n",
       "\n",
       "         BOE/day  Topsides (VL, L, M, S, VS)  Technology Novelt (H,M,A,L,N)  \\\n",
       "0   67166.666667                           2                              2   \n",
       "1   40000.000000                           1                              2   \n",
       "2   65833.333333                           2                              2   \n",
       "3   87500.000000                           2                              3   \n",
       "4  100000.000000                           3                              1   \n",
       "\n",
       "  Type Unit  Water_Depth\\n(meters)  Lessons Learned  Oil/Gas_Prod  \\\n",
       "0      SEMI                    980                2      0.148883   \n",
       "1      FPSO                     30                1      1.000000   \n",
       "2      FPSO                     84                1      0.865823   \n",
       "3      FPSO                    825                2      0.914286   \n",
       "4     BARGE                    600                3      0.900000   \n",
       "\n",
       "   FEED_Detail  Schedule_Overrun  \n",
       "0            4          0.760000  \n",
       "1            1          0.471042  \n",
       "2            2          0.286765  \n",
       "3            4         -0.143875  \n",
       "4            4         -0.022133  "
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.read_excel(open('Cost_Sch-data-v2.xlsx', 'rb'), sheet_name='Sch_T2')\n",
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_t= df_t.drop('Unit Name', axis = 1)\n",
    "df_t= df_t.drop('Schedule_Overrun', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 2., 1., ..., 1., 0., 0.],\n",
       "       [5., 2., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 2., 1., ..., 0., 0., 1.],\n",
       "       [1., 2., 1., ..., 0., 0., 1.],\n",
       "       [1., 2., 1., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.get_dummies(df_t)\n",
    "dataset_t = df_t.values\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "#df.iloc[:,5:].head(5)\n",
    "dataset_t\n",
    "\n",
    "#Xnew = dataset_t[:,1:19]\n",
    "#Xnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 36)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0000e+00, 1.0000e+00, 1.0439e+04, ..., 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 4.3500e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [1.0000e+00, 1.0000e+00, 2.2400e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [2.0000e+00, 1.0000e+00, 7.7290e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 2.3980e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [2.0000e+00, 1.0000e+00, 1.8850e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = dataset_t[:,1:36]\n",
    "Xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "Xnew_scale = min_max_scaler.fit_transform(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew2 = model2.predict(Xnew_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of Xnew and its predicted yhat\n",
      "Xnew[0] = [2.00000000e+00 1.00000000e+00 1.04390000e+04 7.00000000e+02\n",
      " 3.10000000e+00 1.00000000e+00 6.71666667e+04 2.00000000e+00\n",
      " 2.00000000e+00 9.80000000e+02 2.00000000e+00 1.48883375e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[0] = [0.2177259] \n",
      "Xnew[1] = [2.00e+00 1.00e+00 4.35e+03 2.59e+02 4.00e-01 1.00e+00 4.00e+04 1.00e+00\n",
      " 2.00e+00 3.00e+01 1.00e+00 1.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00], ynew2[1] = [0.22765383] \n",
      "Xnew[2] = [1.00000000e+00 1.00000000e+00 2.24000000e+03 8.16000000e+02\n",
      " 4.60000000e-01 1.00000000e+00 6.58333333e+04 2.00000000e+00\n",
      " 2.00000000e+00 8.40000000e+01 1.00000000e+00 8.65822785e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[2] = [0.22588548] \n",
      "Xnew[3] = [1.00000000e+00 3.00000000e+00 5.92200000e+03 7.02000000e+02\n",
      " 5.98425197e-01 1.00000000e+00 8.75000000e+04 2.00000000e+00\n",
      " 3.00000000e+00 8.25000000e+02 2.00000000e+00 9.14285714e-01\n",
      " 4.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[3] = [0.22056669] \n",
      "Xnew[4] = [2.000e+00 1.000e+00 5.720e+03 9.940e+02 1.133e+00 1.000e+00 1.000e+05\n",
      " 3.000e+00 1.000e+00 6.000e+02 3.000e+00 9.000e-01 4.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[4] = [0.2261891] \n",
      "Xnew[5] = [2.00000000e+00 1.00000000e+00 8.82400000e+03 1.05200000e+03\n",
      " 2.67650000e+00 1.00000000e+00 7.94000000e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.20000000e+02 2.00000000e+00 5.54156171e-02\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[5] = [0.22872666] \n",
      "Xnew[6] = [2.00000000e+00 1.00000000e+00 7.81400000e+03 2.22900000e+03\n",
      " 1.11600000e+01 1.00000000e+00 1.48333333e+05 6.00000000e+00\n",
      " 5.00000000e+00 2.50000000e+02 1.00000000e+00 2.35955056e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[6] = [0.2216877] \n",
      "Xnew[7] = [2.00000000e+00 1.00000000e+00 7.53400000e+03 1.38300000e+03\n",
      " 7.00000000e+00 1.00000000e+00 1.98333333e+05 4.00000000e+00\n",
      " 2.00000000e+00 1.29000000e+03 4.00000000e+00 8.06722689e-01\n",
      " 5.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[7] = [0.21794397] \n",
      "Xnew[8] = [2.00000000e+00 1.00000000e+00 4.87200000e+03 1.30600000e+03\n",
      " 3.40000000e+00 1.00000000e+00 2.87000000e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.36000000e+03 5.00000000e+00 8.36236934e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[8] = [0.21624815] \n",
      "Xnew[9] = [2.00000000e+00 1.00000000e+00 3.10300000e+03 8.23000000e+02\n",
      " 2.50000000e+00 1.00000000e+00 2.46666667e+05 5.00000000e+00\n",
      " 3.00000000e+00 1.35000000e+03 1.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[9] = [0.21887007] \n",
      "Xnew[10] = [2.00000000e+00 1.00000000e+00 8.87100000e+03 1.08100000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.31666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 2.00000000e+00 8.73417722e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[10] = [0.22473213] \n",
      "Xnew[11] = [2.00000000e+00 1.00000000e+00 8.87100000e+03 1.17300000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.31666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 2.00000000e+00 8.73417722e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[11] = [0.22544134] \n",
      "Xnew[12] = [2.00000000e+00 1.00000000e+00 4.75600000e+03 1.07100000e+03\n",
      " 7.60000000e-01 1.00000000e+00 3.16666667e+05 6.00000000e+00\n",
      " 1.00000000e+00 1.25000000e+03 5.00000000e+00 7.89473684e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[12] = [0.22149041] \n",
      "Xnew[13] = [1.00000000e+00 1.00000000e+00 5.86600000e+03 7.97000000e+02\n",
      " 7.50000000e-01 2.00000000e+00 1.15833333e+05 3.00000000e+00\n",
      " 1.00000000e+00 7.28000000e+02 3.00000000e+00 8.63309353e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[13] = [0.21436304] \n",
      "Xnew[14] = [1.00000000e+00 3.00000000e+00 5.86600000e+03 7.97000000e+02\n",
      " 7.50000000e-01 2.00000000e+00 1.30000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 7.20000000e+02 3.00000000e+00 8.07692308e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[14] = [0.22597724] \n",
      "Xnew[15] = [2.00000000e+00 1.00000000e+00 5.14400000e+03 1.12400000e+03\n",
      " 1.73000000e+00 1.00000000e+00 3.05000000e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.35000000e+03 2.00000000e+00 8.19672131e-01\n",
      " 4.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[15] = [0.22757661] \n",
      "Xnew[16] = [2.00000000e+00 1.00000000e+00 6.75500000e+03 1.24900000e+03\n",
      " 1.00000000e+01 2.00000000e+00 1.97833333e+05 4.00000000e+00\n",
      " 5.00000000e+00 2.00000000e+03 2.00000000e+00 7.93597304e-01\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[16] = [0.21846327] \n",
      "Xnew[17] = [2.00000000e+00 1.00000000e+00 4.68700000e+03 8.21000000e+02\n",
      " 1.90000000e+00 1.00000000e+00 3.74053100e+04 4.00000000e+00\n",
      " 3.00000000e+00 5.80000000e+01 1.00000000e+00 9.99056016e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[17] = [0.21926218] \n",
      "Xnew[18] = [1.00000000e+00 3.00000000e+00 4.94900000e+03 7.11000000e+02\n",
      " 1.50000000e+00 2.00000000e+00 8.25000000e+04 2.00000000e+00\n",
      " 1.00000000e+00 9.70000000e+02 3.00000000e+00 8.48484848e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[18] = [0.21957633] \n",
      "Xnew[19] = [1.00000000e+00 3.00000000e+00 8.61700000e+03 1.09200000e+03\n",
      " 4.50000000e+00 2.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.42500000e+03 2.00000000e+00 7.38461538e-01\n",
      " 5.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[19] = [0.21567664] \n",
      "Xnew[20] = [2.00000000e+00 2.00000000e+00 5.53900000e+03 1.12600000e+03\n",
      " 4.15384615e+00 1.00000000e+00 3.25000000e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.43300000e+03 2.00000000e+00 7.69230769e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[20] = [0.21853024] \n",
      "Xnew[21] = [2.00000000e+00 1.00000000e+00 5.60600000e+03 1.30300000e+03\n",
      " 2.34500000e+00 1.00000000e+00 2.73333333e+05 6.00000000e+00\n",
      " 4.00000000e+00 1.32500000e+03 1.00000000e+00 6.76829268e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[21] = [0.21888071] \n",
      "Xnew[22] = [2.00000000e+00 1.00000000e+00 4.04900000e+03 1.03300000e+03\n",
      " 2.40000000e+00 1.00000000e+00 2.53333333e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.25000000e+03 1.00000000e+00 8.88157895e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[22] = [0.22351068] \n",
      "Xnew[23] = [2.00000000e+00 1.00000000e+00 8.54000000e+03 1.59500000e+03\n",
      " 1.50000000e+01 1.00000000e+00 2.60000000e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 3.00000000e+00 7.69230769e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[23] = [0.22490677] \n",
      "Xnew[24] = [2.00000000e+00 1.00000000e+00 4.67100000e+03 1.08100000e+03\n",
      " 2.60000000e+00 1.00000000e+00 2.66666667e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.18000000e+03 2.00000000e+00 7.87500000e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[24] = [0.22118092] \n",
      "Xnew[25] = [2.00000000e+00 1.00000000e+00 4.25300000e+03 1.07300000e+03\n",
      " 7.70000000e-01 1.00000000e+00 3.16666667e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.25000000e+03 3.00000000e+00 7.89473684e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[25] = [0.21937823] \n",
      "Xnew[26] = [2.000e+00 1.000e+00 8.102e+03 1.743e+03 2.000e+00 1.000e+00 8.500e+04\n",
      " 2.000e+00 5.000e+00 2.500e+02 2.000e+00 1.000e+00 5.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[26] = [0.21979481] \n",
      "Xnew[27] = [2.00000000e+00 2.00000000e+00 6.37900000e+03 1.01400000e+03\n",
      " 1.66000000e+00 2.00000000e+00 1.06000000e+05 3.00000000e+00\n",
      " 4.00000000e+00 2.00000000e+02 4.00000000e+00 9.05660377e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[27] = [0.21985716] \n",
      "Xnew[28] = [2.00000000e+00 1.00000000e+00 5.99300000e+03 7.16000000e+02\n",
      " 7.20000000e-01 2.00000000e+00 1.36666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 3.40000000e+02 2.00000000e+00 8.78048780e-01\n",
      " 3.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[28] = [0.2226587] \n",
      "Xnew[29] = [2.00000000e+00 1.00000000e+00 4.55700000e+03 8.44000000e+02\n",
      " 4.96000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 4.00000000e+00 1.24000000e+03 1.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[29] = [0.22259161] \n",
      "Xnew[30] = [2.00000000e+00 1.00000000e+00 4.19900000e+03 8.83000000e+02\n",
      " 1.30000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 3.00000000e+00 8.00000000e+02 1.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[30] = [0.2230469] \n",
      "Xnew[31] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.63000000e+03\n",
      " 1.16580000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.19000000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[31] = [0.22248238] \n",
      "Xnew[32] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.72100000e+03\n",
      " 1.22000000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.87500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[32] = [0.2202872] \n",
      "Xnew[33] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.99500000e+03\n",
      " 1.32420000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.03000000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[33] = [0.22215861] \n",
      "Xnew[34] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 2.08600000e+03\n",
      " 1.22000000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.87500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[34] = [0.21949115] \n",
      "Xnew[35] = [2.00000000e+00 1.00000000e+00 4.19900000e+03 1.06600000e+03\n",
      " 1.30000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.04000000e+03 2.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[35] = [0.22416309] \n",
      "Xnew[36] = [2.00000000e+00 1.00000000e+00 6.01400000e+03 9.09000000e+02\n",
      " 2.00000000e+00 2.00000000e+00 1.17666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.08000000e+03 1.00000000e+00 8.49858357e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[36] = [0.22298285] \n",
      "Xnew[37] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.87000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.02139037e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[37] = [0.22634187] \n",
      "Xnew[38] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.24000000e+03 4.00000000e+00 8.09352518e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[38] = [0.22362426] \n",
      "Xnew[39] = [1.00000000e+00 3.00000000e+00 8.35200000e+03 8.38000000e+02\n",
      " 1.17000000e+00 2.00000000e+00 1.96666667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.24000000e+03 3.00000000e+00 7.62711864e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[39] = [0.22479028] \n",
      "Xnew[40] = [1.00000000e+00 3.00000000e+00 7.97100000e+03 1.02100000e+03\n",
      " 1.10000000e+00 2.00000000e+00 1.97166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 3.00000000e+00 7.60777684e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[40] = [0.21765381] \n",
      "Xnew[41] = [1.00000000e+00 2.00000000e+00 6.62200000e+03 1.04100000e+03\n",
      " 1.19500000e+00 2.00000000e+00 1.91833333e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.30000000e+03 4.00000000e+00 9.38314509e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[41] = [0.22371072] \n",
      "Xnew[42] = [1.00000000e+00 3.00000000e+00 8.98400000e+03 8.31000000e+02\n",
      " 1.00000000e+00 2.00000000e+00 7.33333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 1.00000000e+00 6.81818182e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[42] = [0.22927913] \n",
      "Xnew[43] = [1.00000000e+00 3.00000000e+00 8.48100000e+03 1.07500000e+03\n",
      " 1.75000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.12000000e+03 5.00000000e+00 8.10810811e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[43] = [0.22279194] \n",
      "Xnew[44] = [1.00000000e+00 3.00000000e+00 8.46000000e+03 1.12700000e+03\n",
      " 1.75000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 5.00000000e+00 8.10810811e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[44] = [0.2229748] \n",
      "Xnew[45] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.09352518e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[45] = [0.2301645] \n",
      "Xnew[46] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.08400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.79500000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.35654596e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[46] = [0.22372523] \n",
      "Xnew[47] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.02400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 3.00000000e+00 2.16500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[47] = [0.22242245] \n",
      "Xnew[48] = [2.00000000e+00 2.00000000e+00 5.82600000e+03 7.79000000e+02\n",
      " 7.58000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.08000000e+03 2.00000000e+00 8.37209302e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[48] = [0.22412336] \n",
      "Xnew[49] = [2.00000000e+00 1.00000000e+00 7.21300000e+03 1.38300000e+03\n",
      " 1.30000000e+00 2.00000000e+00 1.45833333e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.17000000e+03 2.00000000e+00 9.60000000e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[49] = [0.22892681] \n",
      "Xnew[50] = [2.00000000e+00 1.00000000e+00 7.26800000e+03 1.48100000e+03\n",
      " 1.03000000e+00 2.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 1.00000000e+00 1.40000000e+03 4.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[50] = [0.22287542] \n",
      "Xnew[51] = [1.00000000e+00 3.00000000e+00 6.15300000e+03 7.87000000e+02\n",
      " 1.50862069e+00 2.00000000e+00 1.05000000e+05 3.00000000e+00\n",
      " 5.00000000e+00 1.78000000e+03 1.00000000e+00 9.52380952e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[51] = [0.22174993] \n",
      "Xnew[52] = [2.00000000e+00 1.00000000e+00 5.27200000e+03 1.03400000e+03\n",
      " 6.29000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 3.00000000e+00 1.31500000e+03 3.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[52] = [0.22234863] \n",
      "Xnew[53] = [2.00000000e+00 1.00000000e+00 7.33600000e+03 1.41300000e+03\n",
      " 1.01000000e+00 2.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 1.00000000e+00 1.60000000e+03 4.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[53] = [0.21851584] \n",
      "Xnew[54] = [1.00000000e+00 3.00000000e+00 7.85100000e+03 1.17200000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.10000000e+03 2.00000000e+00 8.09352518e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[54] = [0.21881503] \n",
      "Xnew[55] = [1.00000000e+00 3.00000000e+00 9.10100000e+03 1.01800000e+03\n",
      " 1.26300000e+00 2.00000000e+00 1.79500000e+05 4.00000000e+00\n",
      " 2.00000000e+00 7.65000000e+02 4.00000000e+00 8.35654596e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[55] = [0.21791017] \n",
      "Xnew[56] = [2.00000000e+00 1.00000000e+00 2.80000000e+03 1.15700000e+03\n",
      " 1.30000000e+00 1.00000000e+00 1.75000000e+05 4.00000000e+00\n",
      " 5.00000000e+00 9.00000000e+01 1.00000000e+00 8.57142857e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[56] = [0.22082746] \n",
      "Xnew[57] = [2.000e+00 1.000e+00 4.476e+03 1.229e+03 4.900e-01 1.000e+00 1.250e+05\n",
      " 3.000e+00 5.000e+00 1.200e+02 1.000e+00 8.000e-01 4.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[57] = [0.22894326] \n",
      "Xnew[58] = [2.000e+00 1.000e+00 8.528e+03 1.149e+03 1.000e+00 2.000e+00 6.250e+04\n",
      " 2.000e+00 4.000e+00 2.900e+03 2.000e+00 9.600e-01 5.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[58] = [0.22629645] \n",
      "Xnew[59] = [2.00000000e+00 1.00000000e+00 2.35600000e+03 8.70000000e+02\n",
      " 5.29411765e+00 1.00000000e+00 3.00000000e+05 6.00000000e+00\n",
      " 4.00000000e+00 3.00000000e+02 1.00000000e+00 6.66666667e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[59] = [0.22860768] \n",
      "Xnew[60] = [2.00000000e+00 1.00000000e+00 1.82600000e+03 5.92000000e+02\n",
      " 3.50000000e-01 1.00000000e+00 9.05000000e+04 2.00000000e+00\n",
      " 5.00000000e+00 1.25000000e+02 1.00000000e+00 9.17127072e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[60] = [0.22019625] \n",
      "Xnew[61] = [2.00000000e+00 1.00000000e+00 7.21800000e+03 1.36400000e+03\n",
      " 3.90000000e+00 1.00000000e+00 1.22500000e+05 3.00000000e+00\n",
      " 5.00000000e+00 4.00000000e+02 1.00000000e+00 8.16326531e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[61] = [0.22433066] \n",
      "Xnew[62] = [1.00000000e+00 3.00000000e+00 7.85000000e+03 7.32000000e+02\n",
      " 1.61190909e+00 1.00000000e+00 7.08333333e+04 2.00000000e+00\n",
      " 2.00000000e+00 4.10000000e+02 2.00000000e+00 8.89411765e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[62] = [0.23322079] \n",
      "Xnew[63] = [2.00000000e+00 1.00000000e+00 1.55100000e+03 1.33400000e+03\n",
      " 4.70000000e+00 1.00000000e+00 2.61666667e+05 6.00000000e+00\n",
      " 4.00000000e+00 3.80000000e+02 3.00000000e+00 8.40764331e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[63] = [0.2207849] \n",
      "Xnew[64] = [2.0000000e+00 1.0000000e+00 6.2400000e+03 1.2450000e+03 5.0000000e+00\n",
      " 1.0000000e+00 1.6750000e+05 4.0000000e+00 4.0000000e+00 3.7000000e+02\n",
      " 1.0000000e+00 4.7761194e-01 3.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], ynew2[64] = [0.21966541] \n",
      "Xnew[65] = [1.00000000e+00 0.00000000e+00 8.71900000e+03 1.13600000e+03\n",
      " 2.50000000e+00 2.00000000e+00 8.33333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 1.16000000e+02 1.00000000e+00 9.60000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[65] = [0.22479421] \n",
      "Xnew[66] = [2.00000000e+00 1.00000000e+00 7.72900000e+03 1.94900000e+03\n",
      " 4.78000000e+00 1.00000000e+00 1.66666667e+05 4.00000000e+00\n",
      " 2.00000000e+00 4.24000000e+02 1.00000000e+00 7.80000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[66] = [0.2181519] \n",
      "Xnew[67] = [2.000e+00 1.000e+00 8.391e+03 9.520e+02 1.600e+00 1.000e+00 4.000e+04\n",
      " 1.000e+00 3.000e+00 1.650e+02 2.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[67] = [0.22296631] \n",
      "Xnew[68] = [2.00000000e+00 1.00000000e+00 4.25000000e+03 1.13700000e+03\n",
      " 1.60000000e+00 1.00000000e+00 1.58333333e+05 4.00000000e+00\n",
      " 4.00000000e+00 1.00000000e+02 2.00000000e+00 6.31578947e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[68] = [0.22339219] \n",
      "Xnew[69] = [1.00000000e+00 3.00000000e+00 5.51300000e+03 9.39000000e+02\n",
      " 8.00000000e-01 2.00000000e+00 1.43500000e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.35000000e+03 1.00000000e+00 8.36236934e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[69] = [0.2319378] \n",
      "Xnew[70] = [1.000e+00 1.000e+00 6.339e+03 4.170e+02 2.500e-01 2.000e+00 3.000e+04\n",
      " 1.000e+00 1.000e+00 5.500e+01 2.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[70] = [0.22254309] \n",
      "Xnew[71] = [2.00000000e+00 1.00000000e+00 4.44600000e+03 6.11000000e+02\n",
      " 7.14000000e-01 1.00000000e+00 6.83333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 4.80000000e+01 2.00000000e+00 9.51219512e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[71] = [0.22352836] \n",
      "Xnew[72] = [2.000e+00 1.000e+00 5.524e+03 8.970e+02 1.800e+00 1.000e+00 1.900e+05\n",
      " 4.000e+00 1.000e+00 2.700e+01 1.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[72] = [0.23128882] \n",
      "Xnew[73] = [2.000e+00 1.000e+00 5.804e+03 7.230e+02 1.200e+00 1.000e+00 1.060e+05\n",
      " 3.000e+00 2.000e+00 1.250e+02 1.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[73] = [0.22765511] \n",
      "Xnew[74] = [2.000e+00 1.000e+00 4.018e+03 5.450e+02 1.000e+00 1.000e+00 1.250e+05\n",
      " 3.000e+00 2.000e+00 6.500e+01 3.000e+00 1.000e+00 2.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[74] = [0.22329333] \n",
      "Xnew[75] = [2.000e+00 1.000e+00 4.196e+03 5.050e+02 1.200e+00 2.000e+00 9.000e+04\n",
      " 2.000e+00 2.000e+00 5.600e+01 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[75] = [0.22284076] \n",
      "Xnew[76] = [2.00000000e+00 1.00000000e+00 4.62300000e+03 7.61000000e+02\n",
      " 1.20000000e+00 2.00000000e+00 1.16666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 5.60000000e+01 3.00000000e+00 8.57142857e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[76] = [0.22648618] \n",
      "Xnew[77] = [1.000e+00 0.000e+00 8.521e+03 1.386e+03 3.700e+00 2.000e+00 0.000e+00\n",
      " 1.000e+00 1.000e+00 1.160e+02 2.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[77] = [0.22497532] \n",
      "Xnew[78] = [1.00000000e+00 3.00000000e+00 8.12400000e+03 1.69100000e+03\n",
      " 2.86486486e+00 2.00000000e+00 1.00000000e+05 3.00000000e+00\n",
      " 3.00000000e+00 1.15000000e+02 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[78] = [0.22683117] \n",
      "Xnew[79] = [2.00000000e+00 1.00000000e+00 9.38900000e+03 1.36400000e+03\n",
      " 4.70000000e+00 1.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 2.00000000e+00 9.00000000e+01 5.00000000e+00 2.30769231e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[79] = [0.2195425] \n",
      "Xnew[80] = [2.000e+00 1.000e+00 7.891e+03 1.110e+03 1.200e+00 2.000e+00 1.650e+05\n",
      " 4.000e+00 2.000e+00 3.300e+01 1.000e+00 1.000e+00 2.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[80] = [0.2174162] \n",
      "Xnew[81] = [1.000e+00 3.000e+00 6.038e+03 7.630e+02 5.000e-01 1.000e+00 6.000e+04\n",
      " 2.000e+00 1.000e+00 6.000e+01 2.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew2[81] = [0.22159171] \n",
      "Xnew[82] = [2.00000000e+00 1.00000000e+00 8.04600000e+03 1.81000000e+03\n",
      " 3.00000000e+00 1.00000000e+00 3.61166667e+05 6.00000000e+00\n",
      " 4.00000000e+00 2.50000000e+02 2.00000000e+00 2.35348408e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[82] = [0.22398278] \n",
      "Xnew[83] = [2.00000000e+00 1.00000000e+00 5.20100000e+03 1.41800000e+03\n",
      " 8.30000000e-01 1.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.25000000e+03 5.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[83] = [0.22470796] \n",
      "Xnew[84] = [2.00000000e+00 1.00000000e+00 6.47800000e+03 1.11400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.35000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.67000000e+03 5.00000000e+00 7.40740741e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[84] = [0.22027537] \n",
      "Xnew[85] = [1.00000000e+00 3.00000000e+00 5.06000000e+03 1.23700000e+03\n",
      " 9.06000000e-01 1.00000000e+00 2.35000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.85000000e+03 3.00000000e+00 7.65957447e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[85] = [0.2252259] \n",
      "Xnew[86] = [2.00000000e+00 1.00000000e+00 6.51700000e+03 1.51800000e+03\n",
      " 1.65000000e+00 1.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.79000000e+03 3.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[86] = [0.22250444] \n",
      "Xnew[87] = [2.00000000e+00 1.00000000e+00 4.53300000e+03 1.49200000e+03\n",
      " 2.50000000e+00 1.00000000e+00 2.30000000e+05 5.00000000e+00\n",
      " 3.00000000e+00 2.14500000e+03 3.00000000e+00 8.69565217e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[87] = [0.22288114] \n",
      "Xnew[88] = [2.00000000e+00 1.00000000e+00 8.15800000e+03 1.09300000e+03\n",
      " 2.00000000e+00 1.00000000e+00 1.40000000e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.37200000e+03 5.00000000e+00 7.14285714e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[88] = [0.2164486] \n",
      "Xnew[89] = [2.00000000e+00 1.00000000e+00 5.80200000e+03 8.46000000e+02\n",
      " 1.15100000e+00 1.00000000e+00 5.25000000e+04 2.00000000e+00\n",
      " 4.00000000e+00 2.13000000e+03 1.00000000e+00 8.57142857e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[89] = [0.2164579] \n",
      "Xnew[90] = [1.00000000e+00 3.00000000e+00 6.08600000e+03 9.58000000e+02\n",
      " 8.00000000e-01 1.00000000e+00 5.66666667e+04 2.00000000e+00\n",
      " 1.00000000e+00 1.84700000e+03 4.00000000e+00 7.94117647e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[90] = [0.22218356] \n",
      "Xnew[91] = [2.00000000e+00 1.00000000e+00 4.62400000e+03 1.09800000e+03\n",
      " 5.00000000e+00 1.00000000e+00 2.83333333e+05 6.00000000e+00\n",
      " 5.00000000e+00 1.83000000e+03 1.00000000e+00 8.82352941e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[91] = [0.2224879] \n",
      "Xnew[92] = [2.00000000e+00 1.00000000e+00 7.27000000e+03 1.84400000e+03\n",
      " 7.50000000e+00 1.00000000e+00 1.77166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.13400000e+03 4.00000000e+00 9.59548448e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[92] = [0.21800822] \n",
      "Xnew[93] = [2.00000000e+00 1.00000000e+00 2.35600000e+03 1.57000000e+03\n",
      " 1.30000000e+00 1.00000000e+00 3.51666667e+05 6.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+02 5.00000000e+00 3.83886256e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[93] = [0.22273001] \n",
      "Xnew[94] = [2.00000000e+00 1.00000000e+00 6.02500000e+03 1.46100000e+03\n",
      " 4.43609023e+00 1.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 4.00000000e+00 3.80000000e+02 1.00000000e+00 4.61538462e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[94] = [0.22259095] \n",
      "Xnew[95] = [2.000000e+00 1.000000e+00 4.368000e+03 1.384000e+03 1.900000e+00\n",
      " 1.000000e+00 1.280000e+05 3.000000e+00 5.000000e+00 3.700000e+02\n",
      " 1.000000e+00 9.765625e-01 2.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      " 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00], ynew2[95] = [0.22082794] \n",
      "Xnew[96] = [2.00000000e+00 1.00000000e+00 3.25600000e+03 9.43000000e+02\n",
      " 1.28205128e+00 1.00000000e+00 1.15000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 3.10000000e+02 4.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[96] = [0.22392061] \n",
      "Xnew[97] = [2.00000000e+00 1.00000000e+00 2.64700000e+03 8.21000000e+02\n",
      " 4.50000000e+00 1.00000000e+00 2.43333333e+05 5.00000000e+00\n",
      " 5.00000000e+00 3.40000000e+02 4.00000000e+00 7.80821918e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[97] = [0.22078761] \n",
      "Xnew[98] = [2.00000000e+00 1.00000000e+00 3.79000000e+02 1.26300000e+03\n",
      " 2.90000000e+00 1.00000000e+00 3.17000000e+05 6.00000000e+00\n",
      " 5.00000000e+00 3.20000000e+02 2.00000000e+00 8.51735016e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[98] = [0.22377369] \n",
      "Xnew[99] = [2.00000000e+00 1.00000000e+00 2.25100000e+03 8.51000000e+02\n",
      " 7.00000000e-01 1.00000000e+00 1.71333333e+05 4.00000000e+00\n",
      " 5.00000000e+00 3.35000000e+02 1.00000000e+00 6.59533074e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew2[99] = [0.22168258] \n",
      "Xnew[100] = [1.000e+00 3.000e+00 6.588e+03 1.233e+03 1.600e+00 1.000e+00 2.000e+05\n",
      " 5.000e+00 2.000e+00 1.220e+03 2.000e+00 7.500e-01 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00], ynew2[100] = [0.22162586] \n",
      "Xnew[101] = [2.00000000e+00 1.00000000e+00 6.02500000e+03 9.74000000e+02\n",
      " 3.00000000e+00 1.00000000e+00 1.33333333e+05 3.00000000e+00\n",
      " 5.00000000e+00 2.44000000e+03 1.00000000e+00 7.50000000e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew2[101] = [0.22186384] \n",
      "Xnew[102] = [2.00000000e+00 1.00000000e+00 4.45900000e+03 7.28000000e+02\n",
      " 2.00000000e-01 1.00000000e+00 7.83333333e+04 2.00000000e+00\n",
      " 3.00000000e+00 1.01500000e+03 1.00000000e+00 7.65957447e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew2[102] = [0.22159404] \n",
      "Xnew[103] = [2.00000000e+00 1.00000000e+00 5.59700000e+03 1.15900000e+03\n",
      " 3.50000000e+00 1.00000000e+00 1.36666667e+05 3.00000000e+00\n",
      " 3.00000000e+00 1.28000000e+03 2.00000000e+00 9.14634146e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew2[103] = [0.21867412] \n",
      "Xnew[104] = [2.00000000e+00 1.00000000e+00 4.07000000e+03 8.59000000e+02\n",
      " 1.00000000e+00 1.00000000e+00 1.35000000e+05 3.00000000e+00\n",
      " 4.00000000e+00 1.34500000e+03 2.00000000e+00 8.14814815e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew2[104] = [0.22727501] \n",
      "Xnew[105] = [2.00000000e+00 1.00000000e+00 4.07000000e+03 1.39700000e+03\n",
      " 1.82000000e+00 1.00000000e+00 6.66666667e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.37000000e+03 1.00000000e+00 9.00000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew2[105] = [0.22076093] \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 106 is out of bounds for axis 0 with size 106",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-622-58cb70d38d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The values of Xnew and its predicted yhat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xnew[%s] = %s, ynew2[%s] = %s \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mynew1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 106 is out of bounds for axis 0 with size 106"
     ]
    }
   ],
   "source": [
    "print(\"The values of Xnew and its predicted yhat\")\n",
    "for loop in range(len(Xnew)):\n",
    "        print(\"Xnew[%s] = %s, ynew2[%s] = %s \" % (loop,Xnew[loop],loop,ynew1[loop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.55091667e-01]\n",
      " [4.50771779e-01]\n",
      " [2.86732525e-01]\n",
      " [6.50462508e-03]\n",
      " [2.86760926e-03]\n",
      " [1.06256664e-01]\n",
      " [2.74972737e-01]\n",
      " [1.51020288e-03]\n",
      " [5.07399440e-03]\n",
      " [4.90439147e-01]\n",
      " [4.28923965e-01]\n",
      " [4.36652482e-01]\n",
      " [1.69631839e-03]\n",
      " [6.72712922e-03]\n",
      " [9.31274891e-03]\n",
      " [1.98083669e-01]\n",
      " [2.74429888e-01]\n",
      " [8.99290442e-02]\n",
      " [4.73234057e-02]\n",
      " [2.95117497e-03]\n",
      " [1.13519430e-01]\n",
      " [5.95990717e-02]\n",
      " [6.64986908e-01]\n",
      " [9.00623202e-03]\n",
      " [1.59880042e-01]\n",
      " [3.87434661e-02]\n",
      " [3.55118275e-01]\n",
      " [2.69834101e-02]\n",
      " [1.26285881e-01]\n",
      " [6.59585536e-01]\n",
      " [4.35808897e-01]\n",
      " [3.96761715e-01]\n",
      " [3.77796233e-01]\n",
      " [3.65995586e-01]\n",
      " [3.50248456e-01]\n",
      " [2.58389890e-01]\n",
      " [2.01697558e-01]\n",
      " [2.72724748e-01]\n",
      " [4.10862684e-01]\n",
      " [1.16363466e-01]\n",
      " [1.01134330e-01]\n",
      " [4.18339968e-02]\n",
      " [4.55198050e-01]\n",
      " [1.39744580e-02]\n",
      " [1.34601295e-02]\n",
      " [2.73045123e-01]\n",
      " [4.90200371e-01]\n",
      " [6.40920997e-01]\n",
      " [3.68103594e-01]\n",
      " [1.10449314e-01]\n",
      " [3.75878841e-01]\n",
      " [2.36062914e-01]\n",
      " [2.71329522e-01]\n",
      " [3.22663009e-01]\n",
      " [6.76634908e-02]\n",
      " [2.45134860e-01]\n",
      " [4.13561821e-01]\n",
      " [2.91104317e-01]\n",
      " [1.01180792e-01]\n",
      " [1.83627248e-01]\n",
      " [5.34301281e-01]\n",
      " [7.04384565e-01]\n",
      " [8.61271024e-01]\n",
      " [9.84027982e-03]\n",
      " [7.51441121e-01]\n",
      " [1.67455673e-01]\n",
      " [1.61422074e-01]\n",
      " [8.69903266e-01]\n",
      " [1.55122280e-02]\n",
      " [1.37567192e-01]\n",
      " [3.48300636e-01]\n",
      " [2.92627513e-02]\n",
      " [7.24184394e-01]\n",
      " [3.07684183e-01]\n",
      " [6.74868464e-01]\n",
      " [1.83988988e-01]\n",
      " [6.26388431e-01]\n",
      " [9.71595645e-02]\n",
      " [7.90083289e-01]\n",
      " [9.92989540e-03]\n",
      " [4.14138854e-01]\n",
      " [1.03145868e-01]\n",
      " [3.16713274e-01]\n",
      " [2.39580452e-01]\n",
      " [2.12389499e-01]\n",
      " [1.98204100e-01]\n",
      " [4.91970479e-01]\n",
      " [5.85672855e-01]\n",
      " [6.34881854e-03]\n",
      " [2.77149498e-01]\n",
      " [7.30312169e-02]\n",
      " [7.03085124e-01]\n",
      " [8.08209181e-04]\n",
      " [6.77645206e-04]\n",
      " [1.65498108e-01]\n",
      " [4.89911139e-02]\n",
      " [4.67494130e-03]\n",
      " [1.47623837e-01]\n",
      " [2.99629986e-01]\n",
      " [2.99865365e-01]\n",
      " [6.68329000e-03]\n",
      " [4.05409902e-01]\n",
      " [4.01833177e-01]\n",
      " [2.61349022e-01]\n",
      " [5.97078621e-01]\n",
      " [3.94737124e-02]\n",
      " [1.81569755e-02]\n",
      " [1.28263444e-01]\n",
      " [6.44216776e-01]\n",
      " [1.09733790e-01]\n",
      " [3.95701945e-01]\n",
      " [1.24799609e-02]\n",
      " [1.13406777e-03]\n",
      " [1.93417072e-04]\n",
      " [7.28070736e-04]\n",
      " [8.32974911e-04]\n",
      " [3.67064655e-01]\n",
      " [4.28075194e-02]\n",
      " [3.92623246e-02]\n",
      " [1.46168470e-03]\n",
      " [9.90033150e-05]\n",
      " [9.06035304e-03]\n",
      " [9.22530890e-04]\n",
      " [4.45306301e-04]\n",
      " [1.55308560e-04]\n",
      " [4.00993944e-04]\n",
      " [1.51034887e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(ynew2)\n",
    "# create excel writer\n",
    "# write dataframe to excel sheet named 'marks'\n",
    "writer = pd.ExcelWriter('predict_cost.xlsx')\n",
    "ynew2_df = pd.DataFrame (ynew2)\n",
    "ynew2_df.to_excel(writer, '18')\n",
    "# save the excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew3 = model3.predict(Xnew_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of Xnew and its predicted yhat\n",
      "Xnew[0] = [2.00000000e+00 1.00000000e+00 1.04390000e+04 7.00000000e+02\n",
      " 3.10000000e+00 1.00000000e+00 6.71666667e+04 2.00000000e+00\n",
      " 2.00000000e+00 9.80000000e+02 2.00000000e+00 1.48883375e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[0] = [0.22859916] \n",
      "Xnew[1] = [2.00e+00 1.00e+00 4.35e+03 2.59e+02 4.00e-01 1.00e+00 4.00e+04 1.00e+00\n",
      " 2.00e+00 3.00e+01 1.00e+00 1.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 1.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00], ynew3[1] = [0.22847998] \n",
      "Xnew[2] = [1.00000000e+00 1.00000000e+00 2.24000000e+03 8.16000000e+02\n",
      " 4.60000000e-01 1.00000000e+00 6.58333333e+04 2.00000000e+00\n",
      " 2.00000000e+00 8.40000000e+01 1.00000000e+00 8.65822785e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[2] = [0.22792336] \n",
      "Xnew[3] = [1.00000000e+00 3.00000000e+00 5.92200000e+03 7.02000000e+02\n",
      " 5.98425197e-01 1.00000000e+00 8.75000000e+04 2.00000000e+00\n",
      " 3.00000000e+00 8.25000000e+02 2.00000000e+00 9.14285714e-01\n",
      " 4.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[3] = [0.22817472] \n",
      "Xnew[4] = [2.000e+00 1.000e+00 5.720e+03 9.940e+02 1.133e+00 1.000e+00 1.000e+05\n",
      " 3.000e+00 1.000e+00 6.000e+02 3.000e+00 9.000e-01 4.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[4] = [0.2280769] \n",
      "Xnew[5] = [2.00000000e+00 1.00000000e+00 8.82400000e+03 1.05200000e+03\n",
      " 2.67650000e+00 1.00000000e+00 7.94000000e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.20000000e+02 2.00000000e+00 5.54156171e-02\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[5] = [0.22786003] \n",
      "Xnew[6] = [2.00000000e+00 1.00000000e+00 7.81400000e+03 2.22900000e+03\n",
      " 1.11600000e+01 1.00000000e+00 1.48333333e+05 6.00000000e+00\n",
      " 5.00000000e+00 2.50000000e+02 1.00000000e+00 2.35955056e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[6] = [0.22839233] \n",
      "Xnew[7] = [2.00000000e+00 1.00000000e+00 7.53400000e+03 1.38300000e+03\n",
      " 7.00000000e+00 1.00000000e+00 1.98333333e+05 4.00000000e+00\n",
      " 2.00000000e+00 1.29000000e+03 4.00000000e+00 8.06722689e-01\n",
      " 5.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[7] = [0.22848225] \n",
      "Xnew[8] = [2.00000000e+00 1.00000000e+00 4.87200000e+03 1.30600000e+03\n",
      " 3.40000000e+00 1.00000000e+00 2.87000000e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.36000000e+03 5.00000000e+00 8.36236934e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[8] = [0.22836334] \n",
      "Xnew[9] = [2.00000000e+00 1.00000000e+00 3.10300000e+03 8.23000000e+02\n",
      " 2.50000000e+00 1.00000000e+00 2.46666667e+05 5.00000000e+00\n",
      " 3.00000000e+00 1.35000000e+03 1.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[9] = [0.22826937] \n",
      "Xnew[10] = [2.00000000e+00 1.00000000e+00 8.87100000e+03 1.08100000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.31666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 2.00000000e+00 8.73417722e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[10] = [0.22853202] \n",
      "Xnew[11] = [2.00000000e+00 1.00000000e+00 8.87100000e+03 1.17300000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.31666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 2.00000000e+00 8.73417722e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[11] = [0.2285335] \n",
      "Xnew[12] = [2.00000000e+00 1.00000000e+00 4.75600000e+03 1.07100000e+03\n",
      " 7.60000000e-01 1.00000000e+00 3.16666667e+05 6.00000000e+00\n",
      " 1.00000000e+00 1.25000000e+03 5.00000000e+00 7.89473684e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[12] = [0.22847193] \n",
      "Xnew[13] = [1.00000000e+00 1.00000000e+00 5.86600000e+03 7.97000000e+02\n",
      " 7.50000000e-01 2.00000000e+00 1.15833333e+05 3.00000000e+00\n",
      " 1.00000000e+00 7.28000000e+02 3.00000000e+00 8.63309353e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[13] = [0.22852087] \n",
      "Xnew[14] = [1.00000000e+00 3.00000000e+00 5.86600000e+03 7.97000000e+02\n",
      " 7.50000000e-01 2.00000000e+00 1.30000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 7.20000000e+02 3.00000000e+00 8.07692308e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[14] = [0.22860163] \n",
      "Xnew[15] = [2.00000000e+00 1.00000000e+00 5.14400000e+03 1.12400000e+03\n",
      " 1.73000000e+00 1.00000000e+00 3.05000000e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.35000000e+03 2.00000000e+00 8.19672131e-01\n",
      " 4.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[15] = [0.22846052] \n",
      "Xnew[16] = [2.00000000e+00 1.00000000e+00 6.75500000e+03 1.24900000e+03\n",
      " 1.00000000e+01 2.00000000e+00 1.97833333e+05 4.00000000e+00\n",
      " 5.00000000e+00 2.00000000e+03 2.00000000e+00 7.93597304e-01\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[16] = [0.22833562] \n",
      "Xnew[17] = [2.00000000e+00 1.00000000e+00 4.68700000e+03 8.21000000e+02\n",
      " 1.90000000e+00 1.00000000e+00 3.74053100e+04 4.00000000e+00\n",
      " 3.00000000e+00 5.80000000e+01 1.00000000e+00 9.99056016e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[17] = [0.22829047] \n",
      "Xnew[18] = [1.00000000e+00 3.00000000e+00 4.94900000e+03 7.11000000e+02\n",
      " 1.50000000e+00 2.00000000e+00 8.25000000e+04 2.00000000e+00\n",
      " 1.00000000e+00 9.70000000e+02 3.00000000e+00 8.48484848e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[18] = [0.22850037] \n",
      "Xnew[19] = [1.00000000e+00 3.00000000e+00 8.61700000e+03 1.09200000e+03\n",
      " 4.50000000e+00 2.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.42500000e+03 2.00000000e+00 7.38461538e-01\n",
      " 5.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[19] = [0.2286934] \n",
      "Xnew[20] = [2.00000000e+00 2.00000000e+00 5.53900000e+03 1.12600000e+03\n",
      " 4.15384615e+00 1.00000000e+00 3.25000000e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.43300000e+03 2.00000000e+00 7.69230769e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[20] = [0.22845733] \n",
      "Xnew[21] = [2.00000000e+00 1.00000000e+00 5.60600000e+03 1.30300000e+03\n",
      " 2.34500000e+00 1.00000000e+00 2.73333333e+05 6.00000000e+00\n",
      " 4.00000000e+00 1.32500000e+03 1.00000000e+00 6.76829268e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[21] = [0.22822273] \n",
      "Xnew[22] = [2.00000000e+00 1.00000000e+00 4.04900000e+03 1.03300000e+03\n",
      " 2.40000000e+00 1.00000000e+00 2.53333333e+05 6.00000000e+00\n",
      " 3.00000000e+00 1.25000000e+03 1.00000000e+00 8.88157895e-01\n",
      " 3.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[22] = [0.22839436] \n",
      "Xnew[23] = [2.00000000e+00 1.00000000e+00 8.54000000e+03 1.59500000e+03\n",
      " 1.50000000e+01 1.00000000e+00 2.60000000e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.60000000e+03 3.00000000e+00 7.69230769e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[23] = [0.2284196] \n",
      "Xnew[24] = [2.00000000e+00 1.00000000e+00 4.67100000e+03 1.08100000e+03\n",
      " 2.60000000e+00 1.00000000e+00 2.66666667e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.18000000e+03 2.00000000e+00 7.87500000e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[24] = [0.22841316] \n",
      "Xnew[25] = [2.00000000e+00 1.00000000e+00 4.25300000e+03 1.07300000e+03\n",
      " 7.70000000e-01 1.00000000e+00 3.16666667e+05 6.00000000e+00\n",
      " 2.00000000e+00 1.25000000e+03 3.00000000e+00 7.89473684e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[25] = [0.22842127] \n",
      "Xnew[26] = [2.000e+00 1.000e+00 8.102e+03 1.743e+03 2.000e+00 1.000e+00 8.500e+04\n",
      " 2.000e+00 5.000e+00 2.500e+02 2.000e+00 1.000e+00 5.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[26] = [0.22815311] \n",
      "Xnew[27] = [2.00000000e+00 2.00000000e+00 6.37900000e+03 1.01400000e+03\n",
      " 1.66000000e+00 2.00000000e+00 1.06000000e+05 3.00000000e+00\n",
      " 4.00000000e+00 2.00000000e+02 4.00000000e+00 9.05660377e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[27] = [0.22847879] \n",
      "Xnew[28] = [2.00000000e+00 1.00000000e+00 5.99300000e+03 7.16000000e+02\n",
      " 7.20000000e-01 2.00000000e+00 1.36666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 3.40000000e+02 2.00000000e+00 8.78048780e-01\n",
      " 3.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[28] = [0.22845289] \n",
      "Xnew[29] = [2.00000000e+00 1.00000000e+00 4.55700000e+03 8.44000000e+02\n",
      " 4.96000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 4.00000000e+00 1.24000000e+03 1.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[29] = [0.22871706] \n",
      "Xnew[30] = [2.00000000e+00 1.00000000e+00 4.19900000e+03 8.83000000e+02\n",
      " 1.30000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 3.00000000e+00 8.00000000e+02 1.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[30] = [0.22859982] \n",
      "Xnew[31] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.63000000e+03\n",
      " 1.16580000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.19000000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[31] = [0.2288307] \n",
      "Xnew[32] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.72100000e+03\n",
      " 1.22000000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.87500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[32] = [0.22883931] \n",
      "Xnew[33] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 1.99500000e+03\n",
      " 1.32420000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.03000000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[33] = [0.22884268] \n",
      "Xnew[34] = [2.00000000e+00 1.00000000e+00 8.11000000e+03 2.08600000e+03\n",
      " 1.22000000e+00 2.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.87500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[34] = [0.22884762] \n",
      "Xnew[35] = [2.00000000e+00 1.00000000e+00 4.19900000e+03 1.06600000e+03\n",
      " 1.30000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.04000000e+03 2.00000000e+00 8.10810811e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[35] = [0.22869506] \n",
      "Xnew[36] = [2.00000000e+00 1.00000000e+00 6.01400000e+03 9.09000000e+02\n",
      " 2.00000000e+00 2.00000000e+00 1.17666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.08000000e+03 1.00000000e+00 8.49858357e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[36] = [0.22846594] \n",
      "Xnew[37] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.87000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.02139037e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[37] = [0.22866729] \n",
      "Xnew[38] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.24000000e+03 4.00000000e+00 8.09352518e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[38] = [0.2286067] \n",
      "Xnew[39] = [1.00000000e+00 3.00000000e+00 8.35200000e+03 8.38000000e+02\n",
      " 1.17000000e+00 2.00000000e+00 1.96666667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.24000000e+03 3.00000000e+00 7.62711864e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[39] = [0.22874951] \n",
      "Xnew[40] = [1.00000000e+00 3.00000000e+00 7.97100000e+03 1.02100000e+03\n",
      " 1.10000000e+00 2.00000000e+00 1.97166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 3.00000000e+00 7.60777684e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[40] = [0.2287541] \n",
      "Xnew[41] = [1.00000000e+00 2.00000000e+00 6.62200000e+03 1.04100000e+03\n",
      " 1.19500000e+00 2.00000000e+00 1.91833333e+05 4.00000000e+00\n",
      " 1.00000000e+00 1.30000000e+03 4.00000000e+00 9.38314509e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[41] = [0.22872093] \n",
      "Xnew[42] = [1.00000000e+00 3.00000000e+00 8.98400000e+03 8.31000000e+02\n",
      " 1.00000000e+00 2.00000000e+00 7.33333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 1.00000000e+00 6.81818182e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[42] = [0.22863498] \n",
      "Xnew[43] = [1.00000000e+00 3.00000000e+00 8.48100000e+03 1.07500000e+03\n",
      " 1.75000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.12000000e+03 5.00000000e+00 8.10810811e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[43] = [0.2287941] \n",
      "Xnew[44] = [1.00000000e+00 3.00000000e+00 8.46000000e+03 1.12700000e+03\n",
      " 1.75000000e+00 2.00000000e+00 1.85000000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.20000000e+03 5.00000000e+00 8.10810811e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[44] = [0.22879305] \n",
      "Xnew[45] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.55700000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.09352518e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[45] = [0.22866592] \n",
      "Xnew[46] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.08400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.79500000e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.16500000e+03 4.00000000e+00 8.35654596e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[46] = [0.22864842] \n",
      "Xnew[47] = [2.00000000e+00 1.00000000e+00 7.48600000e+03 2.02400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.91166667e+05 4.00000000e+00\n",
      " 3.00000000e+00 2.16500000e+03 4.00000000e+00 7.84655623e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[47] = [0.22855902] \n",
      "Xnew[48] = [2.00000000e+00 2.00000000e+00 5.82600000e+03 7.79000000e+02\n",
      " 7.58000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.08000000e+03 2.00000000e+00 8.37209302e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[48] = [0.2288506] \n",
      "Xnew[49] = [2.00000000e+00 1.00000000e+00 7.21300000e+03 1.38300000e+03\n",
      " 1.30000000e+00 2.00000000e+00 1.45833333e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.17000000e+03 2.00000000e+00 9.60000000e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[49] = [0.2287791] \n",
      "Xnew[50] = [2.00000000e+00 1.00000000e+00 7.26800000e+03 1.48100000e+03\n",
      " 1.03000000e+00 2.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 1.00000000e+00 1.40000000e+03 4.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[50] = [0.2288298] \n",
      "Xnew[51] = [1.00000000e+00 3.00000000e+00 6.15300000e+03 7.87000000e+02\n",
      " 1.50862069e+00 2.00000000e+00 1.05000000e+05 3.00000000e+00\n",
      " 5.00000000e+00 1.78000000e+03 1.00000000e+00 9.52380952e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[51] = [0.2281816] \n",
      "Xnew[52] = [2.00000000e+00 1.00000000e+00 5.27200000e+03 1.03400000e+03\n",
      " 6.29000000e-01 2.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 3.00000000e+00 1.31500000e+03 3.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[52] = [0.22872218] \n",
      "Xnew[53] = [2.00000000e+00 1.00000000e+00 7.33600000e+03 1.41300000e+03\n",
      " 1.01000000e+00 2.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 1.00000000e+00 1.60000000e+03 4.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[53] = [0.22887045] \n",
      "Xnew[54] = [1.00000000e+00 3.00000000e+00 7.85100000e+03 1.17200000e+03\n",
      " 1.50000000e+00 2.00000000e+00 1.85333333e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.10000000e+03 2.00000000e+00 8.09352518e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[54] = [0.22880006] \n",
      "Xnew[55] = [1.00000000e+00 3.00000000e+00 9.10100000e+03 1.01800000e+03\n",
      " 1.26300000e+00 2.00000000e+00 1.79500000e+05 4.00000000e+00\n",
      " 2.00000000e+00 7.65000000e+02 4.00000000e+00 8.35654596e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[55] = [0.22872302] \n",
      "Xnew[56] = [2.00000000e+00 1.00000000e+00 2.80000000e+03 1.15700000e+03\n",
      " 1.30000000e+00 1.00000000e+00 1.75000000e+05 4.00000000e+00\n",
      " 5.00000000e+00 9.00000000e+01 1.00000000e+00 8.57142857e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[56] = [0.22802377] \n",
      "Xnew[57] = [2.000e+00 1.000e+00 4.476e+03 1.229e+03 4.900e-01 1.000e+00 1.250e+05\n",
      " 3.000e+00 5.000e+00 1.200e+02 1.000e+00 8.000e-01 4.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[57] = [0.22807398] \n",
      "Xnew[58] = [2.000e+00 1.000e+00 8.528e+03 1.149e+03 1.000e+00 2.000e+00 6.250e+04\n",
      " 2.000e+00 4.000e+00 2.900e+03 2.000e+00 9.600e-01 5.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[58] = [0.22853383] \n",
      "Xnew[59] = [2.00000000e+00 1.00000000e+00 2.35600000e+03 8.70000000e+02\n",
      " 5.29411765e+00 1.00000000e+00 3.00000000e+05 6.00000000e+00\n",
      " 4.00000000e+00 3.00000000e+02 1.00000000e+00 6.66666667e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[59] = [0.2280648] \n",
      "Xnew[60] = [2.00000000e+00 1.00000000e+00 1.82600000e+03 5.92000000e+02\n",
      " 3.50000000e-01 1.00000000e+00 9.05000000e+04 2.00000000e+00\n",
      " 5.00000000e+00 1.25000000e+02 1.00000000e+00 9.17127072e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[60] = [0.22772527] \n",
      "Xnew[61] = [2.00000000e+00 1.00000000e+00 7.21800000e+03 1.36400000e+03\n",
      " 3.90000000e+00 1.00000000e+00 1.22500000e+05 3.00000000e+00\n",
      " 5.00000000e+00 4.00000000e+02 1.00000000e+00 8.16326531e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[61] = [0.22797033] \n",
      "Xnew[62] = [1.00000000e+00 3.00000000e+00 7.85000000e+03 7.32000000e+02\n",
      " 1.61190909e+00 1.00000000e+00 7.08333333e+04 2.00000000e+00\n",
      " 2.00000000e+00 4.10000000e+02 2.00000000e+00 8.89411765e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[62] = [0.22807908] \n",
      "Xnew[63] = [2.00000000e+00 1.00000000e+00 1.55100000e+03 1.33400000e+03\n",
      " 4.70000000e+00 1.00000000e+00 2.61666667e+05 6.00000000e+00\n",
      " 4.00000000e+00 3.80000000e+02 3.00000000e+00 8.40764331e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[63] = [0.22811237] \n",
      "Xnew[64] = [2.0000000e+00 1.0000000e+00 6.2400000e+03 1.2450000e+03 5.0000000e+00\n",
      " 1.0000000e+00 1.6750000e+05 4.0000000e+00 4.0000000e+00 3.7000000e+02\n",
      " 1.0000000e+00 4.7761194e-01 3.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], ynew3[64] = [0.22808784] \n",
      "Xnew[65] = [1.00000000e+00 0.00000000e+00 8.71900000e+03 1.13600000e+03\n",
      " 2.50000000e+00 2.00000000e+00 8.33333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 1.16000000e+02 1.00000000e+00 9.60000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[65] = [0.22823319] \n",
      "Xnew[66] = [2.00000000e+00 1.00000000e+00 7.72900000e+03 1.94900000e+03\n",
      " 4.78000000e+00 1.00000000e+00 1.66666667e+05 4.00000000e+00\n",
      " 2.00000000e+00 4.24000000e+02 1.00000000e+00 7.80000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[66] = [0.22820923] \n",
      "Xnew[67] = [2.000e+00 1.000e+00 8.391e+03 9.520e+02 1.600e+00 1.000e+00 4.000e+04\n",
      " 1.000e+00 3.000e+00 1.650e+02 2.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[67] = [0.22795644] \n",
      "Xnew[68] = [2.00000000e+00 1.00000000e+00 4.25000000e+03 1.13700000e+03\n",
      " 1.60000000e+00 1.00000000e+00 1.58333333e+05 4.00000000e+00\n",
      " 4.00000000e+00 1.00000000e+02 2.00000000e+00 6.31578947e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[68] = [0.22807145] \n",
      "Xnew[69] = [1.00000000e+00 3.00000000e+00 5.51300000e+03 9.39000000e+02\n",
      " 8.00000000e-01 2.00000000e+00 1.43500000e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.35000000e+03 1.00000000e+00 8.36236934e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[69] = [0.2283895] \n",
      "Xnew[70] = [1.000e+00 1.000e+00 6.339e+03 4.170e+02 2.500e-01 2.000e+00 3.000e+04\n",
      " 1.000e+00 1.000e+00 5.500e+01 2.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[70] = [0.22848487] \n",
      "Xnew[71] = [2.00000000e+00 1.00000000e+00 4.44600000e+03 6.11000000e+02\n",
      " 7.14000000e-01 1.00000000e+00 6.83333333e+04 2.00000000e+00\n",
      " 1.00000000e+00 4.80000000e+01 2.00000000e+00 9.51219512e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[71] = [0.22851178] \n",
      "Xnew[72] = [2.000e+00 1.000e+00 5.524e+03 8.970e+02 1.800e+00 1.000e+00 1.900e+05\n",
      " 4.000e+00 1.000e+00 2.700e+01 1.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[72] = [0.22877151] \n",
      "Xnew[73] = [2.000e+00 1.000e+00 5.804e+03 7.230e+02 1.200e+00 1.000e+00 1.060e+05\n",
      " 3.000e+00 2.000e+00 1.250e+02 1.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[73] = [0.22856927] \n",
      "Xnew[74] = [2.000e+00 1.000e+00 4.018e+03 5.450e+02 1.000e+00 1.000e+00 1.250e+05\n",
      " 3.000e+00 2.000e+00 6.500e+01 3.000e+00 1.000e+00 2.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[74] = [0.22828987] \n",
      "Xnew[75] = [2.000e+00 1.000e+00 4.196e+03 5.050e+02 1.200e+00 2.000e+00 9.000e+04\n",
      " 2.000e+00 2.000e+00 5.600e+01 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[75] = [0.22841334] \n",
      "Xnew[76] = [2.00000000e+00 1.00000000e+00 4.62300000e+03 7.61000000e+02\n",
      " 1.20000000e+00 2.00000000e+00 1.16666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 5.60000000e+01 3.00000000e+00 8.57142857e-01\n",
      " 2.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[76] = [0.22852385] \n",
      "Xnew[77] = [1.000e+00 0.000e+00 8.521e+03 1.386e+03 3.700e+00 2.000e+00 0.000e+00\n",
      " 1.000e+00 1.000e+00 1.160e+02 2.000e+00 1.000e+00 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[77] = [0.22815824] \n",
      "Xnew[78] = [1.00000000e+00 3.00000000e+00 8.12400000e+03 1.69100000e+03\n",
      " 2.86486486e+00 2.00000000e+00 1.00000000e+05 3.00000000e+00\n",
      " 3.00000000e+00 1.15000000e+02 1.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[78] = [0.2282027] \n",
      "Xnew[79] = [2.00000000e+00 1.00000000e+00 9.38900000e+03 1.36400000e+03\n",
      " 4.70000000e+00 1.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 2.00000000e+00 9.00000000e+01 5.00000000e+00 2.30769231e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[79] = [0.22828081] \n",
      "Xnew[80] = [2.000e+00 1.000e+00 7.891e+03 1.110e+03 1.200e+00 2.000e+00 1.650e+05\n",
      " 4.000e+00 2.000e+00 3.300e+01 1.000e+00 1.000e+00 2.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[80] = [0.2283589] \n",
      "Xnew[81] = [1.000e+00 3.000e+00 6.038e+03 7.630e+02 5.000e-01 1.000e+00 6.000e+04\n",
      " 2.000e+00 1.000e+00 6.000e+01 2.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 0.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00], ynew3[81] = [0.22840205] \n",
      "Xnew[82] = [2.00000000e+00 1.00000000e+00 8.04600000e+03 1.81000000e+03\n",
      " 3.00000000e+00 1.00000000e+00 3.61166667e+05 6.00000000e+00\n",
      " 4.00000000e+00 2.50000000e+02 2.00000000e+00 2.35348408e-01\n",
      " 5.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[82] = [0.22833112] \n",
      "Xnew[83] = [2.00000000e+00 1.00000000e+00 5.20100000e+03 1.41800000e+03\n",
      " 8.30000000e-01 1.00000000e+00 2.15000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.25000000e+03 5.00000000e+00 8.37209302e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[83] = [0.22846079] \n",
      "Xnew[84] = [2.00000000e+00 1.00000000e+00 6.47800000e+03 1.11400000e+03\n",
      " 1.40000000e+00 1.00000000e+00 1.35000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 1.67000000e+03 5.00000000e+00 7.40740741e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[84] = [0.22840855] \n",
      "Xnew[85] = [1.00000000e+00 3.00000000e+00 5.06000000e+03 1.23700000e+03\n",
      " 9.06000000e-01 1.00000000e+00 2.35000000e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.85000000e+03 3.00000000e+00 7.65957447e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[85] = [0.22842407] \n",
      "Xnew[86] = [2.00000000e+00 1.00000000e+00 6.51700000e+03 1.51800000e+03\n",
      " 1.65000000e+00 1.00000000e+00 2.15333333e+05 5.00000000e+00\n",
      " 2.00000000e+00 1.79000000e+03 3.00000000e+00 8.35913313e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[86] = [0.22844756] \n",
      "Xnew[87] = [2.00000000e+00 1.00000000e+00 4.53300000e+03 1.49200000e+03\n",
      " 2.50000000e+00 1.00000000e+00 2.30000000e+05 5.00000000e+00\n",
      " 3.00000000e+00 2.14500000e+03 3.00000000e+00 8.69565217e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[87] = [0.2282336] \n",
      "Xnew[88] = [2.00000000e+00 1.00000000e+00 8.15800000e+03 1.09300000e+03\n",
      " 2.00000000e+00 1.00000000e+00 1.40000000e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.37200000e+03 5.00000000e+00 7.14285714e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[88] = [0.22826022] \n",
      "Xnew[89] = [2.00000000e+00 1.00000000e+00 5.80200000e+03 8.46000000e+02\n",
      " 1.15100000e+00 1.00000000e+00 5.25000000e+04 2.00000000e+00\n",
      " 4.00000000e+00 2.13000000e+03 1.00000000e+00 8.57142857e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[89] = [0.22819817] \n",
      "Xnew[90] = [1.00000000e+00 3.00000000e+00 6.08600000e+03 9.58000000e+02\n",
      " 8.00000000e-01 1.00000000e+00 5.66666667e+04 2.00000000e+00\n",
      " 1.00000000e+00 1.84700000e+03 4.00000000e+00 7.94117647e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[90] = [0.2283594] \n",
      "Xnew[91] = [2.00000000e+00 1.00000000e+00 4.62400000e+03 1.09800000e+03\n",
      " 5.00000000e+00 1.00000000e+00 2.83333333e+05 6.00000000e+00\n",
      " 5.00000000e+00 1.83000000e+03 1.00000000e+00 8.82352941e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[91] = [0.2283046] \n",
      "Xnew[92] = [2.00000000e+00 1.00000000e+00 7.27000000e+03 1.84400000e+03\n",
      " 7.50000000e+00 1.00000000e+00 1.77166667e+05 4.00000000e+00\n",
      " 1.00000000e+00 2.13400000e+03 4.00000000e+00 9.59548448e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[92] = [0.22844815] \n",
      "Xnew[93] = [2.00000000e+00 1.00000000e+00 2.35600000e+03 1.57000000e+03\n",
      " 1.30000000e+00 1.00000000e+00 3.51666667e+05 6.00000000e+00\n",
      " 1.00000000e+00 3.00000000e+02 5.00000000e+00 3.83886256e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[93] = [0.2281802] \n",
      "Xnew[94] = [2.00000000e+00 1.00000000e+00 6.02500000e+03 1.46100000e+03\n",
      " 4.43609023e+00 1.00000000e+00 1.08333333e+05 3.00000000e+00\n",
      " 4.00000000e+00 3.80000000e+02 1.00000000e+00 4.61538462e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[94] = [0.22795859] \n",
      "Xnew[95] = [2.000000e+00 1.000000e+00 4.368000e+03 1.384000e+03 1.900000e+00\n",
      " 1.000000e+00 1.280000e+05 3.000000e+00 5.000000e+00 3.700000e+02\n",
      " 1.000000e+00 9.765625e-01 2.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00\n",
      " 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      " 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00], ynew3[95] = [0.22777656] \n",
      "Xnew[96] = [2.00000000e+00 1.00000000e+00 3.25600000e+03 9.43000000e+02\n",
      " 1.28205128e+00 1.00000000e+00 1.15000000e+05 3.00000000e+00\n",
      " 1.00000000e+00 3.10000000e+02 4.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[96] = [0.2279568] \n",
      "Xnew[97] = [2.00000000e+00 1.00000000e+00 2.64700000e+03 8.21000000e+02\n",
      " 4.50000000e+00 1.00000000e+00 2.43333333e+05 5.00000000e+00\n",
      " 5.00000000e+00 3.40000000e+02 4.00000000e+00 7.80821918e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[97] = [0.22793317] \n",
      "Xnew[98] = [2.00000000e+00 1.00000000e+00 3.79000000e+02 1.26300000e+03\n",
      " 2.90000000e+00 1.00000000e+00 3.17000000e+05 6.00000000e+00\n",
      " 5.00000000e+00 3.20000000e+02 2.00000000e+00 8.51735016e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[98] = [0.22798663] \n",
      "Xnew[99] = [2.00000000e+00 1.00000000e+00 2.25100000e+03 8.51000000e+02\n",
      " 7.00000000e-01 1.00000000e+00 1.71333333e+05 4.00000000e+00\n",
      " 5.00000000e+00 3.35000000e+02 1.00000000e+00 6.59533074e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00], ynew3[99] = [0.2277408] \n",
      "Xnew[100] = [1.000e+00 3.000e+00 6.588e+03 1.233e+03 1.600e+00 1.000e+00 2.000e+05\n",
      " 5.000e+00 2.000e+00 1.220e+03 2.000e+00 7.500e-01 3.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00], ynew3[100] = [0.22807235] \n",
      "Xnew[101] = [2.00000000e+00 1.00000000e+00 6.02500000e+03 9.74000000e+02\n",
      " 3.00000000e+00 1.00000000e+00 1.33333333e+05 3.00000000e+00\n",
      " 5.00000000e+00 2.44000000e+03 1.00000000e+00 7.50000000e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[101] = [0.22812545] \n",
      "Xnew[102] = [2.00000000e+00 1.00000000e+00 4.45900000e+03 7.28000000e+02\n",
      " 2.00000000e-01 1.00000000e+00 7.83333333e+04 2.00000000e+00\n",
      " 3.00000000e+00 1.01500000e+03 1.00000000e+00 7.65957447e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[102] = [0.22800696] \n",
      "Xnew[103] = [2.00000000e+00 1.00000000e+00 5.59700000e+03 1.15900000e+03\n",
      " 3.50000000e+00 1.00000000e+00 1.36666667e+05 3.00000000e+00\n",
      " 3.00000000e+00 1.28000000e+03 2.00000000e+00 9.14634146e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[103] = [0.22818172] \n",
      "Xnew[104] = [2.00000000e+00 1.00000000e+00 4.07000000e+03 8.59000000e+02\n",
      " 1.00000000e+00 1.00000000e+00 1.35000000e+05 3.00000000e+00\n",
      " 4.00000000e+00 1.34500000e+03 2.00000000e+00 8.14814815e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[104] = [0.22818401] \n",
      "Xnew[105] = [2.00000000e+00 1.00000000e+00 4.07000000e+03 1.39700000e+03\n",
      " 1.82000000e+00 1.00000000e+00 6.66666667e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.37000000e+03 1.00000000e+00 9.00000000e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[105] = [0.22827363] \n",
      "Xnew[106] = [2.00000000e+00 1.00000000e+00 8.01800000e+03 1.64900000e+03\n",
      " 6.74500000e+00 1.00000000e+00 9.33333333e+04 2.00000000e+00\n",
      " 4.00000000e+00 1.62000000e+03 5.00000000e+00 8.57142857e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[106] = [0.22823966] \n",
      "Xnew[107] = [2.00000000e+00 1.00000000e+00 8.00200000e+03 1.00700000e+03\n",
      " 7.73600000e+00 1.00000000e+00 1.55000000e+05 4.00000000e+00\n",
      " 4.00000000e+00 2.16500000e+03 4.00000000e+00 5.16129032e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[107] = [0.22833052] \n",
      "Xnew[108] = [2.00000000e+00 1.00000000e+00 4.07700000e+03 5.79000000e+02\n",
      " 2.00000000e-01 1.00000000e+00 5.83333333e+04 2.00000000e+00\n",
      " 3.00000000e+00 6.75000000e+02 1.00000000e+00 6.85714286e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[108] = [0.2280167] \n",
      "Xnew[109] = [1.00000000e+00 3.00000000e+00 7.81300000e+03 1.13200000e+03\n",
      " 2.30000000e+00 1.00000000e+00 1.09166667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.31000000e+03 2.00000000e+00 7.32824427e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[109] = [0.22826436] \n",
      "Xnew[110] = [1.00000000e+00 3.00000000e+00 4.18900000e+03 7.39000000e+02\n",
      " 2.00000000e-01 1.00000000e+00 6.66666667e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.71000000e+03 2.00000000e+00 9.00000000e-01\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[110] = [0.22800958] \n",
      "Xnew[111] = [2.00000000e+00 1.00000000e+00 5.51300000e+03 9.39000000e+02\n",
      " 5.00000000e-01 1.00000000e+00 1.42500000e+05 3.00000000e+00\n",
      " 4.00000000e+00 1.33000000e+03 1.00000000e+00 8.42105263e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00], ynew3[111] = [0.22793916] \n",
      "Xnew[112] = [2.000e+00 1.000e+00 4.253e+03 1.073e+03 6.500e-01 1.000e+00 2.500e+05\n",
      " 6.000e+00 1.000e+00 1.175e+03 3.000e+00 1.000e+00 2.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00], ynew3[112] = [0.22824529] \n",
      "Xnew[113] = [2.000e+00 1.000e+00 4.756e+03 1.071e+03 6.000e-01 1.000e+00 2.500e+05\n",
      " 6.000e+00 1.000e+00 1.250e+03 5.000e+00 1.000e+00 2.000e+00 1.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00], ynew3[113] = [0.2282516] \n",
      "Xnew[114] = [2.00000000e+00 1.00000000e+00 5.41400000e+03 5.50000000e+02\n",
      " 1.42500000e-01 1.00000000e+00 3.00000000e+04 1.00000000e+00\n",
      " 1.00000000e+00 5.00000000e+02 4.00000000e+00 8.33333333e-01\n",
      " 4.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[114] = [0.2281538] \n",
      "Xnew[115] = [2.00000000e+00 1.00000000e+00 5.41400000e+03 5.50000000e+02\n",
      " 1.42500000e-01 1.00000000e+00 3.00000000e+04 1.00000000e+00\n",
      " 1.00000000e+00 2.80000000e+02 4.00000000e+00 8.33333333e-01\n",
      " 4.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[115] = [0.22815841] \n",
      "Xnew[116] = [2.00000000e+00 1.00000000e+00 7.21300000e+03 1.47500000e+03\n",
      " 1.07000000e+00 1.00000000e+00 1.45833333e+05 3.00000000e+00\n",
      " 3.00000000e+00 1.18000000e+03 1.00000000e+00 9.60000000e-01\n",
      " 2.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[116] = [0.22828549] \n",
      "Xnew[117] = [2.00000000e+00 1.00000000e+00 2.87000000e+02 1.23300000e+03\n",
      " 8.63636364e-01 1.00000000e+00 6.50000000e+04 2.00000000e+00\n",
      " 4.00000000e+00 8.70000000e+02 2.00000000e+00 6.15384615e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[117] = [0.2281785] \n",
      "Xnew[118] = [2.00000000e+00 1.00000000e+00 4.39200000e+03 1.04000000e+03\n",
      " 6.00000000e-01 1.00000000e+00 7.50000000e+04 2.00000000e+00\n",
      " 4.00000000e+00 1.43200000e+03 2.00000000e+00 6.66666667e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[118] = [0.22819933] \n",
      "Xnew[119] = [2.00000000e+00 1.00000000e+00 3.57000000e+03 6.74000000e+02\n",
      " 7.60000000e-01 1.00000000e+00 1.55000000e+05 4.00000000e+00\n",
      " 2.00000000e+00 9.10000000e+02 4.00000000e+00 8.38709677e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[119] = [0.22831908] \n",
      "Xnew[120] = [2.00000000e+00 1.00000000e+00 8.52300000e+03 1.98200000e+03\n",
      " 6.20000000e+00 1.00000000e+00 8.66666667e+04 2.00000000e+00\n",
      " 1.00000000e+00 1.16000000e+03 4.00000000e+00 9.23076923e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[120] = [0.2283484] \n",
      "Xnew[121] = [2.00000000e+00 1.00000000e+00 5.67000000e+03 8.87000000e+02\n",
      " 8.50000000e-01 1.00000000e+00 5.83333333e+04 2.00000000e+00\n",
      " 2.00000000e+00 1.30000000e+03 2.00000000e+00 8.57142857e-01\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[121] = [0.22818407] \n",
      "Xnew[122] = [2.00000000e+00 1.00000000e+00 6.00100000e+03 1.11900000e+03\n",
      " 4.41000000e+00 1.00000000e+00 1.16666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 1.33300000e+03 2.00000000e+00 8.57142857e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[122] = [0.22832668] \n",
      "Xnew[123] = [2.00000000e+00 1.00000000e+00 1.38100000e+03 1.09800000e+03\n",
      " 1.20000000e+00 1.00000000e+00 2.30833333e+05 5.00000000e+00\n",
      " 2.00000000e+00 8.96000000e+02 4.00000000e+00 8.66425993e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[123] = [0.22837928] \n",
      "Xnew[124] = [2.00000000e+00 1.00000000e+00 7.72900000e+03 1.20200000e+03\n",
      " 3.00000000e+00 1.00000000e+00 1.16666667e+05 3.00000000e+00\n",
      " 2.00000000e+00 9.45000000e+02 5.00000000e+00 8.57142857e-01\n",
      " 5.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[124] = [0.22832946] \n",
      "Xnew[125] = [2.00000000e+00 1.00000000e+00 2.39800000e+03 1.04000000e+03\n",
      " 1.45000000e+00 1.00000000e+00 2.16666667e+05 5.00000000e+00\n",
      " 3.00000000e+00 1.16000000e+03 5.00000000e+00 6.92307692e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[125] = [0.22834569] \n",
      "Xnew[126] = [2.00000000e+00 1.00000000e+00 1.88500000e+03 9.15000000e+02\n",
      " 1.00000000e+00 1.00000000e+00 9.33333333e+04 2.00000000e+00\n",
      " 3.00000000e+00 9.90000000e+02 5.00000000e+00 6.42857143e-01\n",
      " 4.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00], ynew3[126] = [0.22821909] \n"
     ]
    }
   ],
   "source": [
    "print(\"The values of Xnew and its predicted yhat\")\n",
    "for loop in range(len(Xnew)):\n",
    "        print(\"Xnew[%s] = %s, ynew3[%s] = %s \" % (loop,Xnew[loop],loop,ynew3[loop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22859916]\n",
      " [0.22847998]\n",
      " [0.22792336]\n",
      " [0.22817472]\n",
      " [0.2280769 ]\n",
      " [0.22786003]\n",
      " [0.22839233]\n",
      " [0.22848225]\n",
      " [0.22836334]\n",
      " [0.22826937]\n",
      " [0.22853202]\n",
      " [0.2285335 ]\n",
      " [0.22847193]\n",
      " [0.22852087]\n",
      " [0.22860163]\n",
      " [0.22846052]\n",
      " [0.22833562]\n",
      " [0.22829047]\n",
      " [0.22850037]\n",
      " [0.2286934 ]\n",
      " [0.22845733]\n",
      " [0.22822273]\n",
      " [0.22839436]\n",
      " [0.2284196 ]\n",
      " [0.22841316]\n",
      " [0.22842127]\n",
      " [0.22815311]\n",
      " [0.22847879]\n",
      " [0.22845289]\n",
      " [0.22871706]\n",
      " [0.22859982]\n",
      " [0.2288307 ]\n",
      " [0.22883931]\n",
      " [0.22884268]\n",
      " [0.22884762]\n",
      " [0.22869506]\n",
      " [0.22846594]\n",
      " [0.22866729]\n",
      " [0.2286067 ]\n",
      " [0.22874951]\n",
      " [0.2287541 ]\n",
      " [0.22872093]\n",
      " [0.22863498]\n",
      " [0.2287941 ]\n",
      " [0.22879305]\n",
      " [0.22866592]\n",
      " [0.22864842]\n",
      " [0.22855902]\n",
      " [0.2288506 ]\n",
      " [0.2287791 ]\n",
      " [0.2288298 ]\n",
      " [0.2281816 ]\n",
      " [0.22872218]\n",
      " [0.22887045]\n",
      " [0.22880006]\n",
      " [0.22872302]\n",
      " [0.22802377]\n",
      " [0.22807398]\n",
      " [0.22853383]\n",
      " [0.2280648 ]\n",
      " [0.22772527]\n",
      " [0.22797033]\n",
      " [0.22807908]\n",
      " [0.22811237]\n",
      " [0.22808784]\n",
      " [0.22823319]\n",
      " [0.22820923]\n",
      " [0.22795644]\n",
      " [0.22807145]\n",
      " [0.2283895 ]\n",
      " [0.22848487]\n",
      " [0.22851178]\n",
      " [0.22877151]\n",
      " [0.22856927]\n",
      " [0.22828987]\n",
      " [0.22841334]\n",
      " [0.22852385]\n",
      " [0.22815824]\n",
      " [0.2282027 ]\n",
      " [0.22828081]\n",
      " [0.2283589 ]\n",
      " [0.22840205]\n",
      " [0.22833112]\n",
      " [0.22846079]\n",
      " [0.22840855]\n",
      " [0.22842407]\n",
      " [0.22844756]\n",
      " [0.2282336 ]\n",
      " [0.22826022]\n",
      " [0.22819817]\n",
      " [0.2283594 ]\n",
      " [0.2283046 ]\n",
      " [0.22844815]\n",
      " [0.2281802 ]\n",
      " [0.22795859]\n",
      " [0.22777656]\n",
      " [0.2279568 ]\n",
      " [0.22793317]\n",
      " [0.22798663]\n",
      " [0.2277408 ]\n",
      " [0.22807235]\n",
      " [0.22812545]\n",
      " [0.22800696]\n",
      " [0.22818172]\n",
      " [0.22818401]\n",
      " [0.22827363]\n",
      " [0.22823966]\n",
      " [0.22833052]\n",
      " [0.2280167 ]\n",
      " [0.22826436]\n",
      " [0.22800958]\n",
      " [0.22793916]\n",
      " [0.22824529]\n",
      " [0.2282516 ]\n",
      " [0.2281538 ]\n",
      " [0.22815841]\n",
      " [0.22828549]\n",
      " [0.2281785 ]\n",
      " [0.22819933]\n",
      " [0.22831908]\n",
      " [0.2283484 ]\n",
      " [0.22818407]\n",
      " [0.22832668]\n",
      " [0.22837928]\n",
      " [0.22832946]\n",
      " [0.22834569]\n",
      " [0.22821909]]\n"
     ]
    }
   ],
   "source": [
    "print(ynew3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0      18-2    actual                    Name\n",
      "0    0.755092  0.228599  0.760000           Lingshui Semi\n",
      "1    0.450772  0.228480  0.471042          Bohai Ming Zhu\n",
      "2    0.286733  0.227923  0.286765          Petrojarl Varg\n",
      "3    0.006505  0.228175 -0.143875  Stybarrow Venture MV16\n",
      "4    0.002868  0.228077 -0.022133               Alima FPU\n",
      "..        ...       ...       ...                     ...\n",
      "122  0.000923  0.228327 -0.088472              Shenzi TLP\n",
      "123  0.000445  0.228379 -0.090164                Mars TLP\n",
      "124  0.000155  0.228329 -0.125624             Olympus TLP\n",
      "125  0.000401  0.228346 -0.081731                Ursa TLP\n",
      "126  0.001510  0.228219  0.015301          Ram Powell TLP\n",
      "\n",
      "[127 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "Sch_Pred3 = pd.DataFrame(ynew2)\n",
    "Sch_Pred3['18-2'] = pd.DataFrame(ynew3)\n",
    "\n",
    "df_t = pd.read_excel(open('Cost_Sch-data-v2.xlsx', 'rb'), sheet_name='Sch_T2')\n",
    "\n",
    "\n",
    "Sch_Pred3['actual'] = df_t['Schedule_Overrun']\n",
    "\n",
    "Sch_Pred3['Name'] = df_t['Unit Name']\n",
    "print(Sch_Pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sch_Pred3.to_excel(\"Sch_Pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 Features:\n",
    "Region\n",
    "Local Content\n",
    "Lease/ Own\n",
    "Planned_Cost\n",
    "Hull Type\n",
    "Technology Novelty\n",
    "Type Unit\n",
    "Water_Depth \n",
    "Lessons Learned\n",
    "Oil/Gas\n",
    "FEED Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use only Region, Water Depth, Technology Novelty, and Lessons Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce features as per pearson correlation\n",
    "#X = dataset[:,[1, 2, 4, 9, 10, 13, 14, 15, 16, 17, 18]]\n",
    "X = dataset[:,[1, 2, 4, 9, 10, 11, 12,13, 14, 15, 16, 17, 18]]\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = dataset[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler2 = preprocessing.MinMaxScaler()\n",
    "#Y_scale = min_max_scaler2.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X_scale, Y):\n",
    "# create model\n",
    "\tmodel4 = Sequential()\n",
    "\tmodel4.add(Dense(13, input_dim=13, activation='sigmoid'))\n",
    "\tmodel4.add(Dense(26, activation='sigmoid'))\n",
    "\tmodel4.add(Dense(8, activation='sigmoid'))\n",
    "\tmodel4.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel4.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\t# Fit the model\n",
    "\tmodel4.fit(X_scale[train], Y[train], epochs=150, batch_size=9, verbose=0)\n",
    "\t# evaluate the model\n",
    "\tscores = model4.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "\tprint(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "\tcvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores2 = []\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "# create model\n",
    "    model5 = Sequential([\n",
    "        Dense(26, activation='sigmoid', input_shape=(13,)),\n",
    "        Dense(13, activation='sigmoid'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    epochs=400\n",
    "    learning_rate = 0.1\n",
    "    decay_rate = learning_rate / epochs\n",
    "    momentum = 0.8\n",
    "    sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model5.compile(optimizer='sgd',\n",
    "              loss='mse',              \n",
    "              metrics=['accuracy'])\n",
    "    hist3 = model5.fit(X_train, Y_train,\n",
    "          batch_size=9, epochs=epochs,\n",
    "          validation_data=(X_val, Y_val))\n",
    "    scores = model5.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "    cvscores2.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist3.history['loss'])\n",
    "plt.plot(hist3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t2 = pd.read_excel(open('Cost_Sch-data-v2.xlsx', 'rb'), sheet_name='Cost_T1')\n",
    "df_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_t2 = df_t2.values\n",
    "Xnew2 = dataset_t2[:,[1, 2, 4, 9, 10, 11, 12,13, 14, 15, 16, 17, 18]]\n",
    "print(Xnew2.shape)\n",
    "print(Xnew2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "Xnew_scale2 = min_max_scaler.fit_transform(Xnew2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew4 = model4.predict(Xnew_scale2)\n",
    "ynew5 = model5.predict(Xnew_scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The values of Xnew and its predicted yhat\")\n",
    "for loop in range(len(Xnew)):\n",
    "        print(\"Xnew[%s] = %s, ynew[%s] = %s \" % (loop,Xnew[loop],loop,ynew4[loop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ynew4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 Features:\n",
    "Region\n",
    "Local Content\n",
    "Lease/ Own\n",
    "Technology Novelty\n",
    "Type Unit\n",
    "Lessons Learned\n",
    "FEED Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reduce features further as per pearson correlation\n",
    "X = dataset[:,[1, 2, 12, 13, 14, 16, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = dataset[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold.split(X_scale, Y):\n",
    "# create model\n",
    "\tmodel6 = Sequential()\n",
    "\tmodel6.add(Dense(12, input_dim=7, activation='relu'))\n",
    "\tmodel6.add(Dense(8, activation='relu'))\n",
    "\tmodel6.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel6.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\t# Fit the model\n",
    "\tmodel6.fit(X_scale[train], Y[train], epochs=150, batch_size=9, verbose=0)\n",
    "\t# evaluate the model\n",
    "\tscores = model6.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "\tprint(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "\tcvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores2 = []\n",
    "for train, test in kfold.split(X_train, Y_train):\n",
    "# create model\n",
    "    model7 = Sequential([\n",
    "        Dense(14, activation='sigmoid', input_shape=(7,)),\n",
    "        Dense(7, activation='sigmoid'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    epochs=400\n",
    "    learning_rate = 0.1\n",
    "    decay_rate = learning_rate / epochs\n",
    "    momentum = 0.8\n",
    "    sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model7.compile(optimizer='sgd',\n",
    "              loss='mse',              \n",
    "              metrics=['accuracy'])\n",
    "    hist3 = model7.fit(X_train, Y_train,\n",
    "          batch_size=9, epochs=epochs,\n",
    "          validation_data=(X_val, Y_val))\n",
    "    scores = model7.evaluate(X_scale[train], Y[train], verbose=0)\n",
    "    cvscores2.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores2), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist3.history['loss'])\n",
    "plt.plot(hist3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t3 = pd.read_excel(open('Cost_Sch-data-v2.xlsx', 'rb'), sheet_name='Cost_T1')\n",
    "df_t3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_t3 = df_t3.values\n",
    "Xnew3 = dataset_t3[:,[1, 2, 4, 13, 14, 16, 18]]\n",
    "Xnew3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "Xnew_scale2 = min_max_scaler.fit_transform(Xnew3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ynew6 = model6.predict(Xnew_scale2)\n",
    "ynew7 = model7.predict(Xnew_scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The values of Xnew and its predicted yhat\")\n",
    "for loop in range(len(Xnew)):\n",
    "        print(\"Xnew[%s] = %s, ynew[%s] = %s \" % (loop,Xnew[loop],loop,ynew5[loop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ynew6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ynew5))\n",
    "print(ynew5.shape)\n",
    "#print(range(ynew5))\n",
    "\n",
    "#Cost_Pred3 = pd.DataFrame\n",
    "Sch_Pred3 = pd.DataFrame(ynew1)\n",
    "Sch_Pred3['18-2'] = pd.DataFrame(ynew3)\n",
    "Sch_Pred3['13-1'] = pd.DataFrame(ynew4)\n",
    "Sch_Pred3['13-2'] = pd.DataFrame(ynew5)\n",
    "Sch_Pred3['7-1'] = pd.DataFrame(ynew6)\n",
    "Sch_Pred3['7-2'] = pd.DataFrame(ynew7)\n",
    "Sch_Pred3['actual'] = dataset_t[:,20]\n",
    "\n",
    "Sch_Pred3['Name'] = df['Unit Name']\n",
    "print(Sch_Pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sch_Pred3.to_excel(\"Sch_Pred3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
